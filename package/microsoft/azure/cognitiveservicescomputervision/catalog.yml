Product:
  name: Azure Cognitive Services Computer Vision
  versions: [3.1.0,3.2.0-preview2]
  package: microsoft.azure.cognitiveservicescomputervision
  description: |-
    CognitiveServicesComputerVision
  link: https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/
  contentType: json
Operations:
  AnalyzeImage.AnalyzeImage:
    description: |-
      This operation extracts a rich set of visual features based on the image content.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/analyzeimage/analyzeimage
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "tags": [
            {
              "name": "person",
              "confidence": 0.9897908568382263
            },
            {
              "name": "man",
              "confidence": 0.9449388980865479
            },
            {
              "name": "outdoor",
              "confidence": 0.938492476940155
            },
            {
              "name": "window",
              "confidence": 0.8951393961906433
            },
            {
              "hint": "mammal",
              "name": "pangolin",
              "confidence": 0.7250059783791661
            }
          ],
          "adult": {
            "goreScore": 0.012872257380997575,
            "racyScore": 0.06861349195241928,
            "adultScore": 0.0934349000453949,
            "isGoryContent": false,
            "isRacyContent": false,
            "isAdultContent": false
          },
          "color": {
            "isBWImg": false,
            "accentColor": "873B59",
            "dominantColors": [
              "Brown",
              "Black"
            ],
            "dominantColorBackground": "Brown",
            "dominantColorForeground": "Brown"
          },
          "faces": [
            {
              "age": 44,
              "gender": "Male",
              "faceRectangle": {
                "top": 160,
                "left": 593,
                "width": 250,
                "height": 250
              }
            }
          ],
          "brands": [
            {
              "name": "Pepsi",
              "rectangle": {
                "h": 177,
                "w": 161,
                "x": 489,
                "y": 79
              },
              "confidence": 0.857
            },
            {
              "name": "Coca-Cola",
              "rectangle": {
                "h": 372,
                "w": 171,
                "x": 216,
                "y": 55
              },
              "confidence": 0.893
            }
          ],
          "objects": [
            {
              "object": "tree",
              "parent": {
                "object": "plant",
                "confidence": 0.95
              },
              "rectangle": {
                "h": 50,
                "w": 50,
                "x": 0,
                "y": 0
              },
              "confidence": 0.9
            }
          ],
          "metadata": {
            "width": 1500,
            "format": "Jpeg",
            "height": 1000
          },
          "imageType": {
            "clipArtType": 0,
            "lineDrawingType": 0
          },
          "requestId": "0dbec5ad-a3d3-4f7e-96b4-dfd57efe967d",
          "categories": [
            {
              "name": "abstract_",
              "score": 0.00390625
            },
            {
              "name": "people_",
              "score": 0.83984375,
              "detail": {
                "celebrities": [
                  {
                    "name": "Satya Nadella",
                    "confidence": 0.999028444,
                    "faceRectangle": {
                      "top": 162,
                      "left": 597,
                      "width": 248,
                      "height": 248
                    }
                  }
                ]
              }
            },
            {
              "name": "building_",
              "score": 0.984375,
              "detail": {
                "landmarks": [
                  {
                    "name": "Forbidden City",
                    "confidence": 0.9829016923904419
                  }
                ]
              }
            }
          ],
          "description": {
            "tags": [
              "person",
              "man",
              "outdoor",
              "window",
              "glasses"
            ],
            "captions": [
              {
                "text": "Satya Nadella sitting on a bench",
                "confidence": 0.48293603002174407
              }
            ]
          }
        }
      ]
  AnalyzeImageByDomain.AnalyzeImageByDomain:
    description: |-
      This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API provides following domain-specific models: celebrities, landmarks.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/analyzeimagebydomain/analyzeimagebydomain
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "result": {
            "celebrities": [
              {
                "name": "Satya Nadella",
                "confidence": 0.999028444,
                "faceRectangle": {
                  "top": 162,
                  "left": 597,
                  "width": 248,
                  "height": 248
                }
              }
            ]
          },
          "metadata": {
            "width": 1500,
            "format": "Jpeg",
            "height": 1000
          },
          "requestId": "f0027b4b-dc0d-4082-9228-1545ed246b03"
        }
      ]
  AnalyzeImageByDomainInStream.AnalyzeImageByDomainInStream:
    description: |-
      This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API provides following domain-specific models: celebrities, landmarks.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/analyzeimagebydomaininstream/analyzeimagebydomaininstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "result": {
            "celebrities": [
              {
                "name": "Satya Nadella",
                "confidence": 0.999028444,
                "faceRectangle": {
                  "top": 162,
                  "left": 597,
                  "width": 248,
                  "height": 248
                }
              }
            ]
          },
          "metadata": {
            "width": 1500,
            "format": "Jpeg",
            "height": 1000
          },
          "requestId": "f0027b4b-dc0d-4082-9228-1545ed246b03"
        }
      ]
  AnalyzeImageInStream.AnalyzeImageInStream:
    description: |-
      This operation extracts a rich set of visual features based on the image content.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/analyzeimageinstream/analyzeimageinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "tags": [
            {
              "name": "person",
              "confidence": 0.9897908568382263
            },
            {
              "name": "man",
              "confidence": 0.9449388980865479
            },
            {
              "name": "outdoor",
              "confidence": 0.938492476940155
            },
            {
              "name": "window",
              "confidence": 0.8951393961906433
            },
            {
              "hint": "mammal",
              "name": "pangolin",
              "confidence": 0.7250059783791661
            }
          ],
          "adult": {
            "goreScore": 0.012872257380997575,
            "racyScore": 0.06861349195241928,
            "adultScore": 0.0934349000453949,
            "isGoryContent": false,
            "isRacyContent": false,
            "isAdultContent": false
          },
          "color": {
            "isBWImg": false,
            "accentColor": "873B59",
            "dominantColors": [
              "Brown",
              "Black"
            ],
            "dominantColorBackground": "Brown",
            "dominantColorForeground": "Brown"
          },
          "faces": [
            {
              "age": 44,
              "gender": "Male",
              "faceRectangle": {
                "top": 160,
                "left": 593,
                "width": 250,
                "height": 250
              }
            }
          ],
          "brands": [
            {
              "name": "Pepsi",
              "rectangle": {
                "h": 177,
                "w": 161,
                "x": 489,
                "y": 79
              },
              "confidence": 0.857
            },
            {
              "name": "Coca-Cola",
              "rectangle": {
                "h": 372,
                "w": 171,
                "x": 216,
                "y": 55
              },
              "confidence": 0.893
            }
          ],
          "objects": [
            {
              "object": "tree",
              "parent": {
                "object": "plant",
                "confidence": 0.95
              },
              "rectangle": {
                "h": 50,
                "w": 50,
                "x": 0,
                "y": 0
              },
              "confidence": 0.9
            }
          ],
          "metadata": {
            "width": 1500,
            "format": "Jpeg",
            "height": 1000
          },
          "imageType": {
            "clipArtType": 0,
            "lineDrawingType": 0
          },
          "requestId": "0dbec5ad-a3d3-4f7e-96b4-dfd57efe967d",
          "categories": [
            {
              "name": "abstract_",
              "score": 0.00390625
            },
            {
              "name": "people_",
              "score": 0.83984375,
              "detail": {
                "landmarks": [
                  {
                    "name": "Forbidden City",
                    "confidence": 0.9978346
                  }
                ],
                "celebrities": [
                  {
                    "name": "Satya Nadella",
                    "confidence": 0.999028444,
                    "faceRectangle": {
                      "top": 162,
                      "left": 597,
                      "width": 248,
                      "height": 248
                    }
                  }
                ]
              }
            }
          ],
          "description": {
            "tags": [
              "person",
              "man",
              "outdoor",
              "window",
              "glasses"
            ],
            "captions": [
              {
                "text": "Satya Nadella sitting on a bench",
                "confidence": 0.48293603002174407
              }
            ]
          }
        }
      ]
  DescribeImage.DescribeImage:
    description: |-
      This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may include results from celebrity and landmark domain models, if applicable.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/describeimage/describeimage
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "metadata": {
            "width": 1500,
            "format": "Jpeg",
            "height": 1000
          },
          "requestId": "ed2de1c6-fb55-4686-b0da-4da6e05d283f",
          "description": {
            "tags": [
              "person",
              "man",
              "outdoor",
              "window",
              "glasses"
            ],
            "captions": [
              {
                "text": "Satya Nadella sitting on a bench",
                "confidence": 0.48293603002174407
              },
              {
                "text": "Satya Nadella is sitting on a bench",
                "confidence": 0.4003700681542283
              },
              {
                "text": "Satya Nadella sitting in front of a building",
                "confidence": 0.38035155997373377
              }
            ]
          }
        }
      ]
  DescribeImageInStream.DescribeImageInStream:
    description: |-
      This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. Descriptions may include results from celebrity and landmark domain models, if applicable.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/describeimageinstream/describeimageinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "metadata": {
            "width": 1500,
            "format": "Jpeg",
            "height": 1000
          },
          "requestId": "ed2de1c6-fb55-4686-b0da-4da6e05d283f",
          "description": {
            "tags": [
              "person",
              "man",
              "outdoor",
              "window",
              "glasses"
            ],
            "captions": [
              {
                "text": "Satya Nadella sitting on a bench",
                "confidence": 0.48293603002174407
              },
              {
                "text": "Satya Nadella is sitting on a bench",
                "confidence": 0.4003700681542283
              },
              {
                "text": "Satya Nadella sitting in front of a building",
                "confidence": 0.38035155997373377
              }
            ]
          }
        }
      ]
  DetectObjects.DetectObjects:
    description: |-
      Performs object detection on the specified image.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/detectobjects/detectobjects
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "objects": [
            {
              "object": "tree",
              "parent": {
                "object": "plant",
                "confidence": 0.95
              },
              "rectangle": {
                "h": 50,
                "w": 50,
                "x": 0,
                "y": 0
              },
              "confidence": 0.9
            }
          ],
          "metadata": {
            "width": 100,
            "format": "Jpeg",
            "height": 100
          },
          "requestId": "1ad0e45e-b7b4-4be3-8042-53be96103337"
        }
      ]
  DetectObjectsInStream.DetectObjectsInStream:
    description: |-
      Performs object detection on the specified image.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/detectobjectsinstream/detectobjectsinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "objects": [
            {
              "object": "tree",
              "parent": {
                "object": "plant",
                "confidence": 0.95
              },
              "rectangle": {
                "h": 50,
                "w": 50,
                "x": 0,
                "y": 0
              },
              "confidence": 0.9
            }
          ],
          "metadata": {
            "width": 100,
            "format": "Jpeg",
            "height": 100
          },
          "requestId": "1ad0e45e-b7b4-4be3-8042-53be96103337"
        }
      ]
  GenerateThumbnail.GenerateThumbnail:
    description: |-
      This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/generatethumbnail/generatethumbnail
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        "{Binary}"
      ]
  GenerateThumbnailInStream.GenerateThumbnailInStream:
    description: |-
      This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/generatethumbnailinstream/generatethumbnailinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {}
      ]
  GetAreaOfInterest.GetAreaOfInterest:
    description: |-
      This operation returns a bounding box around the most important area of the image.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/getareaofinterest/getareaofinterest
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "metadata": {
            "width": 1378,
            "format": "Jpeg",
            "height": 951
          },
          "requestId": "ed2de1c6-fb55-4686-b0da-4da6e05d283f",
          "areaOfInterest": {
            "h": 951,
            "w": 950,
            "x": 160,
            "y": 0
          }
        }
      ]
  GetAreaOfInterestInStream.GetAreaOfInterestInStream:
    description: |-
      This operation returns a bounding box around the most important area of the image.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/getareaofinterestinstream/getareaofinterestinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "metadata": {
            "width": 1378,
            "format": "Jpeg",
            "height": 951
          },
          "requestId": "ed2de1c6-fb55-4686-b0da-4da6e05d283f",
          "areaOfInterest": {
            "h": 951,
            "w": 950,
            "x": 160,
            "y": 0
          }
        }
      ]
  ListModels.ListModels:
    description: |-
      This operation returns the list of domain-specific models that are supported by the Computer Vision API. Currently, the API supports following domain-specific models: celebrity recognizer, landmark recognizer.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/listmodels/listmodels
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "models": [
            {
              "name": "celebrities",
              "categories": [
                "people_"
              ]
            },
            {
              "name": "landmarks",
              "categories": [
                "building_"
              ]
            }
          ]
        }
      ]
  RecognizePrintedTextInStream.RecognizePrintedTextInStream:
    description: |-
      Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a machine-usable character stream.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/recognizeprintedtextinstream/recognizeprintedtextinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "regions": [
            {
              "lines": [
                {
                  "words": [
                    {
                      "text": "A",
                      "boundingBox": "462,379,41,73"
                    },
                    {
                      "text": "GOAL",
                      "boundingBox": "523,379,153,73"
                    },
                    {
                      "text": "WITHOUT",
                      "boundingBox": "694,379,265,74"
                    }
                  ],
                  "boundingBox": "462,379,497,74"
                },
                {
                  "words": [
                    {
                      "text": "A",
                      "boundingBox": "565,471,41,73"
                    },
                    {
                      "text": "PLAN",
                      "boundingBox": "626,471,150,73"
                    },
                    {
                      "text": "IS",
                      "boundingBox": "801,472,53,73"
                    }
                  ],
                  "boundingBox": "565,471,289,74"
                },
                {
                  "words": [
                    {
                      "text": "JUST",
                      "boundingBox": "519,563,149,74"
                    },
                    {
                      "text": "A",
                      "boundingBox": "683,564,41,72"
                    },
                    {
                      "text": "WISH",
                      "boundingBox": "741,564,153,73"
                    }
                  ],
                  "boundingBox": "519,563,375,74"
                }
              ],
              "boundingBox": "462,379,497,258"
            }
          ],
          "language": "en",
          "textAngle": -2.0000000000000338,
          "orientation": "Up"
        }
      ]
  RecognizePrintedText.RecognizePrintedText:
    description: |-
      Optical Character Recognition (OCR) detects text in an image and extracts the recognized characters into a machine-usable character stream.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/recognizeprintedtext/recognizeprintedtext
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "regions": [
            {
              "lines": [
                {
                  "words": [
                    {
                      "text": "A",
                      "boundingBox": "462,379,41,73"
                    },
                    {
                      "text": "GOAL",
                      "boundingBox": "523,379,153,73"
                    },
                    {
                      "text": "WITHOUT",
                      "boundingBox": "694,379,265,74"
                    }
                  ],
                  "boundingBox": "462,379,497,74"
                },
                {
                  "words": [
                    {
                      "text": "A",
                      "boundingBox": "565,471,41,73"
                    },
                    {
                      "text": "PLAN",
                      "boundingBox": "626,471,150,73"
                    },
                    {
                      "text": "IS",
                      "boundingBox": "801,472,53,73"
                    }
                  ],
                  "boundingBox": "565,471,289,74"
                },
                {
                  "words": [
                    {
                      "text": "JUST",
                      "boundingBox": "519,563,149,74"
                    },
                    {
                      "text": "A",
                      "boundingBox": "683,564,41,72"
                    },
                    {
                      "text": "WISH",
                      "boundingBox": "741,564,153,73"
                    }
                  ],
                  "boundingBox": "519,563,375,74"
                }
              ],
              "boundingBox": "462,379,497,258"
            }
          ],
          "language": "en",
          "textAngle": -2.0000000000000338,
          "orientation": "Up"
        }
      ]
  TagImageInStream.TagImageInStream:
    description: |-
      This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag `ascomycete` may be accompanied by the hint `fungus`.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/tagimageinstream/tagimageinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {
          "tags": [
            {
              "name": "grass",
              "confidence": 0.9999997615814209
            },
            {
              "name": "outdoor",
              "confidence": 0.9999706745147705
            },
            {
              "name": "sky",
              "confidence": 0.9992897510528564
            },
            {
              "name": "building",
              "confidence": 0.9964632391929626
            },
            {
              "name": "house",
              "confidence": 0.9927980303764343
            },
            {
              "name": "lawn",
              "confidence": 0.8226802945137024
            },
            {
              "name": "green",
              "confidence": 0.6412225365638733
            },
            {
              "name": "residential",
              "confidence": 0.31403225660324097
            }
          ],
          "metadata": {
            "width": 400,
            "format": "Jpeg",
            "height": 400
          },
          "requestId": "1ad0e45e-b7b4-4be3-8042-53be96103337"
        }
      ]
  TagImage.TagImage:
    description: |-
      This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag `ascomycete` may be accompanied by the hint `fungus`.
    versions:
      from: 3.1.0
      to: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.1/tagimage/tagimage
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {
          "tags": [
            {
              "name": "grass",
              "confidence": 0.9999997615814209
            },
            {
              "name": "outdoor",
              "confidence": 0.9999706745147705
            },
            {
              "name": "sky",
              "confidence": 0.9992897510528564
            },
            {
              "name": "building",
              "confidence": 0.9964632391929626
            },
            {
              "name": "house",
              "confidence": 0.9927980303764343
            },
            {
              "name": "lawn",
              "confidence": 0.8226802945137024
            },
            {
              "name": "green",
              "confidence": 0.6412225365638733
            },
            {
              "name": "residential",
              "confidence": 0.31403225660324097
            }
          ],
          "metadata": {
            "width": 400,
            "format": "Jpeg",
            "height": 400
          },
          "requestId": "1ad0e45e-b7b4-4be3-8042-53be96103337"
        }
      ]
  GetReadResult.GetReadResult:
    description: |-
      This interface is used for getting OCR results of Read operation. The URL to this interface should be retrieved from 'Operation-Location' field returned from Read interface.
    versions:
      from: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.2preview2/getreadresult/getreadresult
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "status": "succeeded",
          "analyzeResult": {
            "version": "v3.2",
            "readResults": [
              {
                "page": 1,
                "unit": "pixel",
                "angle": 49.59,
                "lines": [
                  {
                    "text": "Our greatest glory is not",
                    "words": [
                      {
                        "text": "Our",
                        "confidence": 0.164,
                        "boundingBox": [
                          204,
                          627,
                          481,
                          628,
                          481,
                          830,
                          204,
                          829
                        ]
                      },
                      {
                        "text": "greatest",
                        "confidence": 0.164,
                        "boundingBox": [
                          519,
                          628,
                          1057,
                          630,
                          1057,
                          832,
                          518,
                          830
                        ]
                      },
                      {
                        "text": "glory",
                        "confidence": 0.164,
                        "boundingBox": [
                          1114,
                          630,
                          1549,
                          631,
                          1548,
                          833,
                          1114,
                          832
                        ]
                      },
                      {
                        "text": "is",
                        "confidence": 0.164,
                        "boundingBox": [
                          1586,
                          631,
                          1785,
                          632,
                          1784,
                          834,
                          1586,
                          833
                        ]
                      },
                      {
                        "text": "not",
                        "confidence": 0.164,
                        "boundingBox": [
                          1822,
                          632,
                          2115,
                          633,
                          2115,
                          835,
                          1822,
                          834
                        ]
                      }
                    ],
                    "appearance": {
                      "style": {
                        "name": "other",
                        "confidence": 0.995
                      }
                    },
                    "boundingBox": [
                      202,
                      618,
                      2047,
                      643,
                      2046,
                      840,
                      200,
                      813
                    ]
                  },
                  {
                    "text": "but in rising every time we fall",
                    "words": [
                      {
                        "text": "but",
                        "confidence": 0.164,
                        "boundingBox": [
                          423,
                          1269,
                          634,
                          1268,
                          635,
                          1507,
                          424,
                          1508
                        ]
                      },
                      {
                        "text": "in",
                        "confidence": 0.164,
                        "boundingBox": [
                          667,
                          1268,
                          808,
                          1268,
                          809,
                          1506,
                          668,
                          1507
                        ]
                      },
                      {
                        "text": "rising",
                        "confidence": 0.164,
                        "boundingBox": [
                          874,
                          1267,
                          1289,
                          1265,
                          1290,
                          1504,
                          875,
                          1506
                        ]
                      },
                      {
                        "text": "every",
                        "confidence": 0.164,
                        "boundingBox": [
                          1331,
                          1265,
                          1771,
                          1263,
                          1772,
                          1502,
                          1332,
                          1504
                        ]
                      },
                      {
                        "text": "time",
                        "confidence": 0.164,
                        "boundingBox": [
                          1812,
                          1263,
                          2178,
                          1261,
                          2179,
                          1500,
                          1813,
                          1502
                        ]
                      },
                      {
                        "text": "we",
                        "confidence": 0.164,
                        "boundingBox": [
                          2219,
                          1261,
                          2510,
                          1260,
                          2511,
                          1498,
                          2220,
                          1500
                        ]
                      },
                      {
                        "text": "fall",
                        "confidence": 0.164,
                        "boundingBox": [
                          2551,
                          1260,
                          3016,
                          1258,
                          3017,
                          1496,
                          2552,
                          1498
                        ]
                      }
                    ],
                    "appearance": {
                      "style": {
                        "name": "handwriting",
                        "confidence": 0.985
                      }
                    },
                    "boundingBox": [
                      420,
                      1273,
                      2954,
                      1250,
                      2958,
                      1488,
                      422,
                      1511
                    ]
                  },
                  {
                    "text": "Viva la vida",
                    "words": [
                      {
                        "text": "Viva",
                        "confidence": 0.164,
                        "boundingBox": [
                          323,
                          454,
                          416,
                          449,
                          418,
                          494,
                          325,
                          501
                        ]
                      },
                      {
                        "text": "la",
                        "confidence": 0.164,
                        "boundingBox": [
                          92,
                          550,
                          429,
                          541,
                          430,
                          591,
                          94,
                          600
                        ]
                      },
                      {
                        "text": "vida",
                        "confidence": 0.164,
                        "boundingBox": [
                          58,
                          466,
                          268,
                          458,
                          270,
                          505,
                          161,
                          512
                        ]
                      }
                    ],
                    "language": "es",
                    "appearance": {
                      "style": {
                        "name": "other",
                        "confidence": 0.995
                      }
                    },
                    "boundingBox": [
                      1612,
                      903,
                      2744,
                      935,
                      2738,
                      1139,
                      1607,
                      1107
                    ]
                  }
                ],
                "width": 600,
                "height": 400,
                "language": "en"
              },
              {
                "page": 2,
                "unit": "pixel",
                "angle": 1.32,
                "lines": [
                  {
                    "text": "in never failing ,",
                    "words": [
                      {
                        "text": "in",
                        "confidence": 0.164,
                        "boundingBox": [
                          1611,
                          934,
                          1707,
                          933,
                          1708,
                          1147,
                          1613,
                          1147
                        ]
                      },
                      {
                        "text": "never",
                        "confidence": 0.999,
                        "boundingBox": [
                          1753,
                          933,
                          2132,
                          930,
                          2133,
                          1144,
                          1754,
                          1146
                        ]
                      },
                      {
                        "text": "failing",
                        "confidence": 0.164,
                        "boundingBox": [
                          2162,
                          930,
                          2673,
                          927,
                          2674,
                          1140,
                          2164,
                          1144
                        ]
                      },
                      {
                        "text": ",",
                        "confidence": 0.164,
                        "boundingBox": [
                          2703,
                          926,
                          2788,
                          926,
                          2790,
                          1139,
                          2705,
                          1140
                        ]
                      }
                    ],
                    "appearance": {
                      "style": {
                        "name": "handwriting",
                        "confidence": 0.855
                      }
                    },
                    "boundingBox": [
                      1612,
                      903,
                      2744,
                      935,
                      2738,
                      1139,
                      1607,
                      1107
                    ]
                  }
                ],
                "width": 600,
                "height": 400,
                "language": "en"
              }
            ]
          },
          "createdDateTime": "2019-10-03T14:32:04.236Z",
          "lastUpdatedDateTime": "2019-10-03T14:38:14.852Z"
        }
      ]
  ReadInStream.ReadInStream:
    description: |-
      Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for your 'GetReadResult' operation to access OCR results.​
    versions:
      from: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.2preview2/readinstream/readinstream
    example:
      inputs: [
        "{binary}"
      ]
      outputs: [
        {}
      ]
  Read.Read:
    description: |-
      Use this interface to get the result of a Read operation, employing the state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read interface, the response contains a field called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for your 'GetReadResult' operation to access OCR results.​
    versions:
      from: 3.1.0
    link: https://docs.microsoft.com/en-us/rest/api/computervision/3.2preview2/read/read
    example:
      inputs: [
        {
          "url": "{url}"
        }
      ]
      outputs: [
        {}
      ]