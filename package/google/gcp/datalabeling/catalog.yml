Product:
  name: GCP Data Labeling
  versions: [1.0.0]
  package: google.gcp.datalabeling
  description: |-
    Data Labeling
  link: https://cloud.google.com/ai-platform/data-labeling
  contentType: json
Operations:
  projects.annotationSpecSets.create:
    description: |-
      Creates an annotation spec set by providing a set of labels.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.annotationSpecSets/create
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1CreateAnnotationSpecSetRequest",
          "type": "object",
          "properties": {
            "annotationSpecSet": {
              "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSet",
              "type": "object",
              "properties": {
                "name": {
                  "type": "string",
                  "description": "Output only. The AnnotationSpecSet resource name in the following format: \"projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}\""
                },
                "description": {
                  "type": "string",
                  "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10,000 characters long."
                },
                "displayName": {
                  "type": "string",
                  "description": "Required. The display name for AnnotationSpecSet that you define when you create it. Maximum of 64 characters."
                },
                "annotationSpecs": {
                  "type": "array",
                  "items": {
                    "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                    "type": "object",
                    "properties": {
                      "index": {
                        "type": "integer",
                        "format": "int32",
                        "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                      },
                      "description": {
                        "type": "string",
                        "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                      },
                      "displayName": {
                        "type": "string",
                        "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                      }
                    },
                    "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                  },
                  "description": "Required. The array of AnnotationSpecs that you define when you create the AnnotationSpecSet. These are the possible labels for the labeling task."
                },
                "blockingResources": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Output only. The names of any related resources that are blocking changes to the annotation spec set."
                }
              },
              "description": "Required. Annotation spec set to create. Annotation specs must be included. Only one annotation spec will be accepted for annotation specs with same display_name."
            }
          },
          "description": "Request message for CreateAnnotationSpecSet."
        }
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSet",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. The AnnotationSpecSet resource name in the following format: \"projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}\""
            },
            "description": {
              "type": "string",
              "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10,000 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "Required. The display name for AnnotationSpecSet that you define when you create it. Maximum of 64 characters."
            },
            "annotationSpecs": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                "type": "object",
                "properties": {
                  "index": {
                    "type": "integer",
                    "format": "int32",
                    "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                  },
                  "description": {
                    "type": "string",
                    "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                  }
                },
                "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
              },
              "description": "Required. The array of AnnotationSpecs that you define when you create the AnnotationSpecSet. These are the possible labels for the labeling task."
            },
            "blockingResources": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Output only. The names of any related resources that are blocking changes to the annotation spec set."
            }
          },
          "description": "An AnnotationSpecSet is a collection of label definitions. For example, in image classification tasks, you define a set of possible labels for images as an AnnotationSpecSet. An AnnotationSpecSet is immutable upon creation."
        }
      ]
  projects.annotationSpecSets.delete:
    description: |-
      Deletes an annotation spec set by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.annotationSpecSets/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.annotationSpecSets.get:
    description: |-
      Gets an annotation spec set by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.annotationSpecSets/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSet",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. The AnnotationSpecSet resource name in the following format: \"projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}\""
            },
            "description": {
              "type": "string",
              "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10,000 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "Required. The display name for AnnotationSpecSet that you define when you create it. Maximum of 64 characters."
            },
            "annotationSpecs": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                "type": "object",
                "properties": {
                  "index": {
                    "type": "integer",
                    "format": "int32",
                    "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                  },
                  "description": {
                    "type": "string",
                    "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                  }
                },
                "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
              },
              "description": "Required. The array of AnnotationSpecs that you define when you create the AnnotationSpecSet. These are the possible labels for the labeling task."
            },
            "blockingResources": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Output only. The names of any related resources that are blocking changes to the annotation spec set."
            }
          },
          "description": "An AnnotationSpecSet is a collection of label definitions. For example, in image classification tasks, you define a set of possible labels for images as an AnnotationSpecSet. An AnnotationSpecSet is immutable upon creation."
        }
      ]
  projects.annotationSpecSets.list:
    description: |-
      Lists annotation spec sets for a project. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.annotationSpecSets/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListAnnotationSpecSetsResponse",
          "type": "object",
          "properties": {
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            },
            "annotationSpecSets": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSet",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. The AnnotationSpecSet resource name in the following format: \"projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}\""
                  },
                  "description": {
                    "type": "string",
                    "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10,000 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "Required. The display name for AnnotationSpecSet that you define when you create it. Maximum of 64 characters."
                  },
                  "annotationSpecs": {
                    "type": "array",
                    "items": {
                      "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                      "type": "object",
                      "properties": {
                        "index": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                        },
                        "description": {
                          "type": "string",
                          "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                        },
                        "displayName": {
                          "type": "string",
                          "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                        }
                      },
                      "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                    },
                    "description": "Required. The array of AnnotationSpecs that you define when you create the AnnotationSpecSet. These are the possible labels for the labeling task."
                  },
                  "blockingResources": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "Output only. The names of any related resources that are blocking changes to the annotation spec set."
                  }
                },
                "description": "An AnnotationSpecSet is a collection of label definitions. For example, in image classification tasks, you define a set of possible labels for images as an AnnotationSpecSet. An AnnotationSpecSet is immutable upon creation."
              },
              "description": "The list of annotation spec sets."
            }
          },
          "description": "Results of listing annotation spec set under a project."
        }
      ]
  projects.datasets.annotatedDatasets.dataItems.get:
    description: |-
      Gets a data item in a dataset by resource name. This API can be called after data are imported into dataset.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.dataItems/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1DataItem",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Name of the data item, in format of: projects/{project_id}/datasets/{dataset_id}/dataItems/{data_item_id}"
            },
            "textPayload": {
              "id": "GoogleCloudDatalabelingV1beta1TextPayload",
              "type": "object",
              "properties": {
                "textContent": {
                  "type": "string",
                  "description": "Text content."
                }
              },
              "description": "The text payload, a container of text content."
            },
            "imagePayload": {
              "id": "GoogleCloudDatalabelingV1beta1ImagePayload",
              "type": "object",
              "properties": {
                "imageUri": {
                  "type": "string",
                  "description": "Image uri from the user bucket."
                },
                "mimeType": {
                  "type": "string",
                  "description": "Image format."
                },
                "signedUri": {
                  "type": "string",
                  "description": "Signed uri of the image file in the service bucket."
                },
                "imageThumbnail": {
                  "type": "string",
                  "format": "byte",
                  "description": "A byte string of a thumbnail image."
                }
              },
              "description": "The image payload, a container of the image bytes/uri."
            },
            "videoPayload": {
              "id": "GoogleCloudDatalabelingV1beta1VideoPayload",
              "type": "object",
              "properties": {
                "mimeType": {
                  "type": "string",
                  "description": "Video format."
                },
                "videoUri": {
                  "type": "string",
                  "description": "Video uri from the user bucket."
                },
                "frameRate": {
                  "type": "number",
                  "format": "float",
                  "description": "FPS of the video."
                },
                "signedUri": {
                  "type": "string",
                  "description": "Signed uri of the video file in the service bucket."
                },
                "videoThumbnails": {
                  "type": "array",
                  "items": {
                    "id": "GoogleCloudDatalabelingV1beta1VideoThumbnail",
                    "type": "object",
                    "properties": {
                      "thumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "A byte string of the video frame."
                      },
                      "timeOffset": {
                        "type": "string",
                        "format": "google-duration",
                        "description": "Time offset relative to the beginning of the video, corresponding to the video frame where the thumbnail has been extracted from."
                      }
                    },
                    "description": "Container of information of a video thumbnail."
                  },
                  "description": "The list of video thumbnails."
                }
              },
              "description": "The video payload, a container of the video uri."
            }
          },
          "description": "DataItem is a piece of data, without annotation. For example, an image."
        }
      ]
  projects.datasets.annotatedDatasets.dataItems.list:
    description: |-
      Lists data items in a dataset. This API can be called after data are imported into dataset. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.dataItems/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListDataItemsResponse",
          "type": "object",
          "properties": {
            "dataItems": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1DataItem",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Name of the data item, in format of: projects/{project_id}/datasets/{dataset_id}/dataItems/{data_item_id}"
                  },
                  "textPayload": {
                    "id": "GoogleCloudDatalabelingV1beta1TextPayload",
                    "type": "object",
                    "properties": {
                      "textContent": {
                        "type": "string",
                        "description": "Text content."
                      }
                    },
                    "description": "The text payload, a container of text content."
                  },
                  "imagePayload": {
                    "id": "GoogleCloudDatalabelingV1beta1ImagePayload",
                    "type": "object",
                    "properties": {
                      "imageUri": {
                        "type": "string",
                        "description": "Image uri from the user bucket."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "Image format."
                      },
                      "signedUri": {
                        "type": "string",
                        "description": "Signed uri of the image file in the service bucket."
                      },
                      "imageThumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "A byte string of a thumbnail image."
                      }
                    },
                    "description": "The image payload, a container of the image bytes/uri."
                  },
                  "videoPayload": {
                    "id": "GoogleCloudDatalabelingV1beta1VideoPayload",
                    "type": "object",
                    "properties": {
                      "mimeType": {
                        "type": "string",
                        "description": "Video format."
                      },
                      "videoUri": {
                        "type": "string",
                        "description": "Video uri from the user bucket."
                      },
                      "frameRate": {
                        "type": "number",
                        "format": "float",
                        "description": "FPS of the video."
                      },
                      "signedUri": {
                        "type": "string",
                        "description": "Signed uri of the video file in the service bucket."
                      },
                      "videoThumbnails": {
                        "type": "array",
                        "items": {
                          "id": "GoogleCloudDatalabelingV1beta1VideoThumbnail",
                          "type": "object",
                          "properties": {
                            "thumbnail": {
                              "type": "string",
                              "format": "byte",
                              "description": "A byte string of the video frame."
                            },
                            "timeOffset": {
                              "type": "string",
                              "format": "google-duration",
                              "description": "Time offset relative to the beginning of the video, corresponding to the video frame where the thumbnail has been extracted from."
                            }
                          },
                          "description": "Container of information of a video thumbnail."
                        },
                        "description": "The list of video thumbnails."
                      }
                    },
                    "description": "The video payload, a container of the video uri."
                  }
                },
                "description": "DataItem is a piece of data, without annotation. For example, an image."
              },
              "description": "The list of data items to return."
            },
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            }
          },
          "description": "Results of listing data items in a dataset."
        }
      ]
  projects.datasets.annotatedDatasets.delete:
    description: |-
      Deletes an annotated dataset by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.datasets.annotatedDatasets.examples.get:
    description: |-
      Gets an example by resource name, including both data and annotation.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.examples/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1Example",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Name of the example, in format of: projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/ {annotated_dataset_id}/examples/{example_id}"
            },
            "annotations": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1Annotation",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Unique name of this annotation, format is: projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset}/examples/{example_id}/annotations/{annotation_id}"
                  },
                  "annotationValue": {
                    "id": "GoogleCloudDatalabelingV1beta1AnnotationValue",
                    "type": "object",
                    "properties": {
                      "videoEventAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1VideoEventAnnotation",
                        "type": "object",
                        "properties": {
                          "timeSegment": {
                            "id": "GoogleCloudDatalabelingV1beta1TimeSegment",
                            "type": "object",
                            "properties": {
                              "endTimeOffset": {
                                "type": "string",
                                "format": "google-duration",
                                "description": "End of the time segment (exclusive), represented as the duration since the example start."
                              },
                              "startTimeOffset": {
                                "type": "string",
                                "format": "google-duration",
                                "description": "Start of the time segment (inclusive), represented as the duration since the example start."
                              }
                            },
                            "description": "The time segment of the video to which the annotation applies."
                          },
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          }
                        },
                        "description": "Annotation value for video event case."
                      },
                      "imagePolylineAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1ImagePolylineAnnotation",
                        "type": "object",
                        "properties": {
                          "polyline": {
                            "id": "GoogleCloudDatalabelingV1beta1Polyline",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The polyline vertices."
                              }
                            },
                            "description": "A line with multiple line segments."
                          },
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          },
                          "normalizedPolyline": {
                            "id": "GoogleCloudDatalabelingV1beta1NormalizedPolyline",
                            "type": "object",
                            "properties": {
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The normalized polyline vertices."
                              }
                            },
                            "description": "Normalized polyline."
                          }
                        },
                        "description": "Annotation value for image polyline cases. Polyline here is different from BoundingPoly. It is formed by line segments connected to each other but not closed form(Bounding Poly). The line segments can cross each other."
                      },
                      "imageBoundingPolyAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1ImageBoundingPolyAnnotation",
                        "type": "object",
                        "properties": {
                          "boundingPoly": {
                            "id": "GoogleCloudDatalabelingV1beta1BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              }
                            },
                            "description": "A bounding polygon in the image."
                          },
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          },
                          "normalizedBoundingPoly": {
                            "id": "GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly",
                            "type": "object",
                            "properties": {
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "Normalized bounding polygon."
                          }
                        },
                        "description": "Annotation value for image bounding box, oriented bounding box and polygon cases."
                      },
                      "imageSegmentationAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation",
                        "type": "object",
                        "properties": {
                          "mimeType": {
                            "type": "string",
                            "description": "Image format."
                          },
                          "imageBytes": {
                            "type": "string",
                            "format": "byte",
                            "description": "A byte string of a full image's color map."
                          },
                          "annotationColors": {
                            "type": "object",
                            "description": "The mapping between rgb color and annotation spec. The key is the rgb color represented in format of rgb(0, 0, 0). The value is the AnnotationSpec.",
                            "additionalProperties": {
                              "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                              "type": "object",
                              "properties": {
                                "index": {
                                  "type": "integer",
                                  "format": "int32",
                                  "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                },
                                "description": {
                                  "type": "string",
                                  "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                },
                                "displayName": {
                                  "type": "string",
                                  "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                }
                              },
                              "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                            }
                          }
                        },
                        "description": "Annotation value for image segmentation."
                      },
                      "textClassificationAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1TextClassificationAnnotation",
                        "type": "object",
                        "properties": {
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          }
                        },
                        "description": "Annotation value for text classification case."
                      },
                      "imageClassificationAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1ImageClassificationAnnotation",
                        "type": "object",
                        "properties": {
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          }
                        },
                        "description": "Annotation value for image classification case."
                      },
                      "videoClassificationAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1VideoClassificationAnnotation",
                        "type": "object",
                        "properties": {
                          "timeSegment": {
                            "id": "GoogleCloudDatalabelingV1beta1TimeSegment",
                            "type": "object",
                            "properties": {
                              "endTimeOffset": {
                                "type": "string",
                                "format": "google-duration",
                                "description": "End of the time segment (exclusive), represented as the duration since the example start."
                              },
                              "startTimeOffset": {
                                "type": "string",
                                "format": "google-duration",
                                "description": "Start of the time segment (inclusive), represented as the duration since the example start."
                              }
                            },
                            "description": "The time segment of the video to which the annotation applies."
                          },
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          }
                        },
                        "description": "Annotation value for video classification case."
                      },
                      "videoObjectTrackingAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1VideoObjectTrackingAnnotation",
                        "type": "object",
                        "properties": {
                          "timeSegment": {
                            "id": "GoogleCloudDatalabelingV1beta1TimeSegment",
                            "type": "object",
                            "properties": {
                              "endTimeOffset": {
                                "type": "string",
                                "format": "google-duration",
                                "description": "End of the time segment (exclusive), represented as the duration since the example start."
                              },
                              "startTimeOffset": {
                                "type": "string",
                                "format": "google-duration",
                                "description": "Start of the time segment (inclusive), represented as the duration since the example start."
                              }
                            },
                            "description": "The time segment of the video to which object tracking applies."
                          },
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          },
                          "objectTrackingFrames": {
                            "type": "array",
                            "items": {
                              "id": "GoogleCloudDatalabelingV1beta1ObjectTrackingFrame",
                              "type": "object",
                              "properties": {
                                "timeOffset": {
                                  "type": "string",
                                  "format": "google-duration",
                                  "description": "The time offset of this frame relative to the beginning of the video."
                                },
                                "boundingPoly": {
                                  "id": "GoogleCloudDatalabelingV1beta1BoundingPoly",
                                  "type": "object",
                                  "properties": {
                                    "vertices": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1Vertex",
                                        "type": "object",
                                        "properties": {
                                          "x": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "X coordinate."
                                          },
                                          "y": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "Y coordinate."
                                          }
                                        },
                                        "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                      },
                                      "description": "The bounding polygon vertices."
                                    }
                                  },
                                  "description": "A bounding polygon in the image."
                                },
                                "normalizedBoundingPoly": {
                                  "id": "GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly",
                                  "type": "object",
                                  "properties": {
                                    "normalizedVertices": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1NormalizedVertex",
                                        "type": "object",
                                        "properties": {
                                          "x": {
                                            "type": "number",
                                            "format": "float",
                                            "description": "X coordinate."
                                          },
                                          "y": {
                                            "type": "number",
                                            "format": "float",
                                            "description": "Y coordinate."
                                          }
                                        },
                                        "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                      },
                                      "description": "The bounding polygon normalized vertices."
                                    }
                                  },
                                  "description": "Normalized bounding polygon."
                                }
                              },
                              "description": "Video frame level annotation for object detection and tracking."
                            },
                            "description": "The list of frames where this object track appears."
                          }
                        },
                        "description": "Annotation value for video object detection and tracking case."
                      },
                      "textEntityExtractionAnnotation": {
                        "id": "GoogleCloudDatalabelingV1beta1TextEntityExtractionAnnotation",
                        "type": "object",
                        "properties": {
                          "annotationSpec": {
                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                            "type": "object",
                            "properties": {
                              "index": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                              },
                              "description": {
                                "type": "string",
                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                              },
                              "displayName": {
                                "type": "string",
                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                              }
                            },
                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                          },
                          "sequentialSegment": {
                            "id": "GoogleCloudDatalabelingV1beta1SequentialSegment",
                            "type": "object",
                            "properties": {
                              "end": {
                                "type": "integer",
                                "format": "int32",
                                "description": "End position (exclusive)."
                              },
                              "start": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Start position (inclusive)."
                              }
                            },
                            "description": "Position of the entity."
                          }
                        },
                        "description": "Annotation value for text entity extraction case."
                      }
                    },
                    "description": "Output only. This is the actual annotation value, e.g classification, bounding box values are stored here."
                  },
                  "annotationSource": {
                    "enum": [
                      "ANNOTATION_SOURCE_UNSPECIFIED",
                      "OPERATOR"
                    ],
                    "type": "string",
                    "description": "Output only. The source of the annotation.",
                    "enumDescriptions": [
                      "",
                      "Answer is provided by a human contributor."
                    ]
                  },
                  "annotationMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1AnnotationMetadata",
                    "type": "object",
                    "properties": {
                      "operatorMetadata": {
                        "id": "GoogleCloudDatalabelingV1beta1OperatorMetadata",
                        "type": "object",
                        "properties": {
                          "score": {
                            "type": "number",
                            "format": "float",
                            "description": "Confidence score corresponding to a label. For examle, if 3 contributors have answered the question and 2 of them agree on the final label, the confidence score will be 0.67 (2/3)."
                          },
                          "comments": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "Comments from contributors."
                          },
                          "labelVotes": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The total number of contributors that choose this label."
                          },
                          "totalVotes": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The total number of contributors that answer this question."
                          }
                        },
                        "description": "Metadata related to human labeling."
                      }
                    },
                    "description": "Output only. Annotation metadata, including information like votes for labels."
                  },
                  "annotationSentiment": {
                    "enum": [
                      "ANNOTATION_SENTIMENT_UNSPECIFIED",
                      "NEGATIVE",
                      "POSITIVE"
                    ],
                    "type": "string",
                    "description": "Output only. Sentiment for this annotation.",
                    "enumDescriptions": [
                      "",
                      "This annotation describes negatively about the data.",
                      "This label describes positively about the data."
                    ]
                  }
                },
                "description": "Annotation for Example. Each example may have one or more annotations. For example in image classification problem, each image might have one or more labels. We call labels binded with this image an Annotation."
              },
              "description": "Output only. Annotations for the piece of data in Example. One piece of data can have multiple annotations."
            },
            "textPayload": {
              "id": "GoogleCloudDatalabelingV1beta1TextPayload",
              "type": "object",
              "properties": {
                "textContent": {
                  "type": "string",
                  "description": "Text content."
                }
              },
              "description": "The text payload, a container of the text content."
            },
            "imagePayload": {
              "id": "GoogleCloudDatalabelingV1beta1ImagePayload",
              "type": "object",
              "properties": {
                "imageUri": {
                  "type": "string",
                  "description": "Image uri from the user bucket."
                },
                "mimeType": {
                  "type": "string",
                  "description": "Image format."
                },
                "signedUri": {
                  "type": "string",
                  "description": "Signed uri of the image file in the service bucket."
                },
                "imageThumbnail": {
                  "type": "string",
                  "format": "byte",
                  "description": "A byte string of a thumbnail image."
                }
              },
              "description": "The image payload, a container of the image bytes/uri."
            },
            "videoPayload": {
              "id": "GoogleCloudDatalabelingV1beta1VideoPayload",
              "type": "object",
              "properties": {
                "mimeType": {
                  "type": "string",
                  "description": "Video format."
                },
                "videoUri": {
                  "type": "string",
                  "description": "Video uri from the user bucket."
                },
                "frameRate": {
                  "type": "number",
                  "format": "float",
                  "description": "FPS of the video."
                },
                "signedUri": {
                  "type": "string",
                  "description": "Signed uri of the video file in the service bucket."
                },
                "videoThumbnails": {
                  "type": "array",
                  "items": {
                    "id": "GoogleCloudDatalabelingV1beta1VideoThumbnail",
                    "type": "object",
                    "properties": {
                      "thumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "A byte string of the video frame."
                      },
                      "timeOffset": {
                        "type": "string",
                        "format": "google-duration",
                        "description": "Time offset relative to the beginning of the video, corresponding to the video frame where the thumbnail has been extracted from."
                      }
                    },
                    "description": "Container of information of a video thumbnail."
                  },
                  "description": "The list of video thumbnails."
                }
              },
              "description": "The video payload, a container of the video uri."
            }
          },
          "description": "An Example is a piece of data and its annotation. For example, an image with label \"house\"."
        }
      ]
  projects.datasets.annotatedDatasets.examples.list:
    description: |-
      Lists examples in an annotated dataset. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.examples/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListExamplesResponse",
          "type": "object",
          "properties": {
            "examples": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1Example",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Name of the example, in format of: projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/ {annotated_dataset_id}/examples/{example_id}"
                  },
                  "annotations": {
                    "type": "array",
                    "items": {
                      "id": "GoogleCloudDatalabelingV1beta1Annotation",
                      "type": "object",
                      "properties": {
                        "name": {
                          "type": "string",
                          "description": "Output only. Unique name of this annotation, format is: projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset}/examples/{example_id}/annotations/{annotation_id}"
                        },
                        "annotationValue": {
                          "id": "GoogleCloudDatalabelingV1beta1AnnotationValue",
                          "type": "object",
                          "properties": {
                            "videoEventAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1VideoEventAnnotation",
                              "type": "object",
                              "properties": {
                                "timeSegment": {
                                  "id": "GoogleCloudDatalabelingV1beta1TimeSegment",
                                  "type": "object",
                                  "properties": {
                                    "endTimeOffset": {
                                      "type": "string",
                                      "format": "google-duration",
                                      "description": "End of the time segment (exclusive), represented as the duration since the example start."
                                    },
                                    "startTimeOffset": {
                                      "type": "string",
                                      "format": "google-duration",
                                      "description": "Start of the time segment (inclusive), represented as the duration since the example start."
                                    }
                                  },
                                  "description": "The time segment of the video to which the annotation applies."
                                },
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                }
                              },
                              "description": "Annotation value for video event case."
                            },
                            "imagePolylineAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1ImagePolylineAnnotation",
                              "type": "object",
                              "properties": {
                                "polyline": {
                                  "id": "GoogleCloudDatalabelingV1beta1Polyline",
                                  "type": "object",
                                  "properties": {
                                    "vertices": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1Vertex",
                                        "type": "object",
                                        "properties": {
                                          "x": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "X coordinate."
                                          },
                                          "y": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "Y coordinate."
                                          }
                                        },
                                        "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                      },
                                      "description": "The polyline vertices."
                                    }
                                  },
                                  "description": "A line with multiple line segments."
                                },
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                },
                                "normalizedPolyline": {
                                  "id": "GoogleCloudDatalabelingV1beta1NormalizedPolyline",
                                  "type": "object",
                                  "properties": {
                                    "normalizedVertices": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1NormalizedVertex",
                                        "type": "object",
                                        "properties": {
                                          "x": {
                                            "type": "number",
                                            "format": "float",
                                            "description": "X coordinate."
                                          },
                                          "y": {
                                            "type": "number",
                                            "format": "float",
                                            "description": "Y coordinate."
                                          }
                                        },
                                        "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                      },
                                      "description": "The normalized polyline vertices."
                                    }
                                  },
                                  "description": "Normalized polyline."
                                }
                              },
                              "description": "Annotation value for image polyline cases. Polyline here is different from BoundingPoly. It is formed by line segments connected to each other but not closed form(Bounding Poly). The line segments can cross each other."
                            },
                            "imageBoundingPolyAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1ImageBoundingPolyAnnotation",
                              "type": "object",
                              "properties": {
                                "boundingPoly": {
                                  "id": "GoogleCloudDatalabelingV1beta1BoundingPoly",
                                  "type": "object",
                                  "properties": {
                                    "vertices": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1Vertex",
                                        "type": "object",
                                        "properties": {
                                          "x": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "X coordinate."
                                          },
                                          "y": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "Y coordinate."
                                          }
                                        },
                                        "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                      },
                                      "description": "The bounding polygon vertices."
                                    }
                                  },
                                  "description": "A bounding polygon in the image."
                                },
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                },
                                "normalizedBoundingPoly": {
                                  "id": "GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly",
                                  "type": "object",
                                  "properties": {
                                    "normalizedVertices": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1NormalizedVertex",
                                        "type": "object",
                                        "properties": {
                                          "x": {
                                            "type": "number",
                                            "format": "float",
                                            "description": "X coordinate."
                                          },
                                          "y": {
                                            "type": "number",
                                            "format": "float",
                                            "description": "Y coordinate."
                                          }
                                        },
                                        "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                      },
                                      "description": "The bounding polygon normalized vertices."
                                    }
                                  },
                                  "description": "Normalized bounding polygon."
                                }
                              },
                              "description": "Annotation value for image bounding box, oriented bounding box and polygon cases."
                            },
                            "imageSegmentationAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1ImageSegmentationAnnotation",
                              "type": "object",
                              "properties": {
                                "mimeType": {
                                  "type": "string",
                                  "description": "Image format."
                                },
                                "imageBytes": {
                                  "type": "string",
                                  "format": "byte",
                                  "description": "A byte string of a full image's color map."
                                },
                                "annotationColors": {
                                  "type": "object",
                                  "description": "The mapping between rgb color and annotation spec. The key is the rgb color represented in format of rgb(0, 0, 0). The value is the AnnotationSpec.",
                                  "additionalProperties": {
                                    "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                    "type": "object",
                                    "properties": {
                                      "index": {
                                        "type": "integer",
                                        "format": "int32",
                                        "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                      },
                                      "description": {
                                        "type": "string",
                                        "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                      },
                                      "displayName": {
                                        "type": "string",
                                        "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                      }
                                    },
                                    "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                  }
                                }
                              },
                              "description": "Annotation value for image segmentation."
                            },
                            "textClassificationAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1TextClassificationAnnotation",
                              "type": "object",
                              "properties": {
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                }
                              },
                              "description": "Annotation value for text classification case."
                            },
                            "imageClassificationAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1ImageClassificationAnnotation",
                              "type": "object",
                              "properties": {
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                }
                              },
                              "description": "Annotation value for image classification case."
                            },
                            "videoClassificationAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1VideoClassificationAnnotation",
                              "type": "object",
                              "properties": {
                                "timeSegment": {
                                  "id": "GoogleCloudDatalabelingV1beta1TimeSegment",
                                  "type": "object",
                                  "properties": {
                                    "endTimeOffset": {
                                      "type": "string",
                                      "format": "google-duration",
                                      "description": "End of the time segment (exclusive), represented as the duration since the example start."
                                    },
                                    "startTimeOffset": {
                                      "type": "string",
                                      "format": "google-duration",
                                      "description": "Start of the time segment (inclusive), represented as the duration since the example start."
                                    }
                                  },
                                  "description": "The time segment of the video to which the annotation applies."
                                },
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                }
                              },
                              "description": "Annotation value for video classification case."
                            },
                            "videoObjectTrackingAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1VideoObjectTrackingAnnotation",
                              "type": "object",
                              "properties": {
                                "timeSegment": {
                                  "id": "GoogleCloudDatalabelingV1beta1TimeSegment",
                                  "type": "object",
                                  "properties": {
                                    "endTimeOffset": {
                                      "type": "string",
                                      "format": "google-duration",
                                      "description": "End of the time segment (exclusive), represented as the duration since the example start."
                                    },
                                    "startTimeOffset": {
                                      "type": "string",
                                      "format": "google-duration",
                                      "description": "Start of the time segment (inclusive), represented as the duration since the example start."
                                    }
                                  },
                                  "description": "The time segment of the video to which object tracking applies."
                                },
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                },
                                "objectTrackingFrames": {
                                  "type": "array",
                                  "items": {
                                    "id": "GoogleCloudDatalabelingV1beta1ObjectTrackingFrame",
                                    "type": "object",
                                    "properties": {
                                      "timeOffset": {
                                        "type": "string",
                                        "format": "google-duration",
                                        "description": "The time offset of this frame relative to the beginning of the video."
                                      },
                                      "boundingPoly": {
                                        "id": "GoogleCloudDatalabelingV1beta1BoundingPoly",
                                        "type": "object",
                                        "properties": {
                                          "vertices": {
                                            "type": "array",
                                            "items": {
                                              "id": "GoogleCloudDatalabelingV1beta1Vertex",
                                              "type": "object",
                                              "properties": {
                                                "x": {
                                                  "type": "integer",
                                                  "format": "int32",
                                                  "description": "X coordinate."
                                                },
                                                "y": {
                                                  "type": "integer",
                                                  "format": "int32",
                                                  "description": "Y coordinate."
                                                }
                                              },
                                              "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                            },
                                            "description": "The bounding polygon vertices."
                                          }
                                        },
                                        "description": "A bounding polygon in the image."
                                      },
                                      "normalizedBoundingPoly": {
                                        "id": "GoogleCloudDatalabelingV1beta1NormalizedBoundingPoly",
                                        "type": "object",
                                        "properties": {
                                          "normalizedVertices": {
                                            "type": "array",
                                            "items": {
                                              "id": "GoogleCloudDatalabelingV1beta1NormalizedVertex",
                                              "type": "object",
                                              "properties": {
                                                "x": {
                                                  "type": "number",
                                                  "format": "float",
                                                  "description": "X coordinate."
                                                },
                                                "y": {
                                                  "type": "number",
                                                  "format": "float",
                                                  "description": "Y coordinate."
                                                }
                                              },
                                              "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                            },
                                            "description": "The bounding polygon normalized vertices."
                                          }
                                        },
                                        "description": "Normalized bounding polygon."
                                      }
                                    },
                                    "description": "Video frame level annotation for object detection and tracking."
                                  },
                                  "description": "The list of frames where this object track appears."
                                }
                              },
                              "description": "Annotation value for video object detection and tracking case."
                            },
                            "textEntityExtractionAnnotation": {
                              "id": "GoogleCloudDatalabelingV1beta1TextEntityExtractionAnnotation",
                              "type": "object",
                              "properties": {
                                "annotationSpec": {
                                  "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                  "type": "object",
                                  "properties": {
                                    "index": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                    },
                                    "description": {
                                      "type": "string",
                                      "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                    },
                                    "displayName": {
                                      "type": "string",
                                      "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                    }
                                  },
                                  "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                },
                                "sequentialSegment": {
                                  "id": "GoogleCloudDatalabelingV1beta1SequentialSegment",
                                  "type": "object",
                                  "properties": {
                                    "end": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "End position (exclusive)."
                                    },
                                    "start": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Start position (inclusive)."
                                    }
                                  },
                                  "description": "Position of the entity."
                                }
                              },
                              "description": "Annotation value for text entity extraction case."
                            }
                          },
                          "description": "Output only. This is the actual annotation value, e.g classification, bounding box values are stored here."
                        },
                        "annotationSource": {
                          "enum": [
                            "ANNOTATION_SOURCE_UNSPECIFIED",
                            "OPERATOR"
                          ],
                          "type": "string",
                          "description": "Output only. The source of the annotation.",
                          "enumDescriptions": [
                            "",
                            "Answer is provided by a human contributor."
                          ]
                        },
                        "annotationMetadata": {
                          "id": "GoogleCloudDatalabelingV1beta1AnnotationMetadata",
                          "type": "object",
                          "properties": {
                            "operatorMetadata": {
                              "id": "GoogleCloudDatalabelingV1beta1OperatorMetadata",
                              "type": "object",
                              "properties": {
                                "score": {
                                  "type": "number",
                                  "format": "float",
                                  "description": "Confidence score corresponding to a label. For examle, if 3 contributors have answered the question and 2 of them agree on the final label, the confidence score will be 0.67 (2/3)."
                                },
                                "comments": {
                                  "type": "array",
                                  "items": {
                                    "type": "string"
                                  },
                                  "description": "Comments from contributors."
                                },
                                "labelVotes": {
                                  "type": "integer",
                                  "format": "int32",
                                  "description": "The total number of contributors that choose this label."
                                },
                                "totalVotes": {
                                  "type": "integer",
                                  "format": "int32",
                                  "description": "The total number of contributors that answer this question."
                                }
                              },
                              "description": "Metadata related to human labeling."
                            }
                          },
                          "description": "Output only. Annotation metadata, including information like votes for labels."
                        },
                        "annotationSentiment": {
                          "enum": [
                            "ANNOTATION_SENTIMENT_UNSPECIFIED",
                            "NEGATIVE",
                            "POSITIVE"
                          ],
                          "type": "string",
                          "description": "Output only. Sentiment for this annotation.",
                          "enumDescriptions": [
                            "",
                            "This annotation describes negatively about the data.",
                            "This label describes positively about the data."
                          ]
                        }
                      },
                      "description": "Annotation for Example. Each example may have one or more annotations. For example in image classification problem, each image might have one or more labels. We call labels binded with this image an Annotation."
                    },
                    "description": "Output only. Annotations for the piece of data in Example. One piece of data can have multiple annotations."
                  },
                  "textPayload": {
                    "id": "GoogleCloudDatalabelingV1beta1TextPayload",
                    "type": "object",
                    "properties": {
                      "textContent": {
                        "type": "string",
                        "description": "Text content."
                      }
                    },
                    "description": "The text payload, a container of the text content."
                  },
                  "imagePayload": {
                    "id": "GoogleCloudDatalabelingV1beta1ImagePayload",
                    "type": "object",
                    "properties": {
                      "imageUri": {
                        "type": "string",
                        "description": "Image uri from the user bucket."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "Image format."
                      },
                      "signedUri": {
                        "type": "string",
                        "description": "Signed uri of the image file in the service bucket."
                      },
                      "imageThumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "A byte string of a thumbnail image."
                      }
                    },
                    "description": "The image payload, a container of the image bytes/uri."
                  },
                  "videoPayload": {
                    "id": "GoogleCloudDatalabelingV1beta1VideoPayload",
                    "type": "object",
                    "properties": {
                      "mimeType": {
                        "type": "string",
                        "description": "Video format."
                      },
                      "videoUri": {
                        "type": "string",
                        "description": "Video uri from the user bucket."
                      },
                      "frameRate": {
                        "type": "number",
                        "format": "float",
                        "description": "FPS of the video."
                      },
                      "signedUri": {
                        "type": "string",
                        "description": "Signed uri of the video file in the service bucket."
                      },
                      "videoThumbnails": {
                        "type": "array",
                        "items": {
                          "id": "GoogleCloudDatalabelingV1beta1VideoThumbnail",
                          "type": "object",
                          "properties": {
                            "thumbnail": {
                              "type": "string",
                              "format": "byte",
                              "description": "A byte string of the video frame."
                            },
                            "timeOffset": {
                              "type": "string",
                              "format": "google-duration",
                              "description": "Time offset relative to the beginning of the video, corresponding to the video frame where the thumbnail has been extracted from."
                            }
                          },
                          "description": "Container of information of a video thumbnail."
                        },
                        "description": "The list of video thumbnails."
                      }
                    },
                    "description": "The video payload, a container of the video uri."
                  }
                },
                "description": "An Example is a piece of data and its annotation. For example, an image with label \"house\"."
              },
              "description": "The list of examples to return."
            },
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            }
          },
          "description": "Results of listing Examples in and annotated dataset."
        }
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.delete:
    description: |-
      Delete a FeedbackThread.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages.create:
    description: |-
      Create a FeedbackMessage object.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages/create
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1FeedbackMessage",
          "type": "object",
          "properties": {
            "body": {
              "type": "string",
              "description": "String content of the feedback. Maximum of 10000 characters."
            },
            "name": {
              "type": "string",
              "description": "Name of the feedback message in a feedback thread. Format: 'project/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset_id}/feedbackThreads/{feedback_thread_id}/feedbackMessage/{feedback_message_id}'"
            },
            "image": {
              "type": "string",
              "format": "byte",
              "description": "The image storing this feedback if the feedback is an image representing operator's comments."
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Create time."
            },
            "operatorFeedbackMetadata": {
              "id": "GoogleCloudDatalabelingV1beta1OperatorFeedbackMetadata",
              "type": "object",
              "properties": {},
              "description": "Metadata describing the feedback from the operator."
            },
            "requesterFeedbackMetadata": {
              "id": "GoogleCloudDatalabelingV1beta1RequesterFeedbackMetadata",
              "type": "object",
              "properties": {},
              "description": "Metadata describing the feedback from the labeling task requester."
            }
          },
          "description": "A feedback message inside a feedback thread."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages.delete:
    description: |-
      Delete a FeedbackMessage.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages.get:
    description: |-
      Get a FeedbackMessage object.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages.list:
    description: |-
      List FeedbackMessages with pagination.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads.feedbackMessages/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListFeedbackMessagesResponse",
          "type": "object",
          "properties": {
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            },
            "feedbackMessages": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1FeedbackMessage",
                "type": "object",
                "properties": {
                  "body": {
                    "type": "string",
                    "description": "String content of the feedback. Maximum of 10000 characters."
                  },
                  "name": {
                    "type": "string",
                    "description": "Name of the feedback message in a feedback thread. Format: 'project/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset_id}/feedbackThreads/{feedback_thread_id}/feedbackMessage/{feedback_message_id}'"
                  },
                  "image": {
                    "type": "string",
                    "format": "byte",
                    "description": "The image storing this feedback if the feedback is an image representing operator's comments."
                  },
                  "createTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Create time."
                  },
                  "operatorFeedbackMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1OperatorFeedbackMetadata",
                    "type": "object",
                    "properties": {},
                    "description": "Metadata describing the feedback from the operator."
                  },
                  "requesterFeedbackMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1RequesterFeedbackMetadata",
                    "type": "object",
                    "properties": {},
                    "description": "Metadata describing the feedback from the labeling task requester."
                  }
                },
                "description": "A feedback message inside a feedback thread."
              },
              "description": "The list of feedback messages to return."
            }
          },
          "description": "Results for listing FeedbackMessages."
        }
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.get:
    description: |-
      Get a FeedbackThread object.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1FeedbackThread",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Name of the feedback thread. Format: 'project/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset_id}/feedbackThreads/{feedback_thread_id}'"
            },
            "feedbackThreadMetadata": {
              "id": "GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata",
              "type": "object",
              "properties": {
                "status": {
                  "enum": [
                    "FEEDBACK_THREAD_STATUS_UNSPECIFIED",
                    "NEW",
                    "REPLIED"
                  ],
                  "type": "string",
                  "enumDescriptions": [
                    "",
                    "Feedback thread is created with no reply;",
                    "Feedback thread is replied at least once;"
                  ]
                },
                "thumbnail": {
                  "type": "string",
                  "format": "byte",
                  "description": "An image thumbnail of this thread."
                },
                "createTime": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the thread is created"
                },
                "lastUpdateTime": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the thread is last updated."
                }
              },
              "description": "Metadata regarding the feedback thread."
            }
          },
          "description": "A feedback thread of a certain labeling task on a certain annotated dataset."
        }
      ]
  projects.datasets.annotatedDatasets.feedbackThreads.list:
    description: |-
      List FeedbackThreads with pagination.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets.feedbackThreads/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListFeedbackThreadsResponse",
          "type": "object",
          "properties": {
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            },
            "feedbackThreads": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1FeedbackThread",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Name of the feedback thread. Format: 'project/{project_id}/datasets/{dataset_id}/annotatedDatasets/{annotated_dataset_id}/feedbackThreads/{feedback_thread_id}'"
                  },
                  "feedbackThreadMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1FeedbackThreadMetadata",
                    "type": "object",
                    "properties": {
                      "status": {
                        "enum": [
                          "FEEDBACK_THREAD_STATUS_UNSPECIFIED",
                          "NEW",
                          "REPLIED"
                        ],
                        "type": "string",
                        "enumDescriptions": [
                          "",
                          "Feedback thread is created with no reply;",
                          "Feedback thread is replied at least once;"
                        ]
                      },
                      "thumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "An image thumbnail of this thread."
                      },
                      "createTime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "When the thread is created"
                      },
                      "lastUpdateTime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "When the thread is last updated."
                      }
                    },
                    "description": "Metadata regarding the feedback thread."
                  }
                },
                "description": "A feedback thread of a certain labeling task on a certain annotated dataset."
              },
              "description": "The list of feedback threads to return."
            }
          },
          "description": "Results for listing FeedbackThreads."
        }
      ]
  projects.datasets.annotatedDatasets.get:
    description: |-
      Gets an annotated dataset by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1AnnotatedDataset",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. AnnotatedDataset resource name in format of: projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/ {annotated_dataset_id}"
            },
            "metadata": {
              "id": "GoogleCloudDatalabelingV1beta1AnnotatedDatasetMetadata",
              "type": "object",
              "properties": {
                "eventConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1EventConfig",
                  "type": "object",
                  "properties": {
                    "clipLength": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 60s."
                    },
                    "overlapLength": {
                      "type": "integer",
                      "format": "int32",
                      "description": "The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 1s."
                    },
                    "annotationSpecSets": {
                      "type": "array",
                      "items": {
                        "type": "string"
                      },
                      "description": "Required. The list of annotation spec set resource name. Similar to video classification, we support selecting event from multiple AnnotationSpecSet at the same time."
                    }
                  },
                  "description": "Configuration for video event labeling task."
                },
                "polylineConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1PolylineConfig",
                  "type": "object",
                  "properties": {
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    },
                    "instructionMessage": {
                      "type": "string",
                      "description": "Optional. Instruction message showed on contributors UI."
                    }
                  },
                  "description": "Configuration for image polyline task."
                },
                "boundingPolyConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1BoundingPolyConfig",
                  "type": "object",
                  "properties": {
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    },
                    "instructionMessage": {
                      "type": "string",
                      "description": "Optional. Instruction message showed on contributors UI."
                    }
                  },
                  "description": "Configuration for image bounding box and bounding poly task."
                },
                "segmentationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1SegmentationConfig",
                  "type": "object",
                  "properties": {
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name. format: projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}"
                    },
                    "instructionMessage": {
                      "type": "string",
                      "description": "Instruction message showed on labelers UI."
                    }
                  },
                  "description": "Configuration for image segmentation task."
                },
                "objectTrackingConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1ObjectTrackingConfig",
                  "type": "object",
                  "properties": {
                    "clipLength": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 20s."
                    },
                    "overlapLength": {
                      "type": "integer",
                      "format": "int32",
                      "description": "The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 0.3s."
                    },
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    }
                  },
                  "description": "Configuration for video object tracking task."
                },
                "humanAnnotationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
                  "type": "object",
                  "properties": {
                    "labelGroup": {
                      "type": "string",
                      "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                    },
                    "instruction": {
                      "type": "string",
                      "description": "Required. Instruction resource name."
                    },
                    "languageCode": {
                      "type": "string",
                      "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                    },
                    "replicaCount": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                    },
                    "questionDuration": {
                      "type": "string",
                      "format": "google-duration",
                      "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                    },
                    "userEmailAddress": {
                      "type": "string",
                      "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                    },
                    "contributorEmails": {
                      "type": "array",
                      "items": {
                        "type": "string"
                      },
                      "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                    },
                    "annotatedDatasetDescription": {
                      "type": "string",
                      "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                    },
                    "annotatedDatasetDisplayName": {
                      "type": "string",
                      "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                    }
                  },
                  "description": "HumanAnnotationConfig used when requesting the human labeling task for this AnnotatedDataset."
                },
                "objectDetectionConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1ObjectDetectionConfig",
                  "type": "object",
                  "properties": {
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    },
                    "extractionFrameRate": {
                      "type": "number",
                      "format": "double",
                      "description": "Required. Number of frames per second to be extracted from the video."
                    }
                  },
                  "description": "Configuration for video object detection task."
                },
                "textClassificationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1TextClassificationConfig",
                  "type": "object",
                  "properties": {
                    "allowMultiLabel": {
                      "type": "boolean",
                      "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one text segment."
                    },
                    "sentimentConfig": {
                      "id": "GoogleCloudDatalabelingV1beta1SentimentConfig",
                      "type": "object",
                      "properties": {
                        "enableLabelSentimentSelection": {
                          "type": "boolean",
                          "description": "If set to true, contributors will have the option to select sentiment of the label they selected, to mark it as negative or positive label. Default is false."
                        }
                      },
                      "description": "Optional. Configs for sentiment selection. We deprecate sentiment analysis in data labeling side as it is incompatible with uCAIP."
                    },
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    }
                  },
                  "description": "Configuration for text classification task."
                },
                "imageClassificationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1ImageClassificationConfig",
                  "type": "object",
                  "properties": {
                    "allowMultiLabel": {
                      "type": "boolean",
                      "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one image."
                    },
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    },
                    "answerAggregationType": {
                      "enum": [
                        "STRING_AGGREGATION_TYPE_UNSPECIFIED",
                        "MAJORITY_VOTE",
                        "UNANIMOUS_VOTE",
                        "NO_AGGREGATION"
                      ],
                      "type": "string",
                      "description": "Optional. The type of how to aggregate answers.",
                      "enumDescriptions": [
                        "",
                        "Majority vote to aggregate answers.",
                        "Unanimous answers will be adopted.",
                        "Preserve all answers by crowd compute."
                      ]
                    }
                  },
                  "description": "Configuration for image classification task."
                },
                "videoClassificationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1VideoClassificationConfig",
                  "type": "object",
                  "properties": {
                    "applyShotDetection": {
                      "type": "boolean",
                      "description": "Optional. Option to apply shot detection on the video."
                    },
                    "annotationSpecSetConfigs": {
                      "type": "array",
                      "items": {
                        "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSetConfig",
                        "type": "object",
                        "properties": {
                          "allowMultiLabel": {
                            "type": "boolean",
                            "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels from one annotation spec set."
                          },
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          }
                        },
                        "description": "Annotation spec set with the setting of allowing multi labels or not."
                      },
                      "description": "Required. The list of annotation spec set configs. Since watching a video clip takes much longer time than an image, we support label with multiple AnnotationSpecSet at the same time. Labels in each AnnotationSpecSet will be shown in a group to contributors. Contributors can select one or more (depending on whether to allow multi label) from each group."
                    }
                  },
                  "description": "Configuration for video classification task."
                },
                "textEntityExtractionConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig",
                  "type": "object",
                  "properties": {
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    }
                  },
                  "description": "Configuration for text entity extraction task."
                }
              },
              "description": "Output only. Additional information about AnnotatedDataset."
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Time the AnnotatedDataset was created."
            },
            "labelStats": {
              "id": "GoogleCloudDatalabelingV1beta1LabelStats",
              "type": "object",
              "properties": {
                "exampleCount": {
                  "type": "object",
                  "description": "Map of each annotation spec's example count. Key is the annotation spec name and value is the number of examples for that annotation spec. If the annotated dataset does not have annotation spec, the map will return a pair where the key is empty string and value is the total number of annotations.",
                  "additionalProperties": {
                    "type": "string",
                    "format": "int64"
                  }
                }
              },
              "description": "Output only. Per label statistics."
            },
            "description": {
              "type": "string",
              "description": "Output only. The description of the AnnotatedDataset. It is specified in HumanAnnotationConfig when user starts a labeling task. Maximum of 10000 characters."
            },
            "displayName": {
              "type": "string",
              "description": "Output only. The display name of the AnnotatedDataset. It is specified in HumanAnnotationConfig when user starts a labeling task. Maximum of 64 characters."
            },
            "exampleCount": {
              "type": "string",
              "format": "int64",
              "description": "Output only. Number of examples in the annotated dataset."
            },
            "annotationType": {
              "enum": [
                "ANNOTATION_TYPE_UNSPECIFIED",
                "IMAGE_CLASSIFICATION_ANNOTATION",
                "IMAGE_BOUNDING_BOX_ANNOTATION",
                "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                "IMAGE_BOUNDING_POLY_ANNOTATION",
                "IMAGE_POLYLINE_ANNOTATION",
                "IMAGE_SEGMENTATION_ANNOTATION",
                "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                "VIDEO_OBJECT_TRACKING_ANNOTATION",
                "VIDEO_OBJECT_DETECTION_ANNOTATION",
                "VIDEO_EVENT_ANNOTATION",
                "TEXT_CLASSIFICATION_ANNOTATION",
                "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                "GENERAL_CLASSIFICATION_ANNOTATION"
              ],
              "type": "string",
              "description": "Output only. Type of the annotation. It is specified when starting labeling task.",
              "enumDescriptions": [
                "",
                "Classification annotations in an image. Allowed for continuous evaluation.",
                "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                "Bounding poly annotations in an image.",
                "Polyline annotations in an image.",
                "Segmentation annotations in an image.",
                "Classification annotations in video shots.",
                "Video object tracking annotation.",
                "Video object detection annotation.",
                "Video event annotation.",
                "Classification for text. Allowed for continuous evaluation.",
                "Entity extraction for text.",
                "General classification. Allowed for continuous evaluation."
              ]
            },
            "annotationSource": {
              "enum": [
                "ANNOTATION_SOURCE_UNSPECIFIED",
                "OPERATOR"
              ],
              "type": "string",
              "description": "Output only. Source of the annotation.",
              "enumDescriptions": [
                "",
                "Answer is provided by a human contributor."
              ]
            },
            "blockingResources": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Output only. The names of any related resources that are blocking changes to the annotated dataset."
            },
            "completedExampleCount": {
              "type": "string",
              "format": "int64",
              "description": "Output only. Number of examples that have annotation in the annotated dataset."
            }
          },
          "description": "AnnotatedDataset is a set holding annotations for data in a Dataset. Each labeling task will generate an AnnotatedDataset under the Dataset that the task is requested for."
        }
      ]
  projects.datasets.annotatedDatasets.list:
    description: |-
      Lists annotated datasets for a dataset. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.annotatedDatasets/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListAnnotatedDatasetsResponse",
          "type": "object",
          "properties": {
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            },
            "annotatedDatasets": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1AnnotatedDataset",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. AnnotatedDataset resource name in format of: projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/ {annotated_dataset_id}"
                  },
                  "metadata": {
                    "id": "GoogleCloudDatalabelingV1beta1AnnotatedDatasetMetadata",
                    "type": "object",
                    "properties": {
                      "eventConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1EventConfig",
                        "type": "object",
                        "properties": {
                          "clipLength": {
                            "type": "integer",
                            "format": "int32",
                            "description": "Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 60s."
                          },
                          "overlapLength": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 1s."
                          },
                          "annotationSpecSets": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "Required. The list of annotation spec set resource name. Similar to video classification, we support selecting event from multiple AnnotationSpecSet at the same time."
                          }
                        },
                        "description": "Configuration for video event labeling task."
                      },
                      "polylineConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1PolylineConfig",
                        "type": "object",
                        "properties": {
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          },
                          "instructionMessage": {
                            "type": "string",
                            "description": "Optional. Instruction message showed on contributors UI."
                          }
                        },
                        "description": "Configuration for image polyline task."
                      },
                      "boundingPolyConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1BoundingPolyConfig",
                        "type": "object",
                        "properties": {
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          },
                          "instructionMessage": {
                            "type": "string",
                            "description": "Optional. Instruction message showed on contributors UI."
                          }
                        },
                        "description": "Configuration for image bounding box and bounding poly task."
                      },
                      "segmentationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1SegmentationConfig",
                        "type": "object",
                        "properties": {
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name. format: projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}"
                          },
                          "instructionMessage": {
                            "type": "string",
                            "description": "Instruction message showed on labelers UI."
                          }
                        },
                        "description": "Configuration for image segmentation task."
                      },
                      "objectTrackingConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1ObjectTrackingConfig",
                        "type": "object",
                        "properties": {
                          "clipLength": {
                            "type": "integer",
                            "format": "int32",
                            "description": "Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 20s."
                          },
                          "overlapLength": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 0.3s."
                          },
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          }
                        },
                        "description": "Configuration for video object tracking task."
                      },
                      "humanAnnotationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
                        "type": "object",
                        "properties": {
                          "labelGroup": {
                            "type": "string",
                            "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                          },
                          "instruction": {
                            "type": "string",
                            "description": "Required. Instruction resource name."
                          },
                          "languageCode": {
                            "type": "string",
                            "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                          },
                          "replicaCount": {
                            "type": "integer",
                            "format": "int32",
                            "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                          },
                          "questionDuration": {
                            "type": "string",
                            "format": "google-duration",
                            "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                          },
                          "userEmailAddress": {
                            "type": "string",
                            "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                          },
                          "contributorEmails": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                          },
                          "annotatedDatasetDescription": {
                            "type": "string",
                            "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                          },
                          "annotatedDatasetDisplayName": {
                            "type": "string",
                            "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                          }
                        },
                        "description": "HumanAnnotationConfig used when requesting the human labeling task for this AnnotatedDataset."
                      },
                      "objectDetectionConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1ObjectDetectionConfig",
                        "type": "object",
                        "properties": {
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          },
                          "extractionFrameRate": {
                            "type": "number",
                            "format": "double",
                            "description": "Required. Number of frames per second to be extracted from the video."
                          }
                        },
                        "description": "Configuration for video object detection task."
                      },
                      "textClassificationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1TextClassificationConfig",
                        "type": "object",
                        "properties": {
                          "allowMultiLabel": {
                            "type": "boolean",
                            "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one text segment."
                          },
                          "sentimentConfig": {
                            "id": "GoogleCloudDatalabelingV1beta1SentimentConfig",
                            "type": "object",
                            "properties": {
                              "enableLabelSentimentSelection": {
                                "type": "boolean",
                                "description": "If set to true, contributors will have the option to select sentiment of the label they selected, to mark it as negative or positive label. Default is false."
                              }
                            },
                            "description": "Optional. Configs for sentiment selection. We deprecate sentiment analysis in data labeling side as it is incompatible with uCAIP."
                          },
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          }
                        },
                        "description": "Configuration for text classification task."
                      },
                      "imageClassificationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1ImageClassificationConfig",
                        "type": "object",
                        "properties": {
                          "allowMultiLabel": {
                            "type": "boolean",
                            "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one image."
                          },
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          },
                          "answerAggregationType": {
                            "enum": [
                              "STRING_AGGREGATION_TYPE_UNSPECIFIED",
                              "MAJORITY_VOTE",
                              "UNANIMOUS_VOTE",
                              "NO_AGGREGATION"
                            ],
                            "type": "string",
                            "description": "Optional. The type of how to aggregate answers.",
                            "enumDescriptions": [
                              "",
                              "Majority vote to aggregate answers.",
                              "Unanimous answers will be adopted.",
                              "Preserve all answers by crowd compute."
                            ]
                          }
                        },
                        "description": "Configuration for image classification task."
                      },
                      "videoClassificationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1VideoClassificationConfig",
                        "type": "object",
                        "properties": {
                          "applyShotDetection": {
                            "type": "boolean",
                            "description": "Optional. Option to apply shot detection on the video."
                          },
                          "annotationSpecSetConfigs": {
                            "type": "array",
                            "items": {
                              "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSetConfig",
                              "type": "object",
                              "properties": {
                                "allowMultiLabel": {
                                  "type": "boolean",
                                  "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels from one annotation spec set."
                                },
                                "annotationSpecSet": {
                                  "type": "string",
                                  "description": "Required. Annotation spec set resource name."
                                }
                              },
                              "description": "Annotation spec set with the setting of allowing multi labels or not."
                            },
                            "description": "Required. The list of annotation spec set configs. Since watching a video clip takes much longer time than an image, we support label with multiple AnnotationSpecSet at the same time. Labels in each AnnotationSpecSet will be shown in a group to contributors. Contributors can select one or more (depending on whether to allow multi label) from each group."
                          }
                        },
                        "description": "Configuration for video classification task."
                      },
                      "textEntityExtractionConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig",
                        "type": "object",
                        "properties": {
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          }
                        },
                        "description": "Configuration for text entity extraction task."
                      }
                    },
                    "description": "Output only. Additional information about AnnotatedDataset."
                  },
                  "createTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Time the AnnotatedDataset was created."
                  },
                  "labelStats": {
                    "id": "GoogleCloudDatalabelingV1beta1LabelStats",
                    "type": "object",
                    "properties": {
                      "exampleCount": {
                        "type": "object",
                        "description": "Map of each annotation spec's example count. Key is the annotation spec name and value is the number of examples for that annotation spec. If the annotated dataset does not have annotation spec, the map will return a pair where the key is empty string and value is the total number of annotations.",
                        "additionalProperties": {
                          "type": "string",
                          "format": "int64"
                        }
                      }
                    },
                    "description": "Output only. Per label statistics."
                  },
                  "description": {
                    "type": "string",
                    "description": "Output only. The description of the AnnotatedDataset. It is specified in HumanAnnotationConfig when user starts a labeling task. Maximum of 10000 characters."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "Output only. The display name of the AnnotatedDataset. It is specified in HumanAnnotationConfig when user starts a labeling task. Maximum of 64 characters."
                  },
                  "exampleCount": {
                    "type": "string",
                    "format": "int64",
                    "description": "Output only. Number of examples in the annotated dataset."
                  },
                  "annotationType": {
                    "enum": [
                      "ANNOTATION_TYPE_UNSPECIFIED",
                      "IMAGE_CLASSIFICATION_ANNOTATION",
                      "IMAGE_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_BOUNDING_POLY_ANNOTATION",
                      "IMAGE_POLYLINE_ANNOTATION",
                      "IMAGE_SEGMENTATION_ANNOTATION",
                      "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                      "VIDEO_OBJECT_TRACKING_ANNOTATION",
                      "VIDEO_OBJECT_DETECTION_ANNOTATION",
                      "VIDEO_EVENT_ANNOTATION",
                      "TEXT_CLASSIFICATION_ANNOTATION",
                      "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                      "GENERAL_CLASSIFICATION_ANNOTATION"
                    ],
                    "type": "string",
                    "description": "Output only. Type of the annotation. It is specified when starting labeling task.",
                    "enumDescriptions": [
                      "",
                      "Classification annotations in an image. Allowed for continuous evaluation.",
                      "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                      "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                      "Bounding poly annotations in an image.",
                      "Polyline annotations in an image.",
                      "Segmentation annotations in an image.",
                      "Classification annotations in video shots.",
                      "Video object tracking annotation.",
                      "Video object detection annotation.",
                      "Video event annotation.",
                      "Classification for text. Allowed for continuous evaluation.",
                      "Entity extraction for text.",
                      "General classification. Allowed for continuous evaluation."
                    ]
                  },
                  "annotationSource": {
                    "enum": [
                      "ANNOTATION_SOURCE_UNSPECIFIED",
                      "OPERATOR"
                    ],
                    "type": "string",
                    "description": "Output only. Source of the annotation.",
                    "enumDescriptions": [
                      "",
                      "Answer is provided by a human contributor."
                    ]
                  },
                  "blockingResources": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "Output only. The names of any related resources that are blocking changes to the annotated dataset."
                  },
                  "completedExampleCount": {
                    "type": "string",
                    "format": "int64",
                    "description": "Output only. Number of examples that have annotation in the annotated dataset."
                  }
                },
                "description": "AnnotatedDataset is a set holding annotations for data in a Dataset. Each labeling task will generate an AnnotatedDataset under the Dataset that the task is requested for."
              },
              "description": "The list of annotated datasets to return."
            }
          },
          "description": "Results of listing annotated datasets for a dataset."
        }
      ]
  projects.datasets.create:
    description: |-
      Creates dataset. If success return a Dataset resource.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets/create
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1CreateDatasetRequest",
          "type": "object",
          "properties": {
            "dataset": {
              "id": "GoogleCloudDatalabelingV1beta1Dataset",
              "type": "object",
              "properties": {
                "name": {
                  "type": "string",
                  "description": "Output only. Dataset resource name, format is: projects/{project_id}/datasets/{dataset_id}"
                },
                "createTime": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "Output only. Time the dataset is created."
                },
                "description": {
                  "type": "string",
                  "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10000 characters long."
                },
                "displayName": {
                  "type": "string",
                  "description": "Required. The display name of the dataset. Maximum of 64 characters."
                },
                "inputConfigs": {
                  "type": "array",
                  "items": {
                    "id": "GoogleCloudDatalabelingV1beta1InputConfig",
                    "type": "object",
                    "properties": {
                      "dataType": {
                        "enum": [
                          "DATA_TYPE_UNSPECIFIED",
                          "IMAGE",
                          "VIDEO",
                          "TEXT",
                          "GENERAL_DATA"
                        ],
                        "type": "string",
                        "description": "Required. Data type must be specifed when user tries to import data.",
                        "enumDescriptions": [
                          "Data type is unspecified.",
                          "Allowed for continuous evaluation.",
                          "Video data type.",
                          "Allowed for continuous evaluation.",
                          "Allowed for continuous evaluation."
                        ]
                      },
                      "gcsSource": {
                        "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                        "type": "object",
                        "properties": {
                          "inputUri": {
                            "type": "string",
                            "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                          },
                          "mimeType": {
                            "type": "string",
                            "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                          }
                        },
                        "description": "Source located in Cloud Storage."
                      },
                      "textMetadata": {
                        "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                        "type": "object",
                        "properties": {
                          "languageCode": {
                            "type": "string",
                            "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                          }
                        },
                        "description": "Required for text import, as language code must be specified."
                      },
                      "annotationType": {
                        "enum": [
                          "ANNOTATION_TYPE_UNSPECIFIED",
                          "IMAGE_CLASSIFICATION_ANNOTATION",
                          "IMAGE_BOUNDING_BOX_ANNOTATION",
                          "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                          "IMAGE_BOUNDING_POLY_ANNOTATION",
                          "IMAGE_POLYLINE_ANNOTATION",
                          "IMAGE_SEGMENTATION_ANNOTATION",
                          "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                          "VIDEO_OBJECT_TRACKING_ANNOTATION",
                          "VIDEO_OBJECT_DETECTION_ANNOTATION",
                          "VIDEO_EVENT_ANNOTATION",
                          "TEXT_CLASSIFICATION_ANNOTATION",
                          "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                          "GENERAL_CLASSIFICATION_ANNOTATION"
                        ],
                        "type": "string",
                        "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                        "enumDescriptions": [
                          "",
                          "Classification annotations in an image. Allowed for continuous evaluation.",
                          "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                          "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                          "Bounding poly annotations in an image.",
                          "Polyline annotations in an image.",
                          "Segmentation annotations in an image.",
                          "Classification annotations in video shots.",
                          "Video object tracking annotation.",
                          "Video object detection annotation.",
                          "Video event annotation.",
                          "Classification for text. Allowed for continuous evaluation.",
                          "Entity extraction for text.",
                          "General classification. Allowed for continuous evaluation."
                        ]
                      },
                      "bigquerySource": {
                        "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                        "type": "object",
                        "properties": {
                          "inputUri": {
                            "type": "string",
                            "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                          }
                        },
                        "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                      },
                      "classificationMetadata": {
                        "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                        "type": "object",
                        "properties": {
                          "isMultiLabel": {
                            "type": "boolean",
                            "description": "Whether the classification task is multi-label or not."
                          }
                        },
                        "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                      }
                    },
                    "description": "The configuration of input data, including data type, location, etc."
                  },
                  "description": "Output only. This is populated with the original input configs where ImportData is called. It is available only after the clients import data to this dataset."
                },
                "dataItemCount": {
                  "type": "string",
                  "format": "int64",
                  "description": "Output only. The number of data items in the dataset."
                },
                "lastMigrateTime": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "Last time that the Dataset is migrated to AI Platform V2. If any of the AnnotatedDataset is migrated, the last_migration_time in Dataset is also updated."
                },
                "blockingResources": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Output only. The names of any related resources that are blocking changes to the dataset."
                }
              },
              "description": "Required. The dataset to be created."
            }
          },
          "description": "Request message for CreateDataset."
        }
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1Dataset",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Dataset resource name, format is: projects/{project_id}/datasets/{dataset_id}"
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Time the dataset is created."
            },
            "description": {
              "type": "string",
              "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10000 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "Required. The display name of the dataset. Maximum of 64 characters."
            },
            "inputConfigs": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1InputConfig",
                "type": "object",
                "properties": {
                  "dataType": {
                    "enum": [
                      "DATA_TYPE_UNSPECIFIED",
                      "IMAGE",
                      "VIDEO",
                      "TEXT",
                      "GENERAL_DATA"
                    ],
                    "type": "string",
                    "description": "Required. Data type must be specifed when user tries to import data.",
                    "enumDescriptions": [
                      "Data type is unspecified.",
                      "Allowed for continuous evaluation.",
                      "Video data type.",
                      "Allowed for continuous evaluation.",
                      "Allowed for continuous evaluation."
                    ]
                  },
                  "gcsSource": {
                    "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                    "type": "object",
                    "properties": {
                      "inputUri": {
                        "type": "string",
                        "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                      }
                    },
                    "description": "Source located in Cloud Storage."
                  },
                  "textMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                    "type": "object",
                    "properties": {
                      "languageCode": {
                        "type": "string",
                        "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                      }
                    },
                    "description": "Required for text import, as language code must be specified."
                  },
                  "annotationType": {
                    "enum": [
                      "ANNOTATION_TYPE_UNSPECIFIED",
                      "IMAGE_CLASSIFICATION_ANNOTATION",
                      "IMAGE_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_BOUNDING_POLY_ANNOTATION",
                      "IMAGE_POLYLINE_ANNOTATION",
                      "IMAGE_SEGMENTATION_ANNOTATION",
                      "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                      "VIDEO_OBJECT_TRACKING_ANNOTATION",
                      "VIDEO_OBJECT_DETECTION_ANNOTATION",
                      "VIDEO_EVENT_ANNOTATION",
                      "TEXT_CLASSIFICATION_ANNOTATION",
                      "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                      "GENERAL_CLASSIFICATION_ANNOTATION"
                    ],
                    "type": "string",
                    "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                    "enumDescriptions": [
                      "",
                      "Classification annotations in an image. Allowed for continuous evaluation.",
                      "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                      "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                      "Bounding poly annotations in an image.",
                      "Polyline annotations in an image.",
                      "Segmentation annotations in an image.",
                      "Classification annotations in video shots.",
                      "Video object tracking annotation.",
                      "Video object detection annotation.",
                      "Video event annotation.",
                      "Classification for text. Allowed for continuous evaluation.",
                      "Entity extraction for text.",
                      "General classification. Allowed for continuous evaluation."
                    ]
                  },
                  "bigquerySource": {
                    "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                    "type": "object",
                    "properties": {
                      "inputUri": {
                        "type": "string",
                        "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                      }
                    },
                    "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                  },
                  "classificationMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                    "type": "object",
                    "properties": {
                      "isMultiLabel": {
                        "type": "boolean",
                        "description": "Whether the classification task is multi-label or not."
                      }
                    },
                    "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                  }
                },
                "description": "The configuration of input data, including data type, location, etc."
              },
              "description": "Output only. This is populated with the original input configs where ImportData is called. It is available only after the clients import data to this dataset."
            },
            "dataItemCount": {
              "type": "string",
              "format": "int64",
              "description": "Output only. The number of data items in the dataset."
            },
            "lastMigrateTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Last time that the Dataset is migrated to AI Platform V2. If any of the AnnotatedDataset is migrated, the last_migration_time in Dataset is also updated."
            },
            "blockingResources": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Output only. The names of any related resources that are blocking changes to the dataset."
            }
          },
          "description": "Dataset is the resource to hold your data. You can request multiple labeling tasks for a dataset while each one will generate an AnnotatedDataset."
        }
      ]
  projects.datasets.dataItems.get:
    description: |-
      Gets a data item in a dataset by resource name. This API can be called after data are imported into dataset.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.dataItems/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1DataItem",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Name of the data item, in format of: projects/{project_id}/datasets/{dataset_id}/dataItems/{data_item_id}"
            },
            "textPayload": {
              "id": "GoogleCloudDatalabelingV1beta1TextPayload",
              "type": "object",
              "properties": {
                "textContent": {
                  "type": "string",
                  "description": "Text content."
                }
              },
              "description": "The text payload, a container of text content."
            },
            "imagePayload": {
              "id": "GoogleCloudDatalabelingV1beta1ImagePayload",
              "type": "object",
              "properties": {
                "imageUri": {
                  "type": "string",
                  "description": "Image uri from the user bucket."
                },
                "mimeType": {
                  "type": "string",
                  "description": "Image format."
                },
                "signedUri": {
                  "type": "string",
                  "description": "Signed uri of the image file in the service bucket."
                },
                "imageThumbnail": {
                  "type": "string",
                  "format": "byte",
                  "description": "A byte string of a thumbnail image."
                }
              },
              "description": "The image payload, a container of the image bytes/uri."
            },
            "videoPayload": {
              "id": "GoogleCloudDatalabelingV1beta1VideoPayload",
              "type": "object",
              "properties": {
                "mimeType": {
                  "type": "string",
                  "description": "Video format."
                },
                "videoUri": {
                  "type": "string",
                  "description": "Video uri from the user bucket."
                },
                "frameRate": {
                  "type": "number",
                  "format": "float",
                  "description": "FPS of the video."
                },
                "signedUri": {
                  "type": "string",
                  "description": "Signed uri of the video file in the service bucket."
                },
                "videoThumbnails": {
                  "type": "array",
                  "items": {
                    "id": "GoogleCloudDatalabelingV1beta1VideoThumbnail",
                    "type": "object",
                    "properties": {
                      "thumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "A byte string of the video frame."
                      },
                      "timeOffset": {
                        "type": "string",
                        "format": "google-duration",
                        "description": "Time offset relative to the beginning of the video, corresponding to the video frame where the thumbnail has been extracted from."
                      }
                    },
                    "description": "Container of information of a video thumbnail."
                  },
                  "description": "The list of video thumbnails."
                }
              },
              "description": "The video payload, a container of the video uri."
            }
          },
          "description": "DataItem is a piece of data, without annotation. For example, an image."
        }
      ]
  projects.datasets.dataItems.list:
    description: |-
      Lists data items in a dataset. This API can be called after data are imported into dataset. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.dataItems/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListDataItemsResponse",
          "type": "object",
          "properties": {
            "dataItems": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1DataItem",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Name of the data item, in format of: projects/{project_id}/datasets/{dataset_id}/dataItems/{data_item_id}"
                  },
                  "textPayload": {
                    "id": "GoogleCloudDatalabelingV1beta1TextPayload",
                    "type": "object",
                    "properties": {
                      "textContent": {
                        "type": "string",
                        "description": "Text content."
                      }
                    },
                    "description": "The text payload, a container of text content."
                  },
                  "imagePayload": {
                    "id": "GoogleCloudDatalabelingV1beta1ImagePayload",
                    "type": "object",
                    "properties": {
                      "imageUri": {
                        "type": "string",
                        "description": "Image uri from the user bucket."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "Image format."
                      },
                      "signedUri": {
                        "type": "string",
                        "description": "Signed uri of the image file in the service bucket."
                      },
                      "imageThumbnail": {
                        "type": "string",
                        "format": "byte",
                        "description": "A byte string of a thumbnail image."
                      }
                    },
                    "description": "The image payload, a container of the image bytes/uri."
                  },
                  "videoPayload": {
                    "id": "GoogleCloudDatalabelingV1beta1VideoPayload",
                    "type": "object",
                    "properties": {
                      "mimeType": {
                        "type": "string",
                        "description": "Video format."
                      },
                      "videoUri": {
                        "type": "string",
                        "description": "Video uri from the user bucket."
                      },
                      "frameRate": {
                        "type": "number",
                        "format": "float",
                        "description": "FPS of the video."
                      },
                      "signedUri": {
                        "type": "string",
                        "description": "Signed uri of the video file in the service bucket."
                      },
                      "videoThumbnails": {
                        "type": "array",
                        "items": {
                          "id": "GoogleCloudDatalabelingV1beta1VideoThumbnail",
                          "type": "object",
                          "properties": {
                            "thumbnail": {
                              "type": "string",
                              "format": "byte",
                              "description": "A byte string of the video frame."
                            },
                            "timeOffset": {
                              "type": "string",
                              "format": "google-duration",
                              "description": "Time offset relative to the beginning of the video, corresponding to the video frame where the thumbnail has been extracted from."
                            }
                          },
                          "description": "Container of information of a video thumbnail."
                        },
                        "description": "The list of video thumbnails."
                      }
                    },
                    "description": "The video payload, a container of the video uri."
                  }
                },
                "description": "DataItem is a piece of data, without annotation. For example, an image."
              },
              "description": "The list of data items to return."
            },
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            }
          },
          "description": "Results of listing data items in a dataset."
        }
      ]
  projects.datasets.delete:
    description: |-
      Deletes a dataset by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.datasets.evaluations.exampleComparisons.search:
    description: |-
      Searches example comparisons from an evaluation. The return format is a list of example comparisons that show ground truth and prediction(s) for a single input. Search by providing an evaluation ID.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.evaluations.exampleComparisons/search
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.datasets.evaluations.get:
    description: |-
      Gets an evaluation by resource name (to search, use projects.evaluations.search).
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.evaluations/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1Evaluation",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Resource name of an evaluation. The name has the following format: \"projects/{project_id}/datasets/{dataset_id}/evaluations/ {evaluation_id}'"
            },
            "config": {
              "id": "GoogleCloudDatalabelingV1beta1EvaluationConfig",
              "type": "object",
              "properties": {
                "boundingBoxEvaluationOptions": {
                  "id": "GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions",
                  "type": "object",
                  "properties": {
                    "iouThreshold": {
                      "type": "number",
                      "format": "float",
                      "description": "Minimum [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) required for 2 bounding boxes to be considered a match. This must be a number between 0 and 1."
                    }
                  },
                  "description": "Only specify this field if the related model performs image object detection (`IMAGE_BOUNDING_BOX_ANNOTATION`). Describes how to evaluate bounding boxes."
                }
              },
              "description": "Output only. Options used in the evaluation job that created this evaluation."
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Timestamp for when this evaluation was created."
            },
            "annotationType": {
              "enum": [
                "ANNOTATION_TYPE_UNSPECIFIED",
                "IMAGE_CLASSIFICATION_ANNOTATION",
                "IMAGE_BOUNDING_BOX_ANNOTATION",
                "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                "IMAGE_BOUNDING_POLY_ANNOTATION",
                "IMAGE_POLYLINE_ANNOTATION",
                "IMAGE_SEGMENTATION_ANNOTATION",
                "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                "VIDEO_OBJECT_TRACKING_ANNOTATION",
                "VIDEO_OBJECT_DETECTION_ANNOTATION",
                "VIDEO_EVENT_ANNOTATION",
                "TEXT_CLASSIFICATION_ANNOTATION",
                "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                "GENERAL_CLASSIFICATION_ANNOTATION"
              ],
              "type": "string",
              "description": "Output only. Type of task that the model version being evaluated performs, as defined in the evaluationJobConfig.inputConfig.annotationType field of the evaluation job that created this evaluation.",
              "enumDescriptions": [
                "",
                "Classification annotations in an image. Allowed for continuous evaluation.",
                "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                "Bounding poly annotations in an image.",
                "Polyline annotations in an image.",
                "Segmentation annotations in an image.",
                "Classification annotations in video shots.",
                "Video object tracking annotation.",
                "Video object detection annotation.",
                "Video event annotation.",
                "Classification for text. Allowed for continuous evaluation.",
                "Entity extraction for text.",
                "General classification. Allowed for continuous evaluation."
              ]
            },
            "evaluationMetrics": {
              "id": "GoogleCloudDatalabelingV1beta1EvaluationMetrics",
              "type": "object",
              "properties": {
                "classificationMetrics": {
                  "id": "GoogleCloudDatalabelingV1beta1ClassificationMetrics",
                  "type": "object",
                  "properties": {
                    "prCurve": {
                      "id": "GoogleCloudDatalabelingV1beta1PrCurve",
                      "type": "object",
                      "properties": {
                        "annotationSpec": {
                          "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                          "type": "object",
                          "properties": {
                            "index": {
                              "type": "integer",
                              "format": "int32",
                              "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                            },
                            "description": {
                              "type": "string",
                              "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                            },
                            "displayName": {
                              "type": "string",
                              "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                            }
                          },
                          "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                        },
                        "areaUnderCurve": {
                          "type": "number",
                          "format": "float",
                          "description": "Area under the precision-recall curve. Not to be confused with area under a receiver operating characteristic (ROC) curve."
                        },
                        "meanAveragePrecision": {
                          "type": "number",
                          "format": "float",
                          "description": "Mean average prcision of this curve."
                        },
                        "confidenceMetricsEntries": {
                          "type": "array",
                          "items": {
                            "id": "GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry",
                            "type": "object",
                            "properties": {
                              "recall": {
                                "type": "number",
                                "format": "float",
                                "description": "Recall value."
                              },
                              "f1Score": {
                                "type": "number",
                                "format": "float",
                                "description": "Harmonic mean of recall and precision."
                              },
                              "precision": {
                                "type": "number",
                                "format": "float",
                                "description": "Precision value."
                              },
                              "recallAt1": {
                                "type": "number",
                                "format": "float",
                                "description": "Recall value for entries with label that has highest score."
                              },
                              "recallAt5": {
                                "type": "number",
                                "format": "float",
                                "description": "Recall value for entries with label that has highest 5 scores."
                              },
                              "f1ScoreAt1": {
                                "type": "number",
                                "format": "float",
                                "description": "The harmonic mean of recall_at1 and precision_at1."
                              },
                              "f1ScoreAt5": {
                                "type": "number",
                                "format": "float",
                                "description": "The harmonic mean of recall_at5 and precision_at5."
                              },
                              "precisionAt1": {
                                "type": "number",
                                "format": "float",
                                "description": "Precision value for entries with label that has highest score."
                              },
                              "precisionAt5": {
                                "type": "number",
                                "format": "float",
                                "description": "Precision value for entries with label that has highest 5 scores."
                              },
                              "confidenceThreshold": {
                                "type": "number",
                                "format": "float",
                                "description": "Threshold used for this entry. For classification tasks, this is a classification threshold: a predicted label is categorized as positive or negative (in the context of this point on the PR curve) based on whether the label's score meets this threshold. For image object detection (bounding box) tasks, this is the [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) threshold for the context of this point on the PR curve."
                              }
                            }
                          },
                          "description": "Entries that make up the precision-recall graph. Each entry is a \"point\" on the graph drawn for a different `confidence_threshold`."
                        }
                      },
                      "description": "Precision-recall curve based on ground truth labels, predicted labels, and scores for the predicted labels."
                    },
                    "confusionMatrix": {
                      "id": "GoogleCloudDatalabelingV1beta1ConfusionMatrix",
                      "type": "object",
                      "properties": {
                        "row": {
                          "type": "array",
                          "items": {
                            "id": "GoogleCloudDatalabelingV1beta1Row",
                            "type": "object",
                            "properties": {
                              "entries": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1ConfusionMatrixEntry",
                                  "type": "object",
                                  "properties": {
                                    "itemCount": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Number of items predicted to have this label. (The ground truth label for these items is the `Row.annotationSpec` of this entry's parent.)"
                                    },
                                    "annotationSpec": {
                                      "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                      "type": "object",
                                      "properties": {
                                        "index": {
                                          "type": "integer",
                                          "format": "int32",
                                          "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                        },
                                        "description": {
                                          "type": "string",
                                          "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                        },
                                        "displayName": {
                                          "type": "string",
                                          "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                        }
                                      },
                                      "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                    }
                                  }
                                },
                                "description": "A list of the confusion matrix entries. One entry for each possible predicted label."
                              },
                              "annotationSpec": {
                                "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                "type": "object",
                                "properties": {
                                  "index": {
                                    "type": "integer",
                                    "format": "int32",
                                    "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                  },
                                  "description": {
                                    "type": "string",
                                    "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                  },
                                  "displayName": {
                                    "type": "string",
                                    "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                  }
                                },
                                "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                              }
                            },
                            "description": "A row in the confusion matrix. Each entry in this row has the same ground truth label."
                          }
                        }
                      },
                      "description": "Confusion matrix of predicted labels vs. ground truth labels."
                    }
                  },
                  "description": "Metrics calculated for a classification model."
                },
                "objectDetectionMetrics": {
                  "id": "GoogleCloudDatalabelingV1beta1ObjectDetectionMetrics",
                  "type": "object",
                  "properties": {
                    "prCurve": {
                      "id": "GoogleCloudDatalabelingV1beta1PrCurve",
                      "type": "object",
                      "properties": {
                        "annotationSpec": {
                          "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                          "type": "object",
                          "properties": {
                            "index": {
                              "type": "integer",
                              "format": "int32",
                              "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                            },
                            "description": {
                              "type": "string",
                              "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                            },
                            "displayName": {
                              "type": "string",
                              "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                            }
                          },
                          "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                        },
                        "areaUnderCurve": {
                          "type": "number",
                          "format": "float",
                          "description": "Area under the precision-recall curve. Not to be confused with area under a receiver operating characteristic (ROC) curve."
                        },
                        "meanAveragePrecision": {
                          "type": "number",
                          "format": "float",
                          "description": "Mean average prcision of this curve."
                        },
                        "confidenceMetricsEntries": {
                          "type": "array",
                          "items": {
                            "id": "GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry",
                            "type": "object",
                            "properties": {
                              "recall": {
                                "type": "number",
                                "format": "float",
                                "description": "Recall value."
                              },
                              "f1Score": {
                                "type": "number",
                                "format": "float",
                                "description": "Harmonic mean of recall and precision."
                              },
                              "precision": {
                                "type": "number",
                                "format": "float",
                                "description": "Precision value."
                              },
                              "recallAt1": {
                                "type": "number",
                                "format": "float",
                                "description": "Recall value for entries with label that has highest score."
                              },
                              "recallAt5": {
                                "type": "number",
                                "format": "float",
                                "description": "Recall value for entries with label that has highest 5 scores."
                              },
                              "f1ScoreAt1": {
                                "type": "number",
                                "format": "float",
                                "description": "The harmonic mean of recall_at1 and precision_at1."
                              },
                              "f1ScoreAt5": {
                                "type": "number",
                                "format": "float",
                                "description": "The harmonic mean of recall_at5 and precision_at5."
                              },
                              "precisionAt1": {
                                "type": "number",
                                "format": "float",
                                "description": "Precision value for entries with label that has highest score."
                              },
                              "precisionAt5": {
                                "type": "number",
                                "format": "float",
                                "description": "Precision value for entries with label that has highest 5 scores."
                              },
                              "confidenceThreshold": {
                                "type": "number",
                                "format": "float",
                                "description": "Threshold used for this entry. For classification tasks, this is a classification threshold: a predicted label is categorized as positive or negative (in the context of this point on the PR curve) based on whether the label's score meets this threshold. For image object detection (bounding box) tasks, this is the [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) threshold for the context of this point on the PR curve."
                              }
                            }
                          },
                          "description": "Entries that make up the precision-recall graph. Each entry is a \"point\" on the graph drawn for a different `confidence_threshold`."
                        }
                      },
                      "description": "Precision-recall curve."
                    }
                  },
                  "description": "Metrics calculated for an image object detection (bounding box) model."
                }
              },
              "description": "Output only. Metrics comparing predictions to ground truth labels."
            },
            "evaluatedItemCount": {
              "type": "string",
              "format": "int64",
              "description": "Output only. The number of items in the ground truth dataset that were used for this evaluation. Only populated when the evaulation is for certain AnnotationTypes."
            },
            "evaluationJobRunTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Timestamp for when the evaluation job that created this evaluation ran."
            }
          },
          "description": "Describes an evaluation between a machine learning model's predictions and ground truth labels. Created when an EvaluationJob runs successfully."
        }
      ]
  projects.datasets.exportData:
    description: |-
      Exports data and annotations from dataset.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets/exportData
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ExportDataRequest",
          "type": "object",
          "properties": {
            "filter": {
              "type": "string",
              "description": "Optional. Filter is not supported at this moment."
            },
            "outputConfig": {
              "id": "GoogleCloudDatalabelingV1beta1OutputConfig",
              "type": "object",
              "properties": {
                "gcsDestination": {
                  "id": "GoogleCloudDatalabelingV1beta1GcsDestination",
                  "type": "object",
                  "properties": {
                    "mimeType": {
                      "type": "string",
                      "description": "Required. The format of the gcs destination. Only \"text/csv\" and \"application/json\" are supported."
                    },
                    "outputUri": {
                      "type": "string",
                      "description": "Required. The output uri of destination file."
                    }
                  },
                  "description": "Output to a file in Cloud Storage. Should be used for labeling output other than image segmentation."
                },
                "gcsFolderDestination": {
                  "id": "GoogleCloudDatalabelingV1beta1GcsFolderDestination",
                  "type": "object",
                  "properties": {
                    "outputFolderUri": {
                      "type": "string",
                      "description": "Required. Cloud Storage directory to export data to."
                    }
                  },
                  "description": "Output to a folder in Cloud Storage. Should be used for image segmentation or document de-identification labeling outputs."
                }
              },
              "description": "Required. Specify the output destination."
            },
            "annotatedDataset": {
              "type": "string",
              "description": "Required. Annotated dataset resource name. DataItem in Dataset and their annotations in specified annotated dataset will be exported. It's in format of projects/{project_id}/datasets/{dataset_id}/annotatedDatasets/ {annotated_dataset_id}"
            },
            "userEmailAddress": {
              "type": "string",
              "description": "Email of the user who started the export task and should be notified by email. If empty no notification will be sent."
            }
          },
          "description": "Request message for ExportData API."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.datasets.get:
    description: |-
      Gets dataset by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1Dataset",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Dataset resource name, format is: projects/{project_id}/datasets/{dataset_id}"
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Time the dataset is created."
            },
            "description": {
              "type": "string",
              "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10000 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "Required. The display name of the dataset. Maximum of 64 characters."
            },
            "inputConfigs": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1InputConfig",
                "type": "object",
                "properties": {
                  "dataType": {
                    "enum": [
                      "DATA_TYPE_UNSPECIFIED",
                      "IMAGE",
                      "VIDEO",
                      "TEXT",
                      "GENERAL_DATA"
                    ],
                    "type": "string",
                    "description": "Required. Data type must be specifed when user tries to import data.",
                    "enumDescriptions": [
                      "Data type is unspecified.",
                      "Allowed for continuous evaluation.",
                      "Video data type.",
                      "Allowed for continuous evaluation.",
                      "Allowed for continuous evaluation."
                    ]
                  },
                  "gcsSource": {
                    "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                    "type": "object",
                    "properties": {
                      "inputUri": {
                        "type": "string",
                        "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                      }
                    },
                    "description": "Source located in Cloud Storage."
                  },
                  "textMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                    "type": "object",
                    "properties": {
                      "languageCode": {
                        "type": "string",
                        "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                      }
                    },
                    "description": "Required for text import, as language code must be specified."
                  },
                  "annotationType": {
                    "enum": [
                      "ANNOTATION_TYPE_UNSPECIFIED",
                      "IMAGE_CLASSIFICATION_ANNOTATION",
                      "IMAGE_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_BOUNDING_POLY_ANNOTATION",
                      "IMAGE_POLYLINE_ANNOTATION",
                      "IMAGE_SEGMENTATION_ANNOTATION",
                      "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                      "VIDEO_OBJECT_TRACKING_ANNOTATION",
                      "VIDEO_OBJECT_DETECTION_ANNOTATION",
                      "VIDEO_EVENT_ANNOTATION",
                      "TEXT_CLASSIFICATION_ANNOTATION",
                      "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                      "GENERAL_CLASSIFICATION_ANNOTATION"
                    ],
                    "type": "string",
                    "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                    "enumDescriptions": [
                      "",
                      "Classification annotations in an image. Allowed for continuous evaluation.",
                      "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                      "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                      "Bounding poly annotations in an image.",
                      "Polyline annotations in an image.",
                      "Segmentation annotations in an image.",
                      "Classification annotations in video shots.",
                      "Video object tracking annotation.",
                      "Video object detection annotation.",
                      "Video event annotation.",
                      "Classification for text. Allowed for continuous evaluation.",
                      "Entity extraction for text.",
                      "General classification. Allowed for continuous evaluation."
                    ]
                  },
                  "bigquerySource": {
                    "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                    "type": "object",
                    "properties": {
                      "inputUri": {
                        "type": "string",
                        "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                      }
                    },
                    "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                  },
                  "classificationMetadata": {
                    "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                    "type": "object",
                    "properties": {
                      "isMultiLabel": {
                        "type": "boolean",
                        "description": "Whether the classification task is multi-label or not."
                      }
                    },
                    "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                  }
                },
                "description": "The configuration of input data, including data type, location, etc."
              },
              "description": "Output only. This is populated with the original input configs where ImportData is called. It is available only after the clients import data to this dataset."
            },
            "dataItemCount": {
              "type": "string",
              "format": "int64",
              "description": "Output only. The number of data items in the dataset."
            },
            "lastMigrateTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Last time that the Dataset is migrated to AI Platform V2. If any of the AnnotatedDataset is migrated, the last_migration_time in Dataset is also updated."
            },
            "blockingResources": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Output only. The names of any related resources that are blocking changes to the dataset."
            }
          },
          "description": "Dataset is the resource to hold your data. You can request multiple labeling tasks for a dataset while each one will generate an AnnotatedDataset."
        }
      ]
  projects.datasets.image.label:
    description: |-
      Starts a labeling task for image. The type of image labeling task is configured by feature in the request.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.image/label
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1LabelImageRequest",
          "type": "object",
          "properties": {
            "feature": {
              "enum": [
                "FEATURE_UNSPECIFIED",
                "CLASSIFICATION",
                "BOUNDING_BOX",
                "ORIENTED_BOUNDING_BOX",
                "BOUNDING_POLY",
                "POLYLINE",
                "SEGMENTATION"
              ],
              "type": "string",
              "description": "Required. The type of image labeling task.",
              "enumDescriptions": [
                "",
                "Label whole image with one or more of labels.",
                "Label image with bounding boxes for labels.",
                "Label oriented bounding box. The box does not have to be parallel to horizontal line.",
                "Label images with bounding poly. A bounding poly is a plane figure that is bounded by a finite chain of straight line segments closing in a loop.",
                "Label images with polyline. Polyline is formed by connected line segments which are not in closed form.",
                "Label images with segmentation. Segmentation is different from bounding poly since it is more fine-grained, pixel level annotation."
              ]
            },
            "basicConfig": {
              "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
              "type": "object",
              "properties": {
                "labelGroup": {
                  "type": "string",
                  "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                },
                "instruction": {
                  "type": "string",
                  "description": "Required. Instruction resource name."
                },
                "languageCode": {
                  "type": "string",
                  "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                },
                "replicaCount": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                },
                "questionDuration": {
                  "type": "string",
                  "format": "google-duration",
                  "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                },
                "userEmailAddress": {
                  "type": "string",
                  "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                },
                "contributorEmails": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                },
                "annotatedDatasetDescription": {
                  "type": "string",
                  "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                },
                "annotatedDatasetDisplayName": {
                  "type": "string",
                  "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                }
              },
              "description": "Required. Basic human annotation config."
            },
            "polylineConfig": {
              "id": "GoogleCloudDatalabelingV1beta1PolylineConfig",
              "type": "object",
              "properties": {
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                },
                "instructionMessage": {
                  "type": "string",
                  "description": "Optional. Instruction message showed on contributors UI."
                }
              },
              "description": "Configuration for polyline task. One of image_classification_config, bounding_poly_config, polyline_config and segmentation_config are required."
            },
            "boundingPolyConfig": {
              "id": "GoogleCloudDatalabelingV1beta1BoundingPolyConfig",
              "type": "object",
              "properties": {
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                },
                "instructionMessage": {
                  "type": "string",
                  "description": "Optional. Instruction message showed on contributors UI."
                }
              },
              "description": "Configuration for bounding box and bounding poly task. One of image_classification_config, bounding_poly_config, polyline_config and segmentation_config are required."
            },
            "segmentationConfig": {
              "id": "GoogleCloudDatalabelingV1beta1SegmentationConfig",
              "type": "object",
              "properties": {
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name. format: projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}"
                },
                "instructionMessage": {
                  "type": "string",
                  "description": "Instruction message showed on labelers UI."
                }
              },
              "description": "Configuration for segmentation task. One of image_classification_config, bounding_poly_config, polyline_config and segmentation_config are required."
            },
            "imageClassificationConfig": {
              "id": "GoogleCloudDatalabelingV1beta1ImageClassificationConfig",
              "type": "object",
              "properties": {
                "allowMultiLabel": {
                  "type": "boolean",
                  "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one image."
                },
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                },
                "answerAggregationType": {
                  "enum": [
                    "STRING_AGGREGATION_TYPE_UNSPECIFIED",
                    "MAJORITY_VOTE",
                    "UNANIMOUS_VOTE",
                    "NO_AGGREGATION"
                  ],
                  "type": "string",
                  "description": "Optional. The type of how to aggregate answers.",
                  "enumDescriptions": [
                    "",
                    "Majority vote to aggregate answers.",
                    "Unanimous answers will be adopted.",
                    "Preserve all answers by crowd compute."
                  ]
                }
              },
              "description": "Configuration for image classification task. One of image_classification_config, bounding_poly_config, polyline_config and segmentation_config are required."
            }
          },
          "description": "Request message for starting an image labeling task."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.datasets.importData:
    description: |-
      Imports data into dataset based on source locations defined in request. It can be called multiple times for the same dataset. Each dataset can only have one long running operation running on it. For example, no labeling task (also long running operation) can be started while importing is still ongoing. Vice versa.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets/importData
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ImportDataRequest",
          "type": "object",
          "properties": {
            "inputConfig": {
              "id": "GoogleCloudDatalabelingV1beta1InputConfig",
              "type": "object",
              "properties": {
                "dataType": {
                  "enum": [
                    "DATA_TYPE_UNSPECIFIED",
                    "IMAGE",
                    "VIDEO",
                    "TEXT",
                    "GENERAL_DATA"
                  ],
                  "type": "string",
                  "description": "Required. Data type must be specifed when user tries to import data.",
                  "enumDescriptions": [
                    "Data type is unspecified.",
                    "Allowed for continuous evaluation.",
                    "Video data type.",
                    "Allowed for continuous evaluation.",
                    "Allowed for continuous evaluation."
                  ]
                },
                "gcsSource": {
                  "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                  "type": "object",
                  "properties": {
                    "inputUri": {
                      "type": "string",
                      "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                    },
                    "mimeType": {
                      "type": "string",
                      "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                    }
                  },
                  "description": "Source located in Cloud Storage."
                },
                "textMetadata": {
                  "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                  "type": "object",
                  "properties": {
                    "languageCode": {
                      "type": "string",
                      "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                    }
                  },
                  "description": "Required for text import, as language code must be specified."
                },
                "annotationType": {
                  "enum": [
                    "ANNOTATION_TYPE_UNSPECIFIED",
                    "IMAGE_CLASSIFICATION_ANNOTATION",
                    "IMAGE_BOUNDING_BOX_ANNOTATION",
                    "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                    "IMAGE_BOUNDING_POLY_ANNOTATION",
                    "IMAGE_POLYLINE_ANNOTATION",
                    "IMAGE_SEGMENTATION_ANNOTATION",
                    "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                    "VIDEO_OBJECT_TRACKING_ANNOTATION",
                    "VIDEO_OBJECT_DETECTION_ANNOTATION",
                    "VIDEO_EVENT_ANNOTATION",
                    "TEXT_CLASSIFICATION_ANNOTATION",
                    "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                    "GENERAL_CLASSIFICATION_ANNOTATION"
                  ],
                  "type": "string",
                  "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                  "enumDescriptions": [
                    "",
                    "Classification annotations in an image. Allowed for continuous evaluation.",
                    "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                    "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                    "Bounding poly annotations in an image.",
                    "Polyline annotations in an image.",
                    "Segmentation annotations in an image.",
                    "Classification annotations in video shots.",
                    "Video object tracking annotation.",
                    "Video object detection annotation.",
                    "Video event annotation.",
                    "Classification for text. Allowed for continuous evaluation.",
                    "Entity extraction for text.",
                    "General classification. Allowed for continuous evaluation."
                  ]
                },
                "bigquerySource": {
                  "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                  "type": "object",
                  "properties": {
                    "inputUri": {
                      "type": "string",
                      "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                    }
                  },
                  "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                },
                "classificationMetadata": {
                  "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                  "type": "object",
                  "properties": {
                    "isMultiLabel": {
                      "type": "boolean",
                      "description": "Whether the classification task is multi-label or not."
                    }
                  },
                  "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                }
              },
              "description": "The configuration of input data, including data type, location, etc."
            },
            "userEmailAddress": {
              "type": "string",
              "description": "Email of the user who started the import task and should be notified by email. If empty no notification will be sent."
            }
          },
          "description": "Request message for ImportData API."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.datasets.list:
    description: |-
      Lists datasets under a project. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListDatasetsResponse",
          "type": "object",
          "properties": {
            "datasets": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1Dataset",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Dataset resource name, format is: projects/{project_id}/datasets/{dataset_id}"
                  },
                  "createTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Time the dataset is created."
                  },
                  "description": {
                    "type": "string",
                    "description": "Optional. User-provided description of the annotation specification set. The description can be up to 10000 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "Required. The display name of the dataset. Maximum of 64 characters."
                  },
                  "inputConfigs": {
                    "type": "array",
                    "items": {
                      "id": "GoogleCloudDatalabelingV1beta1InputConfig",
                      "type": "object",
                      "properties": {
                        "dataType": {
                          "enum": [
                            "DATA_TYPE_UNSPECIFIED",
                            "IMAGE",
                            "VIDEO",
                            "TEXT",
                            "GENERAL_DATA"
                          ],
                          "type": "string",
                          "description": "Required. Data type must be specifed when user tries to import data.",
                          "enumDescriptions": [
                            "Data type is unspecified.",
                            "Allowed for continuous evaluation.",
                            "Video data type.",
                            "Allowed for continuous evaluation.",
                            "Allowed for continuous evaluation."
                          ]
                        },
                        "gcsSource": {
                          "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                          "type": "object",
                          "properties": {
                            "inputUri": {
                              "type": "string",
                              "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                            },
                            "mimeType": {
                              "type": "string",
                              "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                            }
                          },
                          "description": "Source located in Cloud Storage."
                        },
                        "textMetadata": {
                          "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                          "type": "object",
                          "properties": {
                            "languageCode": {
                              "type": "string",
                              "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                            }
                          },
                          "description": "Required for text import, as language code must be specified."
                        },
                        "annotationType": {
                          "enum": [
                            "ANNOTATION_TYPE_UNSPECIFIED",
                            "IMAGE_CLASSIFICATION_ANNOTATION",
                            "IMAGE_BOUNDING_BOX_ANNOTATION",
                            "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                            "IMAGE_BOUNDING_POLY_ANNOTATION",
                            "IMAGE_POLYLINE_ANNOTATION",
                            "IMAGE_SEGMENTATION_ANNOTATION",
                            "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                            "VIDEO_OBJECT_TRACKING_ANNOTATION",
                            "VIDEO_OBJECT_DETECTION_ANNOTATION",
                            "VIDEO_EVENT_ANNOTATION",
                            "TEXT_CLASSIFICATION_ANNOTATION",
                            "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                            "GENERAL_CLASSIFICATION_ANNOTATION"
                          ],
                          "type": "string",
                          "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                          "enumDescriptions": [
                            "",
                            "Classification annotations in an image. Allowed for continuous evaluation.",
                            "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                            "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                            "Bounding poly annotations in an image.",
                            "Polyline annotations in an image.",
                            "Segmentation annotations in an image.",
                            "Classification annotations in video shots.",
                            "Video object tracking annotation.",
                            "Video object detection annotation.",
                            "Video event annotation.",
                            "Classification for text. Allowed for continuous evaluation.",
                            "Entity extraction for text.",
                            "General classification. Allowed for continuous evaluation."
                          ]
                        },
                        "bigquerySource": {
                          "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                          "type": "object",
                          "properties": {
                            "inputUri": {
                              "type": "string",
                              "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                            }
                          },
                          "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                        },
                        "classificationMetadata": {
                          "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                          "type": "object",
                          "properties": {
                            "isMultiLabel": {
                              "type": "boolean",
                              "description": "Whether the classification task is multi-label or not."
                            }
                          },
                          "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                        }
                      },
                      "description": "The configuration of input data, including data type, location, etc."
                    },
                    "description": "Output only. This is populated with the original input configs where ImportData is called. It is available only after the clients import data to this dataset."
                  },
                  "dataItemCount": {
                    "type": "string",
                    "format": "int64",
                    "description": "Output only. The number of data items in the dataset."
                  },
                  "lastMigrateTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Last time that the Dataset is migrated to AI Platform V2. If any of the AnnotatedDataset is migrated, the last_migration_time in Dataset is also updated."
                  },
                  "blockingResources": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "Output only. The names of any related resources that are blocking changes to the dataset."
                  }
                },
                "description": "Dataset is the resource to hold your data. You can request multiple labeling tasks for a dataset while each one will generate an AnnotatedDataset."
              },
              "description": "The list of datasets to return."
            },
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            }
          },
          "description": "Results of listing datasets within a project."
        }
      ]
  projects.datasets.text.label:
    description: |-
      Starts a labeling task for text. The type of text labeling task is configured by feature in the request.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.text/label
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1LabelTextRequest",
          "type": "object",
          "properties": {
            "feature": {
              "enum": [
                "FEATURE_UNSPECIFIED",
                "TEXT_CLASSIFICATION",
                "TEXT_ENTITY_EXTRACTION"
              ],
              "type": "string",
              "description": "Required. The type of text labeling task.",
              "enumDescriptions": [
                "",
                "Label text content to one of more labels.",
                "Label entities and their span in text."
              ]
            },
            "basicConfig": {
              "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
              "type": "object",
              "properties": {
                "labelGroup": {
                  "type": "string",
                  "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                },
                "instruction": {
                  "type": "string",
                  "description": "Required. Instruction resource name."
                },
                "languageCode": {
                  "type": "string",
                  "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                },
                "replicaCount": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                },
                "questionDuration": {
                  "type": "string",
                  "format": "google-duration",
                  "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                },
                "userEmailAddress": {
                  "type": "string",
                  "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                },
                "contributorEmails": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                },
                "annotatedDatasetDescription": {
                  "type": "string",
                  "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                },
                "annotatedDatasetDisplayName": {
                  "type": "string",
                  "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                }
              },
              "description": "Required. Basic human annotation config."
            },
            "textClassificationConfig": {
              "id": "GoogleCloudDatalabelingV1beta1TextClassificationConfig",
              "type": "object",
              "properties": {
                "allowMultiLabel": {
                  "type": "boolean",
                  "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one text segment."
                },
                "sentimentConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1SentimentConfig",
                  "type": "object",
                  "properties": {
                    "enableLabelSentimentSelection": {
                      "type": "boolean",
                      "description": "If set to true, contributors will have the option to select sentiment of the label they selected, to mark it as negative or positive label. Default is false."
                    }
                  },
                  "description": "Optional. Configs for sentiment selection. We deprecate sentiment analysis in data labeling side as it is incompatible with uCAIP."
                },
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                }
              },
              "description": "Configuration for text classification task. One of text_classification_config and text_entity_extraction_config is required."
            },
            "textEntityExtractionConfig": {
              "id": "GoogleCloudDatalabelingV1beta1TextEntityExtractionConfig",
              "type": "object",
              "properties": {
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                }
              },
              "description": "Configuration for entity extraction task. One of text_classification_config and text_entity_extraction_config is required."
            }
          },
          "description": "Request message for LabelText."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.datasets.video.label:
    description: |-
      Starts a labeling task for video. The type of video labeling task is configured by feature in the request.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.datasets.video/label
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1LabelVideoRequest",
          "type": "object",
          "properties": {
            "feature": {
              "enum": [
                "FEATURE_UNSPECIFIED",
                "CLASSIFICATION",
                "OBJECT_DETECTION",
                "OBJECT_TRACKING",
                "EVENT"
              ],
              "type": "string",
              "description": "Required. The type of video labeling task.",
              "enumDescriptions": [
                "",
                "Label whole video or video segment with one or more labels.",
                "Label objects with bounding box on image frames extracted from the video.",
                "Label and track objects in video.",
                "Label the range of video for the specified events."
              ]
            },
            "basicConfig": {
              "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
              "type": "object",
              "properties": {
                "labelGroup": {
                  "type": "string",
                  "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                },
                "instruction": {
                  "type": "string",
                  "description": "Required. Instruction resource name."
                },
                "languageCode": {
                  "type": "string",
                  "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                },
                "replicaCount": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                },
                "questionDuration": {
                  "type": "string",
                  "format": "google-duration",
                  "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                },
                "userEmailAddress": {
                  "type": "string",
                  "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                },
                "contributorEmails": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                },
                "annotatedDatasetDescription": {
                  "type": "string",
                  "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                },
                "annotatedDatasetDisplayName": {
                  "type": "string",
                  "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                }
              },
              "description": "Required. Basic human annotation config."
            },
            "eventConfig": {
              "id": "GoogleCloudDatalabelingV1beta1EventConfig",
              "type": "object",
              "properties": {
                "clipLength": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 60s."
                },
                "overlapLength": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 1s."
                },
                "annotationSpecSets": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Required. The list of annotation spec set resource name. Similar to video classification, we support selecting event from multiple AnnotationSpecSet at the same time."
                }
              },
              "description": "Configuration for video event task. One of video_classification_config, object_detection_config, object_tracking_config and event_config is required."
            },
            "objectTrackingConfig": {
              "id": "GoogleCloudDatalabelingV1beta1ObjectTrackingConfig",
              "type": "object",
              "properties": {
                "clipLength": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 20s."
                },
                "overlapLength": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 0.3s."
                },
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                }
              },
              "description": "Configuration for video object tracking task. One of video_classification_config, object_detection_config, object_tracking_config and event_config is required."
            },
            "objectDetectionConfig": {
              "id": "GoogleCloudDatalabelingV1beta1ObjectDetectionConfig",
              "type": "object",
              "properties": {
                "annotationSpecSet": {
                  "type": "string",
                  "description": "Required. Annotation spec set resource name."
                },
                "extractionFrameRate": {
                  "type": "number",
                  "format": "double",
                  "description": "Required. Number of frames per second to be extracted from the video."
                }
              },
              "description": "Configuration for video object detection task. One of video_classification_config, object_detection_config, object_tracking_config and event_config is required."
            },
            "videoClassificationConfig": {
              "id": "GoogleCloudDatalabelingV1beta1VideoClassificationConfig",
              "type": "object",
              "properties": {
                "applyShotDetection": {
                  "type": "boolean",
                  "description": "Optional. Option to apply shot detection on the video."
                },
                "annotationSpecSetConfigs": {
                  "type": "array",
                  "items": {
                    "id": "GoogleCloudDatalabelingV1beta1AnnotationSpecSetConfig",
                    "type": "object",
                    "properties": {
                      "allowMultiLabel": {
                        "type": "boolean",
                        "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels from one annotation spec set."
                      },
                      "annotationSpecSet": {
                        "type": "string",
                        "description": "Required. Annotation spec set resource name."
                      }
                    },
                    "description": "Annotation spec set with the setting of allowing multi labels or not."
                  },
                  "description": "Required. The list of annotation spec set configs. Since watching a video clip takes much longer time than an image, we support label with multiple AnnotationSpecSet at the same time. Labels in each AnnotationSpecSet will be shown in a group to contributors. Contributors can select one or more (depending on whether to allow multi label) from each group."
                }
              },
              "description": "Configuration for video classification task. One of video_classification_config, object_detection_config, object_tracking_config and event_config is required."
            }
          },
          "description": "Request message for LabelVideo."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.evaluationJobs.create:
    description: |-
      Creates an evaluation job.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/create
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.evaluationJobs.delete:
    description: |-
      Stops and deletes an evaluation job.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.evaluationJobs.get:
    description: |-
      Gets an evaluation job by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1EvaluationJob",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. After you create a job, Data Labeling Service assigns a name to the job with the following format: \"projects/{project_id}/evaluationJobs/ {evaluation_job_id}\""
            },
            "state": {
              "enum": [
                "STATE_UNSPECIFIED",
                "SCHEDULED",
                "RUNNING",
                "PAUSED",
                "STOPPED"
              ],
              "type": "string",
              "description": "Output only. Describes the current state of the job.",
              "enumDescriptions": [
                "",
                "The job is scheduled to run at the configured interval. You can pause or delete the job. When the job is in this state, it samples prediction input and output from your model version into your BigQuery table as predictions occur.",
                "The job is currently running. When the job runs, Data Labeling Service does several things: 1. If you have configured your job to use Data Labeling Service for ground truth labeling, the service creates a Dataset and a labeling task for all data sampled since the last time the job ran. Human labelers provide ground truth labels for your data. Human labeling may take hours, or even days, depending on how much data has been sampled. The job remains in the `RUNNING` state during this time, and it can even be running multiple times in parallel if it gets triggered again (for example 24 hours later) before the earlier run has completed. When human labelers have finished labeling the data, the next step occurs. If you have configured your job to provide your own ground truth labels, Data Labeling Service still creates a Dataset for newly sampled data, but it expects that you have already added ground truth labels to the BigQuery table by this time. The next step occurs immediately. 2. Data Labeling Service creates an Evaluation by comparing your model version's predictions with the ground truth labels. If the job remains in this state for a long time, it continues to sample prediction data into your BigQuery table and will run again at the next interval, even if it causes the job to run multiple times in parallel.",
                "The job is not sampling prediction input and output into your BigQuery table and it will not run according to its schedule. You can resume the job.",
                "The job has this state right before it is deleted."
              ]
            },
            "attempts": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1Attempt",
                "type": "object",
                "properties": {
                  "attemptTime": {
                    "type": "string",
                    "format": "google-datetime"
                  },
                  "partialFailures": {
                    "type": "array",
                    "items": {
                      "id": "GoogleRpcStatus",
                      "type": "object",
                      "properties": {
                        "code": {
                          "type": "integer",
                          "format": "int32",
                          "description": "The status code, which should be an enum value of google.rpc.Code."
                        },
                        "details": {
                          "type": "array",
                          "items": {
                            "type": "object",
                            "additionalProperties": {
                              "type": "any",
                              "description": "Properties of the object. Contains field @type with type URL."
                            }
                          },
                          "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                        },
                        "message": {
                          "type": "string",
                          "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                        }
                      },
                      "description": "The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors)."
                    },
                    "description": "Details of errors that occurred."
                  }
                },
                "description": "Records a failed evaluation job run."
              },
              "description": "Output only. Every time the evaluation job runs and an error occurs, the failed attempt is appended to this array."
            },
            "schedule": {
              "type": "string",
              "description": "Required. Describes the interval at which the job runs. This interval must be at least 1 day, and it is rounded to the nearest day. For example, if you specify a 50-hour interval, the job runs every 2 days. You can provide the schedule in [crontab format](/scheduler/docs/configuring/cron-job-schedules) or in an [English-like format](/appengine/docs/standard/python/config/cronref#schedule_format). Regardless of what you specify, the job will run at 10:00 AM UTC. Only the interval from this schedule is used, not the specific time of day."
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Timestamp of when this evaluation job was created."
            },
            "description": {
              "type": "string",
              "description": "Required. Description of the job. The description can be up to 25,000 characters long."
            },
            "modelVersion": {
              "type": "string",
              "description": "Required. The [AI Platform Prediction model version](/ml-engine/docs/prediction-overview) to be evaluated. Prediction input and output is sampled from this model version. When creating an evaluation job, specify the model version in the following format: \"projects/{project_id}/models/{model_name}/versions/{version_name}\" There can only be one evaluation job per model version."
            },
            "annotationSpecSet": {
              "type": "string",
              "description": "Required. Name of the AnnotationSpecSet describing all the labels that your machine learning model outputs. You must create this resource before you create an evaluation job and provide its name in the following format: \"projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}\""
            },
            "evaluationJobConfig": {
              "id": "GoogleCloudDatalabelingV1beta1EvaluationJobConfig",
              "type": "object",
              "properties": {
                "inputConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1InputConfig",
                  "type": "object",
                  "properties": {
                    "dataType": {
                      "enum": [
                        "DATA_TYPE_UNSPECIFIED",
                        "IMAGE",
                        "VIDEO",
                        "TEXT",
                        "GENERAL_DATA"
                      ],
                      "type": "string",
                      "description": "Required. Data type must be specifed when user tries to import data.",
                      "enumDescriptions": [
                        "Data type is unspecified.",
                        "Allowed for continuous evaluation.",
                        "Video data type.",
                        "Allowed for continuous evaluation.",
                        "Allowed for continuous evaluation."
                      ]
                    },
                    "gcsSource": {
                      "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                      "type": "object",
                      "properties": {
                        "inputUri": {
                          "type": "string",
                          "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                        },
                        "mimeType": {
                          "type": "string",
                          "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                        }
                      },
                      "description": "Source located in Cloud Storage."
                    },
                    "textMetadata": {
                      "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                      "type": "object",
                      "properties": {
                        "languageCode": {
                          "type": "string",
                          "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                        }
                      },
                      "description": "Required for text import, as language code must be specified."
                    },
                    "annotationType": {
                      "enum": [
                        "ANNOTATION_TYPE_UNSPECIFIED",
                        "IMAGE_CLASSIFICATION_ANNOTATION",
                        "IMAGE_BOUNDING_BOX_ANNOTATION",
                        "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                        "IMAGE_BOUNDING_POLY_ANNOTATION",
                        "IMAGE_POLYLINE_ANNOTATION",
                        "IMAGE_SEGMENTATION_ANNOTATION",
                        "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                        "VIDEO_OBJECT_TRACKING_ANNOTATION",
                        "VIDEO_OBJECT_DETECTION_ANNOTATION",
                        "VIDEO_EVENT_ANNOTATION",
                        "TEXT_CLASSIFICATION_ANNOTATION",
                        "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                        "GENERAL_CLASSIFICATION_ANNOTATION"
                      ],
                      "type": "string",
                      "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                      "enumDescriptions": [
                        "",
                        "Classification annotations in an image. Allowed for continuous evaluation.",
                        "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                        "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                        "Bounding poly annotations in an image.",
                        "Polyline annotations in an image.",
                        "Segmentation annotations in an image.",
                        "Classification annotations in video shots.",
                        "Video object tracking annotation.",
                        "Video object detection annotation.",
                        "Video event annotation.",
                        "Classification for text. Allowed for continuous evaluation.",
                        "Entity extraction for text.",
                        "General classification. Allowed for continuous evaluation."
                      ]
                    },
                    "bigquerySource": {
                      "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                      "type": "object",
                      "properties": {
                        "inputUri": {
                          "type": "string",
                          "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                        }
                      },
                      "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                    },
                    "classificationMetadata": {
                      "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                      "type": "object",
                      "properties": {
                        "isMultiLabel": {
                          "type": "boolean",
                          "description": "Whether the classification task is multi-label or not."
                        }
                      },
                      "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                    }
                  },
                  "description": "The configuration of input data, including data type, location, etc."
                },
                "exampleCount": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Required. The maximum number of predictions to sample and save to BigQuery during each evaluation interval. This limit overrides `example_sample_percentage`: even if the service has not sampled enough predictions to fulfill `example_sample_perecentage` during an interval, it stops sampling predictions when it meets this limit."
                },
                "evaluationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1EvaluationConfig",
                  "type": "object",
                  "properties": {
                    "boundingBoxEvaluationOptions": {
                      "id": "GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions",
                      "type": "object",
                      "properties": {
                        "iouThreshold": {
                          "type": "number",
                          "format": "float",
                          "description": "Minimum [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) required for 2 bounding boxes to be considered a match. This must be a number between 0 and 1."
                        }
                      },
                      "description": "Only specify this field if the related model performs image object detection (`IMAGE_BOUNDING_BOX_ANNOTATION`). Describes how to evaluate bounding boxes."
                    }
                  },
                  "description": "Required. Details for calculating evaluation metrics and creating Evaulations. If your model version performs image object detection, you must specify the `boundingBoxEvaluationOptions` field within this configuration. Otherwise, provide an empty object for this configuration."
                },
                "bigqueryImportKeys": {
                  "type": "object",
                  "description": "Required. Prediction keys that tell Data Labeling Service where to find the data for evaluation in your BigQuery table. When the service samples prediction input and output from your model version and saves it to BigQuery, the data gets stored as JSON strings in the BigQuery table. These keys tell Data Labeling Service how to parse the JSON. You can provide the following entries in this field: * `data_json_key`: the data key for prediction input. You must provide either this key or `reference_json_key`. * `reference_json_key`: the data reference key for prediction input. You must provide either this key or `data_json_key`. * `label_json_key`: the label key for prediction output. Required. * `label_score_json_key`: the score key for prediction output. Required. * `bounding_box_json_key`: the bounding box key for prediction output. Required if your model version perform image object detection. Learn [how to configure prediction keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "boundingPolyConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1BoundingPolyConfig",
                  "type": "object",
                  "properties": {
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    },
                    "instructionMessage": {
                      "type": "string",
                      "description": "Optional. Instruction message showed on contributors UI."
                    }
                  },
                  "description": "Specify this field if your model version performs image object detection (bounding box detection). `annotationSpecSet` in this configuration must match EvaluationJob.annotationSpecSet."
                },
                "humanAnnotationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
                  "type": "object",
                  "properties": {
                    "labelGroup": {
                      "type": "string",
                      "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                    },
                    "instruction": {
                      "type": "string",
                      "description": "Required. Instruction resource name."
                    },
                    "languageCode": {
                      "type": "string",
                      "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                    },
                    "replicaCount": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                    },
                    "questionDuration": {
                      "type": "string",
                      "format": "google-duration",
                      "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                    },
                    "userEmailAddress": {
                      "type": "string",
                      "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                    },
                    "contributorEmails": {
                      "type": "array",
                      "items": {
                        "type": "string"
                      },
                      "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                    },
                    "annotatedDatasetDescription": {
                      "type": "string",
                      "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                    },
                    "annotatedDatasetDisplayName": {
                      "type": "string",
                      "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                    }
                  },
                  "description": "Optional. Details for human annotation of your data. If you set labelMissingGroundTruth to `true` for this evaluation job, then you must specify this field. If you plan to provide your own ground truth labels, then omit this field. Note that you must create an Instruction resource before you can specify this field. Provide the name of the instruction resource in the `instruction` field within this configuration."
                },
                "exampleSamplePercentage": {
                  "type": "number",
                  "format": "double",
                  "description": "Required. Fraction of predictions to sample and save to BigQuery during each evaluation interval. For example, 0.1 means 10% of predictions served by your model version get saved to BigQuery."
                },
                "evaluationJobAlertConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig",
                  "type": "object",
                  "properties": {
                    "email": {
                      "type": "string",
                      "description": "Required. An email address to send alerts to."
                    },
                    "minAcceptableMeanAveragePrecision": {
                      "type": "number",
                      "format": "double",
                      "description": "Required. A number between 0 and 1 that describes a minimum mean average precision threshold. When the evaluation job runs, if it calculates that your model version's predictions from the recent interval have meanAveragePrecision below this threshold, then it sends an alert to your specified email."
                    }
                  },
                  "description": "Optional. Configuration details for evaluation job alerts. Specify this field if you want to receive email alerts if the evaluation job finds that your predictions have low mean average precision during a run."
                },
                "textClassificationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1TextClassificationConfig",
                  "type": "object",
                  "properties": {
                    "allowMultiLabel": {
                      "type": "boolean",
                      "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one text segment."
                    },
                    "sentimentConfig": {
                      "id": "GoogleCloudDatalabelingV1beta1SentimentConfig",
                      "type": "object",
                      "properties": {
                        "enableLabelSentimentSelection": {
                          "type": "boolean",
                          "description": "If set to true, contributors will have the option to select sentiment of the label they selected, to mark it as negative or positive label. Default is false."
                        }
                      },
                      "description": "Optional. Configs for sentiment selection. We deprecate sentiment analysis in data labeling side as it is incompatible with uCAIP."
                    },
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    }
                  },
                  "description": "Specify this field if your model version performs text classification. `annotationSpecSet` in this configuration must match EvaluationJob.annotationSpecSet. `allowMultiLabel` in this configuration must match `classificationMetadata.isMultiLabel` in input_config."
                },
                "imageClassificationConfig": {
                  "id": "GoogleCloudDatalabelingV1beta1ImageClassificationConfig",
                  "type": "object",
                  "properties": {
                    "allowMultiLabel": {
                      "type": "boolean",
                      "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one image."
                    },
                    "annotationSpecSet": {
                      "type": "string",
                      "description": "Required. Annotation spec set resource name."
                    },
                    "answerAggregationType": {
                      "enum": [
                        "STRING_AGGREGATION_TYPE_UNSPECIFIED",
                        "MAJORITY_VOTE",
                        "UNANIMOUS_VOTE",
                        "NO_AGGREGATION"
                      ],
                      "type": "string",
                      "description": "Optional. The type of how to aggregate answers.",
                      "enumDescriptions": [
                        "",
                        "Majority vote to aggregate answers.",
                        "Unanimous answers will be adopted.",
                        "Preserve all answers by crowd compute."
                      ]
                    }
                  },
                  "description": "Specify this field if your model version performs image classification or general classification. `annotationSpecSet` in this configuration must match EvaluationJob.annotationSpecSet. `allowMultiLabel` in this configuration must match `classificationMetadata.isMultiLabel` in input_config."
                }
              },
              "description": "Required. Configuration details for the evaluation job."
            },
            "labelMissingGroundTruth": {
              "type": "boolean",
              "description": "Required. Whether you want Data Labeling Service to provide ground truth labels for prediction input. If you want the service to assign human labelers to annotate your data, set this to `true`. If you want to provide your own ground truth labels in the evaluation job's BigQuery table, set this to `false`."
            }
          },
          "description": "Defines an evaluation job that runs periodically to generate Evaluations. [Creating an evaluation job](/ml-engine/docs/continuous-evaluation/create-job) is the starting point for using continuous evaluation."
        }
      ]
  projects.evaluationJobs.list:
    description: |-
      Lists all evaluation jobs within a project with possible filters. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListEvaluationJobsResponse",
          "type": "object",
          "properties": {
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            },
            "evaluationJobs": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1EvaluationJob",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. After you create a job, Data Labeling Service assigns a name to the job with the following format: \"projects/{project_id}/evaluationJobs/ {evaluation_job_id}\""
                  },
                  "state": {
                    "enum": [
                      "STATE_UNSPECIFIED",
                      "SCHEDULED",
                      "RUNNING",
                      "PAUSED",
                      "STOPPED"
                    ],
                    "type": "string",
                    "description": "Output only. Describes the current state of the job.",
                    "enumDescriptions": [
                      "",
                      "The job is scheduled to run at the configured interval. You can pause or delete the job. When the job is in this state, it samples prediction input and output from your model version into your BigQuery table as predictions occur.",
                      "The job is currently running. When the job runs, Data Labeling Service does several things: 1. If you have configured your job to use Data Labeling Service for ground truth labeling, the service creates a Dataset and a labeling task for all data sampled since the last time the job ran. Human labelers provide ground truth labels for your data. Human labeling may take hours, or even days, depending on how much data has been sampled. The job remains in the `RUNNING` state during this time, and it can even be running multiple times in parallel if it gets triggered again (for example 24 hours later) before the earlier run has completed. When human labelers have finished labeling the data, the next step occurs. If you have configured your job to provide your own ground truth labels, Data Labeling Service still creates a Dataset for newly sampled data, but it expects that you have already added ground truth labels to the BigQuery table by this time. The next step occurs immediately. 2. Data Labeling Service creates an Evaluation by comparing your model version's predictions with the ground truth labels. If the job remains in this state for a long time, it continues to sample prediction data into your BigQuery table and will run again at the next interval, even if it causes the job to run multiple times in parallel.",
                      "The job is not sampling prediction input and output into your BigQuery table and it will not run according to its schedule. You can resume the job.",
                      "The job has this state right before it is deleted."
                    ]
                  },
                  "attempts": {
                    "type": "array",
                    "items": {
                      "id": "GoogleCloudDatalabelingV1beta1Attempt",
                      "type": "object",
                      "properties": {
                        "attemptTime": {
                          "type": "string",
                          "format": "google-datetime"
                        },
                        "partialFailures": {
                          "type": "array",
                          "items": {
                            "id": "GoogleRpcStatus",
                            "type": "object",
                            "properties": {
                              "code": {
                                "type": "integer",
                                "format": "int32",
                                "description": "The status code, which should be an enum value of google.rpc.Code."
                              },
                              "details": {
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "additionalProperties": {
                                    "type": "any",
                                    "description": "Properties of the object. Contains field @type with type URL."
                                  }
                                },
                                "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                              },
                              "message": {
                                "type": "string",
                                "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                              }
                            },
                            "description": "The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors)."
                          },
                          "description": "Details of errors that occurred."
                        }
                      },
                      "description": "Records a failed evaluation job run."
                    },
                    "description": "Output only. Every time the evaluation job runs and an error occurs, the failed attempt is appended to this array."
                  },
                  "schedule": {
                    "type": "string",
                    "description": "Required. Describes the interval at which the job runs. This interval must be at least 1 day, and it is rounded to the nearest day. For example, if you specify a 50-hour interval, the job runs every 2 days. You can provide the schedule in [crontab format](/scheduler/docs/configuring/cron-job-schedules) or in an [English-like format](/appengine/docs/standard/python/config/cronref#schedule_format). Regardless of what you specify, the job will run at 10:00 AM UTC. Only the interval from this schedule is used, not the specific time of day."
                  },
                  "createTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Timestamp of when this evaluation job was created."
                  },
                  "description": {
                    "type": "string",
                    "description": "Required. Description of the job. The description can be up to 25,000 characters long."
                  },
                  "modelVersion": {
                    "type": "string",
                    "description": "Required. The [AI Platform Prediction model version](/ml-engine/docs/prediction-overview) to be evaluated. Prediction input and output is sampled from this model version. When creating an evaluation job, specify the model version in the following format: \"projects/{project_id}/models/{model_name}/versions/{version_name}\" There can only be one evaluation job per model version."
                  },
                  "annotationSpecSet": {
                    "type": "string",
                    "description": "Required. Name of the AnnotationSpecSet describing all the labels that your machine learning model outputs. You must create this resource before you create an evaluation job and provide its name in the following format: \"projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}\""
                  },
                  "evaluationJobConfig": {
                    "id": "GoogleCloudDatalabelingV1beta1EvaluationJobConfig",
                    "type": "object",
                    "properties": {
                      "inputConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1InputConfig",
                        "type": "object",
                        "properties": {
                          "dataType": {
                            "enum": [
                              "DATA_TYPE_UNSPECIFIED",
                              "IMAGE",
                              "VIDEO",
                              "TEXT",
                              "GENERAL_DATA"
                            ],
                            "type": "string",
                            "description": "Required. Data type must be specifed when user tries to import data.",
                            "enumDescriptions": [
                              "Data type is unspecified.",
                              "Allowed for continuous evaluation.",
                              "Video data type.",
                              "Allowed for continuous evaluation.",
                              "Allowed for continuous evaluation."
                            ]
                          },
                          "gcsSource": {
                            "id": "GoogleCloudDatalabelingV1beta1GcsSource",
                            "type": "object",
                            "properties": {
                              "inputUri": {
                                "type": "string",
                                "description": "Required. The input URI of source file. This must be a Cloud Storage path (`gs://...`)."
                              },
                              "mimeType": {
                                "type": "string",
                                "description": "Required. The format of the source file. Only \"text/csv\" is supported."
                              }
                            },
                            "description": "Source located in Cloud Storage."
                          },
                          "textMetadata": {
                            "id": "GoogleCloudDatalabelingV1beta1TextMetadata",
                            "type": "object",
                            "properties": {
                              "languageCode": {
                                "type": "string",
                                "description": "The language of this text, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US."
                              }
                            },
                            "description": "Required for text import, as language code must be specified."
                          },
                          "annotationType": {
                            "enum": [
                              "ANNOTATION_TYPE_UNSPECIFIED",
                              "IMAGE_CLASSIFICATION_ANNOTATION",
                              "IMAGE_BOUNDING_BOX_ANNOTATION",
                              "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                              "IMAGE_BOUNDING_POLY_ANNOTATION",
                              "IMAGE_POLYLINE_ANNOTATION",
                              "IMAGE_SEGMENTATION_ANNOTATION",
                              "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                              "VIDEO_OBJECT_TRACKING_ANNOTATION",
                              "VIDEO_OBJECT_DETECTION_ANNOTATION",
                              "VIDEO_EVENT_ANNOTATION",
                              "TEXT_CLASSIFICATION_ANNOTATION",
                              "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                              "GENERAL_CLASSIFICATION_ANNOTATION"
                            ],
                            "type": "string",
                            "description": "Optional. The type of annotation to be performed on this data. You must specify this field if you are using this InputConfig in an EvaluationJob.",
                            "enumDescriptions": [
                              "",
                              "Classification annotations in an image. Allowed for continuous evaluation.",
                              "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                              "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                              "Bounding poly annotations in an image.",
                              "Polyline annotations in an image.",
                              "Segmentation annotations in an image.",
                              "Classification annotations in video shots.",
                              "Video object tracking annotation.",
                              "Video object detection annotation.",
                              "Video event annotation.",
                              "Classification for text. Allowed for continuous evaluation.",
                              "Entity extraction for text.",
                              "General classification. Allowed for continuous evaluation."
                            ]
                          },
                          "bigquerySource": {
                            "id": "GoogleCloudDatalabelingV1beta1BigQuerySource",
                            "type": "object",
                            "properties": {
                              "inputUri": {
                                "type": "string",
                                "description": "Required. BigQuery URI to a table, up to 2,000 characters long. If you specify the URI of a table that does not exist, Data Labeling Service creates a table at the URI with the correct schema when you create your EvaluationJob. If you specify the URI of a table that already exists, it must have the [correct schema](/ml-engine/docs/continuous-evaluation/create-job#table-schema). Provide the table URI in the following format: \"bq://{your_project_id}/ {your_dataset_name}/{your_table_name}\" [Learn more](/ml-engine/docs/continuous-evaluation/create-job#table-schema)."
                              }
                            },
                            "description": "Source located in BigQuery. You must specify this field if you are using this InputConfig in an EvaluationJob."
                          },
                          "classificationMetadata": {
                            "id": "GoogleCloudDatalabelingV1beta1ClassificationMetadata",
                            "type": "object",
                            "properties": {
                              "isMultiLabel": {
                                "type": "boolean",
                                "description": "Whether the classification task is multi-label or not."
                              }
                            },
                            "description": "Optional. Metadata about annotations for the input. You must specify this field if you are using this InputConfig in an EvaluationJob for a model version that performs classification."
                          }
                        },
                        "description": "The configuration of input data, including data type, location, etc."
                      },
                      "exampleCount": {
                        "type": "integer",
                        "format": "int32",
                        "description": "Required. The maximum number of predictions to sample and save to BigQuery during each evaluation interval. This limit overrides `example_sample_percentage`: even if the service has not sampled enough predictions to fulfill `example_sample_perecentage` during an interval, it stops sampling predictions when it meets this limit."
                      },
                      "evaluationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1EvaluationConfig",
                        "type": "object",
                        "properties": {
                          "boundingBoxEvaluationOptions": {
                            "id": "GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions",
                            "type": "object",
                            "properties": {
                              "iouThreshold": {
                                "type": "number",
                                "format": "float",
                                "description": "Minimum [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) required for 2 bounding boxes to be considered a match. This must be a number between 0 and 1."
                              }
                            },
                            "description": "Only specify this field if the related model performs image object detection (`IMAGE_BOUNDING_BOX_ANNOTATION`). Describes how to evaluate bounding boxes."
                          }
                        },
                        "description": "Required. Details for calculating evaluation metrics and creating Evaulations. If your model version performs image object detection, you must specify the `boundingBoxEvaluationOptions` field within this configuration. Otherwise, provide an empty object for this configuration."
                      },
                      "bigqueryImportKeys": {
                        "type": "object",
                        "description": "Required. Prediction keys that tell Data Labeling Service where to find the data for evaluation in your BigQuery table. When the service samples prediction input and output from your model version and saves it to BigQuery, the data gets stored as JSON strings in the BigQuery table. These keys tell Data Labeling Service how to parse the JSON. You can provide the following entries in this field: * `data_json_key`: the data key for prediction input. You must provide either this key or `reference_json_key`. * `reference_json_key`: the data reference key for prediction input. You must provide either this key or `data_json_key`. * `label_json_key`: the label key for prediction output. Required. * `label_score_json_key`: the score key for prediction output. Required. * `bounding_box_json_key`: the bounding box key for prediction output. Required if your model version perform image object detection. Learn [how to configure prediction keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).",
                        "additionalProperties": {
                          "type": "string"
                        }
                      },
                      "boundingPolyConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1BoundingPolyConfig",
                        "type": "object",
                        "properties": {
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          },
                          "instructionMessage": {
                            "type": "string",
                            "description": "Optional. Instruction message showed on contributors UI."
                          }
                        },
                        "description": "Specify this field if your model version performs image object detection (bounding box detection). `annotationSpecSet` in this configuration must match EvaluationJob.annotationSpecSet."
                      },
                      "humanAnnotationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1HumanAnnotationConfig",
                        "type": "object",
                        "properties": {
                          "labelGroup": {
                            "type": "string",
                            "description": "Optional. A human-readable label used to logically group labeling tasks. This string must match the regular expression `[a-zA-Z\\\\d_-]{0,128}`."
                          },
                          "instruction": {
                            "type": "string",
                            "description": "Required. Instruction resource name."
                          },
                          "languageCode": {
                            "type": "string",
                            "description": "Optional. The Language of this question, as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt). Default value is en-US. Only need to set this when task is language related. For example, French text classification."
                          },
                          "replicaCount": {
                            "type": "integer",
                            "format": "int32",
                            "description": "Optional. Replication of questions. Each question will be sent to up to this number of contributors to label. Aggregated answers will be returned. Default is set to 1. For image related labeling, valid values are 1, 3, 5."
                          },
                          "questionDuration": {
                            "type": "string",
                            "format": "google-duration",
                            "description": "Optional. Maximum duration for contributors to answer a question. Maximum is 3600 seconds. Default is 3600 seconds."
                          },
                          "userEmailAddress": {
                            "type": "string",
                            "description": "Email of the user who started the labeling task and should be notified by email. If empty no notification will be sent."
                          },
                          "contributorEmails": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "Optional. If you want your own labeling contributors to manage and work on this labeling request, you can set these contributors here. We will give them access to the question types in crowdcompute. Note that these emails must be registered in crowdcompute worker UI: https://crowd-compute.appspot.com/"
                          },
                          "annotatedDatasetDescription": {
                            "type": "string",
                            "description": "Optional. A human-readable description for AnnotatedDataset. The description can be up to 10000 characters long."
                          },
                          "annotatedDatasetDisplayName": {
                            "type": "string",
                            "description": "Required. A human-readable name for AnnotatedDataset defined by users. Maximum of 64 characters ."
                          }
                        },
                        "description": "Optional. Details for human annotation of your data. If you set labelMissingGroundTruth to `true` for this evaluation job, then you must specify this field. If you plan to provide your own ground truth labels, then omit this field. Note that you must create an Instruction resource before you can specify this field. Provide the name of the instruction resource in the `instruction` field within this configuration."
                      },
                      "exampleSamplePercentage": {
                        "type": "number",
                        "format": "double",
                        "description": "Required. Fraction of predictions to sample and save to BigQuery during each evaluation interval. For example, 0.1 means 10% of predictions served by your model version get saved to BigQuery."
                      },
                      "evaluationJobAlertConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig",
                        "type": "object",
                        "properties": {
                          "email": {
                            "type": "string",
                            "description": "Required. An email address to send alerts to."
                          },
                          "minAcceptableMeanAveragePrecision": {
                            "type": "number",
                            "format": "double",
                            "description": "Required. A number between 0 and 1 that describes a minimum mean average precision threshold. When the evaluation job runs, if it calculates that your model version's predictions from the recent interval have meanAveragePrecision below this threshold, then it sends an alert to your specified email."
                          }
                        },
                        "description": "Optional. Configuration details for evaluation job alerts. Specify this field if you want to receive email alerts if the evaluation job finds that your predictions have low mean average precision during a run."
                      },
                      "textClassificationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1TextClassificationConfig",
                        "type": "object",
                        "properties": {
                          "allowMultiLabel": {
                            "type": "boolean",
                            "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one text segment."
                          },
                          "sentimentConfig": {
                            "id": "GoogleCloudDatalabelingV1beta1SentimentConfig",
                            "type": "object",
                            "properties": {
                              "enableLabelSentimentSelection": {
                                "type": "boolean",
                                "description": "If set to true, contributors will have the option to select sentiment of the label they selected, to mark it as negative or positive label. Default is false."
                              }
                            },
                            "description": "Optional. Configs for sentiment selection. We deprecate sentiment analysis in data labeling side as it is incompatible with uCAIP."
                          },
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          }
                        },
                        "description": "Specify this field if your model version performs text classification. `annotationSpecSet` in this configuration must match EvaluationJob.annotationSpecSet. `allowMultiLabel` in this configuration must match `classificationMetadata.isMultiLabel` in input_config."
                      },
                      "imageClassificationConfig": {
                        "id": "GoogleCloudDatalabelingV1beta1ImageClassificationConfig",
                        "type": "object",
                        "properties": {
                          "allowMultiLabel": {
                            "type": "boolean",
                            "description": "Optional. If allow_multi_label is true, contributors are able to choose multiple labels for one image."
                          },
                          "annotationSpecSet": {
                            "type": "string",
                            "description": "Required. Annotation spec set resource name."
                          },
                          "answerAggregationType": {
                            "enum": [
                              "STRING_AGGREGATION_TYPE_UNSPECIFIED",
                              "MAJORITY_VOTE",
                              "UNANIMOUS_VOTE",
                              "NO_AGGREGATION"
                            ],
                            "type": "string",
                            "description": "Optional. The type of how to aggregate answers.",
                            "enumDescriptions": [
                              "",
                              "Majority vote to aggregate answers.",
                              "Unanimous answers will be adopted.",
                              "Preserve all answers by crowd compute."
                            ]
                          }
                        },
                        "description": "Specify this field if your model version performs image classification or general classification. `annotationSpecSet` in this configuration must match EvaluationJob.annotationSpecSet. `allowMultiLabel` in this configuration must match `classificationMetadata.isMultiLabel` in input_config."
                      }
                    },
                    "description": "Required. Configuration details for the evaluation job."
                  },
                  "labelMissingGroundTruth": {
                    "type": "boolean",
                    "description": "Required. Whether you want Data Labeling Service to provide ground truth labels for prediction input. If you want the service to assign human labelers to annotate your data, set this to `true`. If you want to provide your own ground truth labels in the evaluation job's BigQuery table, set this to `false`."
                  }
                },
                "description": "Defines an evaluation job that runs periodically to generate Evaluations. [Creating an evaluation job](/ml-engine/docs/continuous-evaluation/create-job) is the starting point for using continuous evaluation."
              },
              "description": "The list of evaluation jobs to return."
            }
          },
          "description": "Results for listing evaluation jobs."
        }
      ]
  projects.evaluationJobs.patch:
    description: |-
      Updates an evaluation job. You can only update certain fields of the job's EvaluationJobConfig: `humanAnnotationConfig.instruction`, `exampleCount`, and `exampleSamplePercentage`. If you want to change any other aspect of the evaluation job, you must delete the job and create a new one.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/patch
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.evaluationJobs.pause:
    description: |-
      Pauses an evaluation job. Pausing an evaluation job that is already in a `PAUSED` state is a no-op.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/pause
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1PauseEvaluationJobRequest",
          "type": "object",
          "properties": {},
          "description": "Request message for PauseEvaluationJob."
        }
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.evaluationJobs.resume:
    description: |-
      Resumes a paused evaluation job. A deleted evaluation job can't be resumed. Resuming a running or scheduled evaluation job is a no-op.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluationJobs/resume
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ResumeEvaluationJobRequest",
          "type": "object",
          "properties": {},
          "description": "Request message ResumeEvaluationJob."
        }
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.evaluations.search:
    description: |-
      Searches evaluations within a project.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.evaluations/search
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1SearchEvaluationsResponse",
          "type": "object",
          "properties": {
            "evaluations": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1Evaluation",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Resource name of an evaluation. The name has the following format: \"projects/{project_id}/datasets/{dataset_id}/evaluations/ {evaluation_id}'"
                  },
                  "config": {
                    "id": "GoogleCloudDatalabelingV1beta1EvaluationConfig",
                    "type": "object",
                    "properties": {
                      "boundingBoxEvaluationOptions": {
                        "id": "GoogleCloudDatalabelingV1beta1BoundingBoxEvaluationOptions",
                        "type": "object",
                        "properties": {
                          "iouThreshold": {
                            "type": "number",
                            "format": "float",
                            "description": "Minimum [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) required for 2 bounding boxes to be considered a match. This must be a number between 0 and 1."
                          }
                        },
                        "description": "Only specify this field if the related model performs image object detection (`IMAGE_BOUNDING_BOX_ANNOTATION`). Describes how to evaluate bounding boxes."
                      }
                    },
                    "description": "Output only. Options used in the evaluation job that created this evaluation."
                  },
                  "createTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Timestamp for when this evaluation was created."
                  },
                  "annotationType": {
                    "enum": [
                      "ANNOTATION_TYPE_UNSPECIFIED",
                      "IMAGE_CLASSIFICATION_ANNOTATION",
                      "IMAGE_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_ORIENTED_BOUNDING_BOX_ANNOTATION",
                      "IMAGE_BOUNDING_POLY_ANNOTATION",
                      "IMAGE_POLYLINE_ANNOTATION",
                      "IMAGE_SEGMENTATION_ANNOTATION",
                      "VIDEO_SHOTS_CLASSIFICATION_ANNOTATION",
                      "VIDEO_OBJECT_TRACKING_ANNOTATION",
                      "VIDEO_OBJECT_DETECTION_ANNOTATION",
                      "VIDEO_EVENT_ANNOTATION",
                      "TEXT_CLASSIFICATION_ANNOTATION",
                      "TEXT_ENTITY_EXTRACTION_ANNOTATION",
                      "GENERAL_CLASSIFICATION_ANNOTATION"
                    ],
                    "type": "string",
                    "description": "Output only. Type of task that the model version being evaluated performs, as defined in the evaluationJobConfig.inputConfig.annotationType field of the evaluation job that created this evaluation.",
                    "enumDescriptions": [
                      "",
                      "Classification annotations in an image. Allowed for continuous evaluation.",
                      "Bounding box annotations in an image. A form of image object detection. Allowed for continuous evaluation.",
                      "Oriented bounding box. The box does not have to be parallel to horizontal line.",
                      "Bounding poly annotations in an image.",
                      "Polyline annotations in an image.",
                      "Segmentation annotations in an image.",
                      "Classification annotations in video shots.",
                      "Video object tracking annotation.",
                      "Video object detection annotation.",
                      "Video event annotation.",
                      "Classification for text. Allowed for continuous evaluation.",
                      "Entity extraction for text.",
                      "General classification. Allowed for continuous evaluation."
                    ]
                  },
                  "evaluationMetrics": {
                    "id": "GoogleCloudDatalabelingV1beta1EvaluationMetrics",
                    "type": "object",
                    "properties": {
                      "classificationMetrics": {
                        "id": "GoogleCloudDatalabelingV1beta1ClassificationMetrics",
                        "type": "object",
                        "properties": {
                          "prCurve": {
                            "id": "GoogleCloudDatalabelingV1beta1PrCurve",
                            "type": "object",
                            "properties": {
                              "annotationSpec": {
                                "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                "type": "object",
                                "properties": {
                                  "index": {
                                    "type": "integer",
                                    "format": "int32",
                                    "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                  },
                                  "description": {
                                    "type": "string",
                                    "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                  },
                                  "displayName": {
                                    "type": "string",
                                    "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                  }
                                },
                                "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                              },
                              "areaUnderCurve": {
                                "type": "number",
                                "format": "float",
                                "description": "Area under the precision-recall curve. Not to be confused with area under a receiver operating characteristic (ROC) curve."
                              },
                              "meanAveragePrecision": {
                                "type": "number",
                                "format": "float",
                                "description": "Mean average prcision of this curve."
                              },
                              "confidenceMetricsEntries": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry",
                                  "type": "object",
                                  "properties": {
                                    "recall": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Recall value."
                                    },
                                    "f1Score": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Harmonic mean of recall and precision."
                                    },
                                    "precision": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Precision value."
                                    },
                                    "recallAt1": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Recall value for entries with label that has highest score."
                                    },
                                    "recallAt5": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Recall value for entries with label that has highest 5 scores."
                                    },
                                    "f1ScoreAt1": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "The harmonic mean of recall_at1 and precision_at1."
                                    },
                                    "f1ScoreAt5": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "The harmonic mean of recall_at5 and precision_at5."
                                    },
                                    "precisionAt1": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Precision value for entries with label that has highest score."
                                    },
                                    "precisionAt5": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Precision value for entries with label that has highest 5 scores."
                                    },
                                    "confidenceThreshold": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Threshold used for this entry. For classification tasks, this is a classification threshold: a predicted label is categorized as positive or negative (in the context of this point on the PR curve) based on whether the label's score meets this threshold. For image object detection (bounding box) tasks, this is the [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) threshold for the context of this point on the PR curve."
                                    }
                                  }
                                },
                                "description": "Entries that make up the precision-recall graph. Each entry is a \"point\" on the graph drawn for a different `confidence_threshold`."
                              }
                            },
                            "description": "Precision-recall curve based on ground truth labels, predicted labels, and scores for the predicted labels."
                          },
                          "confusionMatrix": {
                            "id": "GoogleCloudDatalabelingV1beta1ConfusionMatrix",
                            "type": "object",
                            "properties": {
                              "row": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1Row",
                                  "type": "object",
                                  "properties": {
                                    "entries": {
                                      "type": "array",
                                      "items": {
                                        "id": "GoogleCloudDatalabelingV1beta1ConfusionMatrixEntry",
                                        "type": "object",
                                        "properties": {
                                          "itemCount": {
                                            "type": "integer",
                                            "format": "int32",
                                            "description": "Number of items predicted to have this label. (The ground truth label for these items is the `Row.annotationSpec` of this entry's parent.)"
                                          },
                                          "annotationSpec": {
                                            "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                            "type": "object",
                                            "properties": {
                                              "index": {
                                                "type": "integer",
                                                "format": "int32",
                                                "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                              },
                                              "description": {
                                                "type": "string",
                                                "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                              },
                                              "displayName": {
                                                "type": "string",
                                                "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                              }
                                            },
                                            "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                          }
                                        }
                                      },
                                      "description": "A list of the confusion matrix entries. One entry for each possible predicted label."
                                    },
                                    "annotationSpec": {
                                      "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                      "type": "object",
                                      "properties": {
                                        "index": {
                                          "type": "integer",
                                          "format": "int32",
                                          "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                        },
                                        "description": {
                                          "type": "string",
                                          "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                        },
                                        "displayName": {
                                          "type": "string",
                                          "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                        }
                                      },
                                      "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                                    }
                                  },
                                  "description": "A row in the confusion matrix. Each entry in this row has the same ground truth label."
                                }
                              }
                            },
                            "description": "Confusion matrix of predicted labels vs. ground truth labels."
                          }
                        },
                        "description": "Metrics calculated for a classification model."
                      },
                      "objectDetectionMetrics": {
                        "id": "GoogleCloudDatalabelingV1beta1ObjectDetectionMetrics",
                        "type": "object",
                        "properties": {
                          "prCurve": {
                            "id": "GoogleCloudDatalabelingV1beta1PrCurve",
                            "type": "object",
                            "properties": {
                              "annotationSpec": {
                                "id": "GoogleCloudDatalabelingV1beta1AnnotationSpec",
                                "type": "object",
                                "properties": {
                                  "index": {
                                    "type": "integer",
                                    "format": "int32",
                                    "description": "Output only. This is the integer index of the AnnotationSpec. The index for the whole AnnotationSpecSet is sequential starting from 0. For example, an AnnotationSpecSet with classes `dog` and `cat`, might contain one AnnotationSpec with `{ display_name: \"dog\", index: 0 }` and one AnnotationSpec with `{ display_name: \"cat\", index: 1 }`. This is especially useful for model training as it encodes the string labels into numeric values."
                                  },
                                  "description": {
                                    "type": "string",
                                    "description": "Optional. User-provided description of the annotation specification. The description can be up to 10,000 characters long."
                                  },
                                  "displayName": {
                                    "type": "string",
                                    "description": "Required. The display name of the AnnotationSpec. Maximum of 64 characters."
                                  }
                                },
                                "description": "Container of information related to one possible annotation that can be used in a labeling task. For example, an image classification task where images are labeled as `dog` or `cat` must reference an AnnotationSpec for `dog` and an AnnotationSpec for `cat`."
                              },
                              "areaUnderCurve": {
                                "type": "number",
                                "format": "float",
                                "description": "Area under the precision-recall curve. Not to be confused with area under a receiver operating characteristic (ROC) curve."
                              },
                              "meanAveragePrecision": {
                                "type": "number",
                                "format": "float",
                                "description": "Mean average prcision of this curve."
                              },
                              "confidenceMetricsEntries": {
                                "type": "array",
                                "items": {
                                  "id": "GoogleCloudDatalabelingV1beta1ConfidenceMetricsEntry",
                                  "type": "object",
                                  "properties": {
                                    "recall": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Recall value."
                                    },
                                    "f1Score": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Harmonic mean of recall and precision."
                                    },
                                    "precision": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Precision value."
                                    },
                                    "recallAt1": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Recall value for entries with label that has highest score."
                                    },
                                    "recallAt5": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Recall value for entries with label that has highest 5 scores."
                                    },
                                    "f1ScoreAt1": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "The harmonic mean of recall_at1 and precision_at1."
                                    },
                                    "f1ScoreAt5": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "The harmonic mean of recall_at5 and precision_at5."
                                    },
                                    "precisionAt1": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Precision value for entries with label that has highest score."
                                    },
                                    "precisionAt5": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Precision value for entries with label that has highest 5 scores."
                                    },
                                    "confidenceThreshold": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Threshold used for this entry. For classification tasks, this is a classification threshold: a predicted label is categorized as positive or negative (in the context of this point on the PR curve) based on whether the label's score meets this threshold. For image object detection (bounding box) tasks, this is the [intersection-over-union (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union) threshold for the context of this point on the PR curve."
                                    }
                                  }
                                },
                                "description": "Entries that make up the precision-recall graph. Each entry is a \"point\" on the graph drawn for a different `confidence_threshold`."
                              }
                            },
                            "description": "Precision-recall curve."
                          }
                        },
                        "description": "Metrics calculated for an image object detection (bounding box) model."
                      }
                    },
                    "description": "Output only. Metrics comparing predictions to ground truth labels."
                  },
                  "evaluatedItemCount": {
                    "type": "string",
                    "format": "int64",
                    "description": "Output only. The number of items in the ground truth dataset that were used for this evaluation. Only populated when the evaulation is for certain AnnotationTypes."
                  },
                  "evaluationJobRunTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Timestamp for when the evaluation job that created this evaluation ran."
                  }
                },
                "description": "Describes an evaluation between a machine learning model's predictions and ground truth labels. Created when an EvaluationJob runs successfully."
              },
              "description": "The list of evaluations matching the search."
            },
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            }
          },
          "description": "Results of searching evaluations."
        }
      ]
  projects.instructions.create:
    description: |-
      Creates an instruction for how data should be labeled.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.instructions/create
    example:
      inputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1CreateInstructionRequest",
          "type": "object",
          "properties": {
            "instruction": {
              "id": "GoogleCloudDatalabelingV1beta1Instruction",
              "type": "object",
              "properties": {
                "name": {
                  "type": "string",
                  "description": "Output only. Instruction resource name, format: projects/{project_id}/instructions/{instruction_id}"
                },
                "dataType": {
                  "enum": [
                    "DATA_TYPE_UNSPECIFIED",
                    "IMAGE",
                    "VIDEO",
                    "TEXT",
                    "GENERAL_DATA"
                  ],
                  "type": "string",
                  "description": "Required. The data type of this instruction.",
                  "enumDescriptions": [
                    "Data type is unspecified.",
                    "Allowed for continuous evaluation.",
                    "Video data type.",
                    "Allowed for continuous evaluation.",
                    "Allowed for continuous evaluation."
                  ]
                },
                "createTime": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "Output only. Creation time of instruction."
                },
                "updateTime": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "Output only. Last update time of instruction."
                },
                "description": {
                  "type": "string",
                  "description": "Optional. User-provided description of the instruction. The description can be up to 10000 characters long."
                },
                "displayName": {
                  "type": "string",
                  "description": "Required. The display name of the instruction. Maximum of 64 characters."
                },
                "csvInstruction": {
                  "id": "GoogleCloudDatalabelingV1beta1CsvInstruction",
                  "type": "object",
                  "properties": {
                    "gcsFileUri": {
                      "type": "string",
                      "description": "CSV file for the instruction. Only gcs path is allowed."
                    }
                  },
                  "description": "Deprecated: this instruction format is not supported any more. Instruction from a CSV file, such as for classification task. The CSV file should have exact two columns, in the following format: * The first column is labeled data, such as an image reference, text. * The second column is comma separated labels associated with data."
                },
                "pdfInstruction": {
                  "id": "GoogleCloudDatalabelingV1beta1PdfInstruction",
                  "type": "object",
                  "properties": {
                    "gcsFileUri": {
                      "type": "string",
                      "description": "PDF file for the instruction. Only gcs path is allowed."
                    }
                  },
                  "description": "Instruction from a PDF document. The PDF should be in a Cloud Storage bucket."
                },
                "blockingResources": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Output only. The names of any related resources that are blocking changes to the instruction."
                }
              },
              "description": "Required. Instruction of how to perform the labeling task."
            }
          },
          "description": "Request message for CreateInstruction."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.instructions.delete:
    description: |-
      Deletes an instruction object by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.instructions/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.instructions.get:
    description: |-
      Gets an instruction by resource name.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.instructions/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1Instruction",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "Output only. Instruction resource name, format: projects/{project_id}/instructions/{instruction_id}"
            },
            "dataType": {
              "enum": [
                "DATA_TYPE_UNSPECIFIED",
                "IMAGE",
                "VIDEO",
                "TEXT",
                "GENERAL_DATA"
              ],
              "type": "string",
              "description": "Required. The data type of this instruction.",
              "enumDescriptions": [
                "Data type is unspecified.",
                "Allowed for continuous evaluation.",
                "Video data type.",
                "Allowed for continuous evaluation.",
                "Allowed for continuous evaluation."
              ]
            },
            "createTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Creation time of instruction."
            },
            "updateTime": {
              "type": "string",
              "format": "google-datetime",
              "description": "Output only. Last update time of instruction."
            },
            "description": {
              "type": "string",
              "description": "Optional. User-provided description of the instruction. The description can be up to 10000 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "Required. The display name of the instruction. Maximum of 64 characters."
            },
            "csvInstruction": {
              "id": "GoogleCloudDatalabelingV1beta1CsvInstruction",
              "type": "object",
              "properties": {
                "gcsFileUri": {
                  "type": "string",
                  "description": "CSV file for the instruction. Only gcs path is allowed."
                }
              },
              "description": "Deprecated: this instruction format is not supported any more. Instruction from a CSV file, such as for classification task. The CSV file should have exact two columns, in the following format: * The first column is labeled data, such as an image reference, text. * The second column is comma separated labels associated with data."
            },
            "pdfInstruction": {
              "id": "GoogleCloudDatalabelingV1beta1PdfInstruction",
              "type": "object",
              "properties": {
                "gcsFileUri": {
                  "type": "string",
                  "description": "PDF file for the instruction. Only gcs path is allowed."
                }
              },
              "description": "Instruction from a PDF document. The PDF should be in a Cloud Storage bucket."
            },
            "blockingResources": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Output only. The names of any related resources that are blocking changes to the instruction."
            }
          },
          "description": "Instruction of how to perform the labeling task for human operators. Currently only PDF instruction is supported."
        }
      ]
  projects.instructions.list:
    description: |-
      Lists instructions for a project. Pagination is supported.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.instructions/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleCloudDatalabelingV1beta1ListInstructionsResponse",
          "type": "object",
          "properties": {
            "instructions": {
              "type": "array",
              "items": {
                "id": "GoogleCloudDatalabelingV1beta1Instruction",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Output only. Instruction resource name, format: projects/{project_id}/instructions/{instruction_id}"
                  },
                  "dataType": {
                    "enum": [
                      "DATA_TYPE_UNSPECIFIED",
                      "IMAGE",
                      "VIDEO",
                      "TEXT",
                      "GENERAL_DATA"
                    ],
                    "type": "string",
                    "description": "Required. The data type of this instruction.",
                    "enumDescriptions": [
                      "Data type is unspecified.",
                      "Allowed for continuous evaluation.",
                      "Video data type.",
                      "Allowed for continuous evaluation.",
                      "Allowed for continuous evaluation."
                    ]
                  },
                  "createTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Creation time of instruction."
                  },
                  "updateTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "description": "Output only. Last update time of instruction."
                  },
                  "description": {
                    "type": "string",
                    "description": "Optional. User-provided description of the instruction. The description can be up to 10000 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "Required. The display name of the instruction. Maximum of 64 characters."
                  },
                  "csvInstruction": {
                    "id": "GoogleCloudDatalabelingV1beta1CsvInstruction",
                    "type": "object",
                    "properties": {
                      "gcsFileUri": {
                        "type": "string",
                        "description": "CSV file for the instruction. Only gcs path is allowed."
                      }
                    },
                    "description": "Deprecated: this instruction format is not supported any more. Instruction from a CSV file, such as for classification task. The CSV file should have exact two columns, in the following format: * The first column is labeled data, such as an image reference, text. * The second column is comma separated labels associated with data."
                  },
                  "pdfInstruction": {
                    "id": "GoogleCloudDatalabelingV1beta1PdfInstruction",
                    "type": "object",
                    "properties": {
                      "gcsFileUri": {
                        "type": "string",
                        "description": "PDF file for the instruction. Only gcs path is allowed."
                      }
                    },
                    "description": "Instruction from a PDF document. The PDF should be in a Cloud Storage bucket."
                  },
                  "blockingResources": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    },
                    "description": "Output only. The names of any related resources that are blocking changes to the instruction."
                  }
                },
                "description": "Instruction of how to perform the labeling task for human operators. Currently only PDF instruction is supported."
              },
              "description": "The list of Instructions to return."
            },
            "nextPageToken": {
              "type": "string",
              "description": "A token to retrieve next page of results."
            }
          },
          "description": "Results of listing instructions under a project."
        }
      ]
  projects.operations.cancel:
    description: |-
      Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.operations/cancel
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.operations.delete:
    description: |-
      Deletes a long-running operation. This method indicates that the client is no longer interested in the operation result. It does not cancel the operation. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.operations/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleProtobufEmpty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.operations.get:
    description: |-
      Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.operations/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.operations.list:
    description: |-
      Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`. NOTE: the `name` binding allows API services to override the binding to use different resource name schemes, such as `users/*/operations`. To override the binding, API services can add a binding such as `"/v1/{name=users/*}/operations"` to their service configuration. For backwards compatibility, the default name includes the operations collection id, however overriding users must ensure the name binding is the parent resource, without the operations collection id.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/ai-platform/data-labeling/docs/reference/rest/v1beta1/projects.operations/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "GoogleLongrunningListOperationsResponse",
          "type": "object",
          "properties": {
            "operations": {
              "type": "array",
              "items": {
                "id": "GoogleLongrunningOperation",
                "type": "object",
                "properties": {
                  "done": {
                    "type": "boolean",
                    "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
                  },
                  "name": {
                    "type": "string",
                    "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
                  },
                  "error": {
                    "id": "GoogleRpcStatus",
                    "type": "object",
                    "properties": {
                      "code": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The status code, which should be an enum value of google.rpc.Code."
                      },
                      "details": {
                        "type": "array",
                        "items": {
                          "type": "object",
                          "additionalProperties": {
                            "type": "any",
                            "description": "Properties of the object. Contains field @type with type URL."
                          }
                        },
                        "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                      },
                      "message": {
                        "type": "string",
                        "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                      }
                    },
                    "description": "The error result of the operation in case of failure or cancellation."
                  },
                  "metadata": {
                    "type": "object",
                    "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "response": {
                    "type": "object",
                    "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  }
                },
                "description": "This resource represents a long-running operation that is the result of a network API call."
              },
              "description": "A list of operations that matches the specified filter in the request."
            },
            "nextPageToken": {
              "type": "string",
              "description": "The standard List next-page token."
            }
          },
          "description": "The response message for Operations.ListOperations."
        }
      ]