Product:
  name: GCP Vision
  versions: [1.0.0]
  package: google.gcp.vision
  description: |-
    Cloud Vision
  link: https://cloud.google.com/vision
  contentType: json
Operations:
  files.annotate:
    description: |-
      Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/files/annotate
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  files.asyncBatchAnnotate:
    description: |-
      Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results).
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/files/asyncBatchAnnotate
    example:
      inputs: [
        {
          "id": "AsyncBatchAnnotateFilesRequest",
          "type": "object",
          "properties": {
            "parent": {
              "type": "string",
              "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
            },
            "requests": {
              "type": "array",
              "items": {
                "id": "AsyncAnnotateFileRequest",
                "type": "object",
                "properties": {
                  "features": {
                    "type": "array",
                    "items": {
                      "id": "Feature",
                      "type": "object",
                      "properties": {
                        "type": {
                          "enum": [
                            "TYPE_UNSPECIFIED",
                            "FACE_DETECTION",
                            "LANDMARK_DETECTION",
                            "LOGO_DETECTION",
                            "LABEL_DETECTION",
                            "TEXT_DETECTION",
                            "DOCUMENT_TEXT_DETECTION",
                            "SAFE_SEARCH_DETECTION",
                            "IMAGE_PROPERTIES",
                            "CROP_HINTS",
                            "WEB_DETECTION",
                            "PRODUCT_SEARCH",
                            "OBJECT_LOCALIZATION"
                          ],
                          "type": "string",
                          "description": "The feature type.",
                          "enumDescriptions": [
                            "Unspecified feature type.",
                            "Run face detection.",
                            "Run landmark detection.",
                            "Run logo detection.",
                            "Run label detection.",
                            "Run text detection / optical character recognition (OCR). Text detection is optimized for areas of text within a larger image; if the image is a document, use `DOCUMENT_TEXT_DETECTION` instead.",
                            "Run dense text document OCR. Takes precedence when both `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.",
                            "Run Safe Search to detect potentially unsafe or undesirable content.",
                            "Compute a set of image properties, such as the image's dominant colors.",
                            "Run crop hints.",
                            "Run web detection.",
                            "Run Product Search.",
                            "Run localizer for object detection."
                          ]
                        },
                        "model": {
                          "type": "string",
                          "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\"."
                        },
                        "maxResults": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`."
                        }
                      },
                      "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list."
                    },
                    "description": "Required. Requested features."
                  },
                  "inputConfig": {
                    "id": "InputConfig",
                    "type": "object",
                    "properties": {
                      "content": {
                        "type": "string",
                        "format": "byte",
                        "description": "File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "The type of the file. Currently only \"application/pdf\", \"image/tiff\" and \"image/gif\" are supported. Wildcards are not supported."
                      },
                      "gcsSource": {
                        "id": "GcsSource",
                        "type": "object",
                        "properties": {
                          "uri": {
                            "type": "string",
                            "description": "Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported."
                          }
                        },
                        "description": "The Google Cloud Storage location to read the input from."
                      }
                    },
                    "description": "Required. Information about the input file."
                  },
                  "imageContext": {
                    "id": "ImageContext",
                    "type": "object",
                    "properties": {
                      "latLongRect": {
                        "id": "LatLongRect",
                        "type": "object",
                        "properties": {
                          "maxLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Max lat/long pair."
                          },
                          "minLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Min lat/long pair."
                          }
                        },
                        "description": "Not used."
                      },
                      "languageHints": {
                        "type": "array",
                        "items": {
                          "type": "string"
                        },
                        "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages)."
                      },
                      "cropHintsParams": {
                        "id": "CropHintsParams",
                        "type": "object",
                        "properties": {
                          "aspectRatios": {
                            "type": "array",
                            "items": {
                              "type": "number",
                              "format": "float"
                            },
                            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored."
                          }
                        },
                        "description": "Parameters for crop hints annotation request."
                      },
                      "webDetectionParams": {
                        "id": "WebDetectionParams",
                        "type": "object",
                        "properties": {
                          "includeGeoResults": {
                            "type": "boolean",
                            "description": "Whether to include results derived from the geo information in the image."
                          }
                        },
                        "description": "Parameters for web detection."
                      },
                      "productSearchParams": {
                        "id": "ProductSearchParams",
                        "type": "object",
                        "properties": {
                          "filter": {
                            "type": "string",
                            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='."
                          },
                          "productSet": {
                            "type": "string",
                            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`."
                          },
                          "boundingPoly": {
                            "id": "BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              },
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "The bounding polygon around the area of interest in the image. If it is not specified, system discretion will be applied."
                          },
                          "productCategories": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well."
                          }
                        },
                        "description": "Parameters for product search."
                      },
                      "textDetectionParams": {
                        "id": "TextDetectionParams",
                        "type": "object",
                        "properties": {
                          "enableTextDetectionConfidenceScore": {
                            "type": "boolean",
                            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well."
                          }
                        },
                        "description": "Parameters for text detection and document text detection."
                      }
                    },
                    "description": "Additional context that may accompany the image(s) in the file."
                  },
                  "outputConfig": {
                    "id": "OutputConfig",
                    "type": "object",
                    "properties": {
                      "batchSize": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations."
                      },
                      "gcsDestination": {
                        "id": "GcsDestination",
                        "type": "object",
                        "properties": {
                          "uri": {
                            "type": "string",
                            "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files."
                          }
                        },
                        "description": "The Google Cloud Storage location to write the output(s) to."
                      }
                    },
                    "description": "Required. The desired output location and metadata (e.g. format)."
                  }
                },
                "description": "An offline file annotation request."
              },
              "description": "Required. Individual async file annotation requests for this batch."
            }
          },
          "description": "Multiple async file annotation requests are batched into a single service call."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  images.annotate:
    description: |-
      Run image detection and annotation for a batch of images.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  images.asyncBatchAnnotate:
    description: |-
      Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/images/asyncBatchAnnotate
    example:
      inputs: [
        {
          "id": "AsyncBatchAnnotateImagesRequest",
          "type": "object",
          "properties": {
            "parent": {
              "type": "string",
              "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
            },
            "requests": {
              "type": "array",
              "items": {
                "id": "AnnotateImageRequest",
                "type": "object",
                "properties": {
                  "image": {
                    "id": "Image",
                    "type": "object",
                    "properties": {
                      "source": {
                        "id": "ImageSource",
                        "type": "object",
                        "properties": {
                          "imageUri": {
                            "type": "string",
                            "description": "The URI of the source image. Can be either: 1. A Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info. 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from HTTP/HTTPS URLs, Google cannot guarantee that the request will be completed. Your request may fail if the specified host denies the request (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse prevention. You should not depend on externally-hosted images for production applications. When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes precedence."
                          },
                          "gcsImageUri": {
                            "type": "string",
                            "description": "**Use `image_uri` instead.** The Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info."
                          }
                        },
                        "description": "Google Cloud Storage image location, or publicly-accessible image URL. If both `content` and `source` are provided for an image, `content` takes precedence and is used to perform the image annotation request."
                      },
                      "content": {
                        "type": "string",
                        "format": "byte",
                        "description": "Image content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateImages requests. It does not work for AsyncBatchAnnotateImages requests."
                      }
                    },
                    "description": "The image to be processed."
                  },
                  "features": {
                    "type": "array",
                    "items": {
                      "id": "Feature",
                      "type": "object",
                      "properties": {
                        "type": {
                          "enum": [
                            "TYPE_UNSPECIFIED",
                            "FACE_DETECTION",
                            "LANDMARK_DETECTION",
                            "LOGO_DETECTION",
                            "LABEL_DETECTION",
                            "TEXT_DETECTION",
                            "DOCUMENT_TEXT_DETECTION",
                            "SAFE_SEARCH_DETECTION",
                            "IMAGE_PROPERTIES",
                            "CROP_HINTS",
                            "WEB_DETECTION",
                            "PRODUCT_SEARCH",
                            "OBJECT_LOCALIZATION"
                          ],
                          "type": "string",
                          "description": "The feature type.",
                          "enumDescriptions": [
                            "Unspecified feature type.",
                            "Run face detection.",
                            "Run landmark detection.",
                            "Run logo detection.",
                            "Run label detection.",
                            "Run text detection / optical character recognition (OCR). Text detection is optimized for areas of text within a larger image; if the image is a document, use `DOCUMENT_TEXT_DETECTION` instead.",
                            "Run dense text document OCR. Takes precedence when both `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.",
                            "Run Safe Search to detect potentially unsafe or undesirable content.",
                            "Compute a set of image properties, such as the image's dominant colors.",
                            "Run crop hints.",
                            "Run web detection.",
                            "Run Product Search.",
                            "Run localizer for object detection."
                          ]
                        },
                        "model": {
                          "type": "string",
                          "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\"."
                        },
                        "maxResults": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`."
                        }
                      },
                      "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list."
                    },
                    "description": "Requested features."
                  },
                  "imageContext": {
                    "id": "ImageContext",
                    "type": "object",
                    "properties": {
                      "latLongRect": {
                        "id": "LatLongRect",
                        "type": "object",
                        "properties": {
                          "maxLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Max lat/long pair."
                          },
                          "minLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Min lat/long pair."
                          }
                        },
                        "description": "Not used."
                      },
                      "languageHints": {
                        "type": "array",
                        "items": {
                          "type": "string"
                        },
                        "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages)."
                      },
                      "cropHintsParams": {
                        "id": "CropHintsParams",
                        "type": "object",
                        "properties": {
                          "aspectRatios": {
                            "type": "array",
                            "items": {
                              "type": "number",
                              "format": "float"
                            },
                            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored."
                          }
                        },
                        "description": "Parameters for crop hints annotation request."
                      },
                      "webDetectionParams": {
                        "id": "WebDetectionParams",
                        "type": "object",
                        "properties": {
                          "includeGeoResults": {
                            "type": "boolean",
                            "description": "Whether to include results derived from the geo information in the image."
                          }
                        },
                        "description": "Parameters for web detection."
                      },
                      "productSearchParams": {
                        "id": "ProductSearchParams",
                        "type": "object",
                        "properties": {
                          "filter": {
                            "type": "string",
                            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='."
                          },
                          "productSet": {
                            "type": "string",
                            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`."
                          },
                          "boundingPoly": {
                            "id": "BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              },
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "The bounding polygon around the area of interest in the image. If it is not specified, system discretion will be applied."
                          },
                          "productCategories": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well."
                          }
                        },
                        "description": "Parameters for product search."
                      },
                      "textDetectionParams": {
                        "id": "TextDetectionParams",
                        "type": "object",
                        "properties": {
                          "enableTextDetectionConfidenceScore": {
                            "type": "boolean",
                            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well."
                          }
                        },
                        "description": "Parameters for text detection and document text detection."
                      }
                    },
                    "description": "Additional context that may accompany the image."
                  }
                },
                "description": "Request for performing Google Cloud Vision API tasks over a user-provided image, with user-requested features, and with context information."
              },
              "description": "Required. Individual image annotation requests for this batch."
            },
            "outputConfig": {
              "id": "OutputConfig",
              "type": "object",
              "properties": {
                "batchSize": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations."
                },
                "gcsDestination": {
                  "id": "GcsDestination",
                  "type": "object",
                  "properties": {
                    "uri": {
                      "type": "string",
                      "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files."
                    }
                  },
                  "description": "The Google Cloud Storage location to write the output(s) to."
                }
              },
              "description": "Required. The desired output location and metadata (e.g. format)."
            }
          },
          "description": "Request for async image annotation for a list of images."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  locations.operations.get:
    description: |-
      Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/locations.operations/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  operations.cancel:
    description: |-
      Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/operations/cancel
    example:
      inputs: [
        {
          "id": "CancelOperationRequest",
          "type": "object",
          "properties": {},
          "description": "The request message for Operations.CancelOperation."
        }
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  operations.delete:
    description: |-
      Deletes a long-running operation. This method indicates that the client is no longer interested in the operation result. It does not cancel the operation. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/operations/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  operations.get:
    description: |-
      Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/operations/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  operations.list:
    description: |-
      Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`. NOTE: the `name` binding allows API services to override the binding to use different resource name schemes, such as `users/*/operations`. To override the binding, API services can add a binding such as `"/v1/{name=users/*}/operations"` to their service configuration. For backwards compatibility, the default name includes the operations collection id, however overriding users must ensure the name binding is the parent resource, without the operations collection id.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/operations/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "ListOperationsResponse",
          "type": "object",
          "properties": {
            "operations": {
              "type": "array",
              "items": {
                "id": "Operation",
                "type": "object",
                "properties": {
                  "done": {
                    "type": "boolean",
                    "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
                  },
                  "name": {
                    "type": "string",
                    "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
                  },
                  "error": {
                    "id": "Status",
                    "type": "object",
                    "properties": {
                      "code": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The status code, which should be an enum value of google.rpc.Code."
                      },
                      "details": {
                        "type": "array",
                        "items": {
                          "type": "object",
                          "additionalProperties": {
                            "type": "any",
                            "description": "Properties of the object. Contains field @type with type URL."
                          }
                        },
                        "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                      },
                      "message": {
                        "type": "string",
                        "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                      }
                    },
                    "description": "The error result of the operation in case of failure or cancellation."
                  },
                  "metadata": {
                    "type": "object",
                    "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "response": {
                    "type": "object",
                    "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  }
                },
                "description": "This resource represents a long-running operation that is the result of a network API call."
              },
              "description": "A list of operations that matches the specified filter in the request."
            },
            "nextPageToken": {
              "type": "string",
              "description": "The standard List next-page token."
            }
          },
          "description": "The response message for Operations.ListOperations."
        }
      ]
  projects.files.annotate:
    description: |-
      Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.files/annotate
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.files.asyncBatchAnnotate:
    description: |-
      Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results).
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.files/asyncBatchAnnotate
    example:
      inputs: [
        {
          "id": "AsyncBatchAnnotateFilesRequest",
          "type": "object",
          "properties": {
            "parent": {
              "type": "string",
              "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
            },
            "requests": {
              "type": "array",
              "items": {
                "id": "AsyncAnnotateFileRequest",
                "type": "object",
                "properties": {
                  "features": {
                    "type": "array",
                    "items": {
                      "id": "Feature",
                      "type": "object",
                      "properties": {
                        "type": {
                          "enum": [
                            "TYPE_UNSPECIFIED",
                            "FACE_DETECTION",
                            "LANDMARK_DETECTION",
                            "LOGO_DETECTION",
                            "LABEL_DETECTION",
                            "TEXT_DETECTION",
                            "DOCUMENT_TEXT_DETECTION",
                            "SAFE_SEARCH_DETECTION",
                            "IMAGE_PROPERTIES",
                            "CROP_HINTS",
                            "WEB_DETECTION",
                            "PRODUCT_SEARCH",
                            "OBJECT_LOCALIZATION"
                          ],
                          "type": "string",
                          "description": "The feature type.",
                          "enumDescriptions": [
                            "Unspecified feature type.",
                            "Run face detection.",
                            "Run landmark detection.",
                            "Run logo detection.",
                            "Run label detection.",
                            "Run text detection / optical character recognition (OCR). Text detection is optimized for areas of text within a larger image; if the image is a document, use `DOCUMENT_TEXT_DETECTION` instead.",
                            "Run dense text document OCR. Takes precedence when both `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.",
                            "Run Safe Search to detect potentially unsafe or undesirable content.",
                            "Compute a set of image properties, such as the image's dominant colors.",
                            "Run crop hints.",
                            "Run web detection.",
                            "Run Product Search.",
                            "Run localizer for object detection."
                          ]
                        },
                        "model": {
                          "type": "string",
                          "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\"."
                        },
                        "maxResults": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`."
                        }
                      },
                      "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list."
                    },
                    "description": "Required. Requested features."
                  },
                  "inputConfig": {
                    "id": "InputConfig",
                    "type": "object",
                    "properties": {
                      "content": {
                        "type": "string",
                        "format": "byte",
                        "description": "File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "The type of the file. Currently only \"application/pdf\", \"image/tiff\" and \"image/gif\" are supported. Wildcards are not supported."
                      },
                      "gcsSource": {
                        "id": "GcsSource",
                        "type": "object",
                        "properties": {
                          "uri": {
                            "type": "string",
                            "description": "Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported."
                          }
                        },
                        "description": "The Google Cloud Storage location to read the input from."
                      }
                    },
                    "description": "Required. Information about the input file."
                  },
                  "imageContext": {
                    "id": "ImageContext",
                    "type": "object",
                    "properties": {
                      "latLongRect": {
                        "id": "LatLongRect",
                        "type": "object",
                        "properties": {
                          "maxLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Max lat/long pair."
                          },
                          "minLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Min lat/long pair."
                          }
                        },
                        "description": "Not used."
                      },
                      "languageHints": {
                        "type": "array",
                        "items": {
                          "type": "string"
                        },
                        "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages)."
                      },
                      "cropHintsParams": {
                        "id": "CropHintsParams",
                        "type": "object",
                        "properties": {
                          "aspectRatios": {
                            "type": "array",
                            "items": {
                              "type": "number",
                              "format": "float"
                            },
                            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored."
                          }
                        },
                        "description": "Parameters for crop hints annotation request."
                      },
                      "webDetectionParams": {
                        "id": "WebDetectionParams",
                        "type": "object",
                        "properties": {
                          "includeGeoResults": {
                            "type": "boolean",
                            "description": "Whether to include results derived from the geo information in the image."
                          }
                        },
                        "description": "Parameters for web detection."
                      },
                      "productSearchParams": {
                        "id": "ProductSearchParams",
                        "type": "object",
                        "properties": {
                          "filter": {
                            "type": "string",
                            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='."
                          },
                          "productSet": {
                            "type": "string",
                            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`."
                          },
                          "boundingPoly": {
                            "id": "BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              },
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "The bounding polygon around the area of interest in the image. If it is not specified, system discretion will be applied."
                          },
                          "productCategories": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well."
                          }
                        },
                        "description": "Parameters for product search."
                      },
                      "textDetectionParams": {
                        "id": "TextDetectionParams",
                        "type": "object",
                        "properties": {
                          "enableTextDetectionConfidenceScore": {
                            "type": "boolean",
                            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well."
                          }
                        },
                        "description": "Parameters for text detection and document text detection."
                      }
                    },
                    "description": "Additional context that may accompany the image(s) in the file."
                  },
                  "outputConfig": {
                    "id": "OutputConfig",
                    "type": "object",
                    "properties": {
                      "batchSize": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations."
                      },
                      "gcsDestination": {
                        "id": "GcsDestination",
                        "type": "object",
                        "properties": {
                          "uri": {
                            "type": "string",
                            "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files."
                          }
                        },
                        "description": "The Google Cloud Storage location to write the output(s) to."
                      }
                    },
                    "description": "Required. The desired output location and metadata (e.g. format)."
                  }
                },
                "description": "An offline file annotation request."
              },
              "description": "Required. Individual async file annotation requests for this batch."
            }
          },
          "description": "Multiple async file annotation requests are batched into a single service call."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.images.annotate:
    description: |-
      Run image detection and annotation for a batch of images.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.images/annotate
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.images.asyncBatchAnnotate:
    description: |-
      Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.images/asyncBatchAnnotate
    example:
      inputs: [
        {
          "id": "AsyncBatchAnnotateImagesRequest",
          "type": "object",
          "properties": {
            "parent": {
              "type": "string",
              "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
            },
            "requests": {
              "type": "array",
              "items": {
                "id": "AnnotateImageRequest",
                "type": "object",
                "properties": {
                  "image": {
                    "id": "Image",
                    "type": "object",
                    "properties": {
                      "source": {
                        "id": "ImageSource",
                        "type": "object",
                        "properties": {
                          "imageUri": {
                            "type": "string",
                            "description": "The URI of the source image. Can be either: 1. A Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info. 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from HTTP/HTTPS URLs, Google cannot guarantee that the request will be completed. Your request may fail if the specified host denies the request (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse prevention. You should not depend on externally-hosted images for production applications. When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes precedence."
                          },
                          "gcsImageUri": {
                            "type": "string",
                            "description": "**Use `image_uri` instead.** The Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info."
                          }
                        },
                        "description": "Google Cloud Storage image location, or publicly-accessible image URL. If both `content` and `source` are provided for an image, `content` takes precedence and is used to perform the image annotation request."
                      },
                      "content": {
                        "type": "string",
                        "format": "byte",
                        "description": "Image content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateImages requests. It does not work for AsyncBatchAnnotateImages requests."
                      }
                    },
                    "description": "The image to be processed."
                  },
                  "features": {
                    "type": "array",
                    "items": {
                      "id": "Feature",
                      "type": "object",
                      "properties": {
                        "type": {
                          "enum": [
                            "TYPE_UNSPECIFIED",
                            "FACE_DETECTION",
                            "LANDMARK_DETECTION",
                            "LOGO_DETECTION",
                            "LABEL_DETECTION",
                            "TEXT_DETECTION",
                            "DOCUMENT_TEXT_DETECTION",
                            "SAFE_SEARCH_DETECTION",
                            "IMAGE_PROPERTIES",
                            "CROP_HINTS",
                            "WEB_DETECTION",
                            "PRODUCT_SEARCH",
                            "OBJECT_LOCALIZATION"
                          ],
                          "type": "string",
                          "description": "The feature type.",
                          "enumDescriptions": [
                            "Unspecified feature type.",
                            "Run face detection.",
                            "Run landmark detection.",
                            "Run logo detection.",
                            "Run label detection.",
                            "Run text detection / optical character recognition (OCR). Text detection is optimized for areas of text within a larger image; if the image is a document, use `DOCUMENT_TEXT_DETECTION` instead.",
                            "Run dense text document OCR. Takes precedence when both `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.",
                            "Run Safe Search to detect potentially unsafe or undesirable content.",
                            "Compute a set of image properties, such as the image's dominant colors.",
                            "Run crop hints.",
                            "Run web detection.",
                            "Run Product Search.",
                            "Run localizer for object detection."
                          ]
                        },
                        "model": {
                          "type": "string",
                          "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\"."
                        },
                        "maxResults": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`."
                        }
                      },
                      "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list."
                    },
                    "description": "Requested features."
                  },
                  "imageContext": {
                    "id": "ImageContext",
                    "type": "object",
                    "properties": {
                      "latLongRect": {
                        "id": "LatLongRect",
                        "type": "object",
                        "properties": {
                          "maxLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Max lat/long pair."
                          },
                          "minLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Min lat/long pair."
                          }
                        },
                        "description": "Not used."
                      },
                      "languageHints": {
                        "type": "array",
                        "items": {
                          "type": "string"
                        },
                        "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages)."
                      },
                      "cropHintsParams": {
                        "id": "CropHintsParams",
                        "type": "object",
                        "properties": {
                          "aspectRatios": {
                            "type": "array",
                            "items": {
                              "type": "number",
                              "format": "float"
                            },
                            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored."
                          }
                        },
                        "description": "Parameters for crop hints annotation request."
                      },
                      "webDetectionParams": {
                        "id": "WebDetectionParams",
                        "type": "object",
                        "properties": {
                          "includeGeoResults": {
                            "type": "boolean",
                            "description": "Whether to include results derived from the geo information in the image."
                          }
                        },
                        "description": "Parameters for web detection."
                      },
                      "productSearchParams": {
                        "id": "ProductSearchParams",
                        "type": "object",
                        "properties": {
                          "filter": {
                            "type": "string",
                            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='."
                          },
                          "productSet": {
                            "type": "string",
                            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`."
                          },
                          "boundingPoly": {
                            "id": "BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              },
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "The bounding polygon around the area of interest in the image. If it is not specified, system discretion will be applied."
                          },
                          "productCategories": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well."
                          }
                        },
                        "description": "Parameters for product search."
                      },
                      "textDetectionParams": {
                        "id": "TextDetectionParams",
                        "type": "object",
                        "properties": {
                          "enableTextDetectionConfidenceScore": {
                            "type": "boolean",
                            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well."
                          }
                        },
                        "description": "Parameters for text detection and document text detection."
                      }
                    },
                    "description": "Additional context that may accompany the image."
                  }
                },
                "description": "Request for performing Google Cloud Vision API tasks over a user-provided image, with user-requested features, and with context information."
              },
              "description": "Required. Individual image annotation requests for this batch."
            },
            "outputConfig": {
              "id": "OutputConfig",
              "type": "object",
              "properties": {
                "batchSize": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations."
                },
                "gcsDestination": {
                  "id": "GcsDestination",
                  "type": "object",
                  "properties": {
                    "uri": {
                      "type": "string",
                      "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files."
                    }
                  },
                  "description": "The Google Cloud Storage location to write the output(s) to."
                }
              },
              "description": "Required. The desired output location and metadata (e.g. format)."
            }
          },
          "description": "Request for async image annotation for a list of images."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.locations.files.annotate:
    description: |-
      Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.files/annotate
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.locations.files.asyncBatchAnnotate:
    description: |-
      Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results).
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.files/asyncBatchAnnotate
    example:
      inputs: [
        {
          "id": "AsyncBatchAnnotateFilesRequest",
          "type": "object",
          "properties": {
            "parent": {
              "type": "string",
              "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
            },
            "requests": {
              "type": "array",
              "items": {
                "id": "AsyncAnnotateFileRequest",
                "type": "object",
                "properties": {
                  "features": {
                    "type": "array",
                    "items": {
                      "id": "Feature",
                      "type": "object",
                      "properties": {
                        "type": {
                          "enum": [
                            "TYPE_UNSPECIFIED",
                            "FACE_DETECTION",
                            "LANDMARK_DETECTION",
                            "LOGO_DETECTION",
                            "LABEL_DETECTION",
                            "TEXT_DETECTION",
                            "DOCUMENT_TEXT_DETECTION",
                            "SAFE_SEARCH_DETECTION",
                            "IMAGE_PROPERTIES",
                            "CROP_HINTS",
                            "WEB_DETECTION",
                            "PRODUCT_SEARCH",
                            "OBJECT_LOCALIZATION"
                          ],
                          "type": "string",
                          "description": "The feature type.",
                          "enumDescriptions": [
                            "Unspecified feature type.",
                            "Run face detection.",
                            "Run landmark detection.",
                            "Run logo detection.",
                            "Run label detection.",
                            "Run text detection / optical character recognition (OCR). Text detection is optimized for areas of text within a larger image; if the image is a document, use `DOCUMENT_TEXT_DETECTION` instead.",
                            "Run dense text document OCR. Takes precedence when both `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.",
                            "Run Safe Search to detect potentially unsafe or undesirable content.",
                            "Compute a set of image properties, such as the image's dominant colors.",
                            "Run crop hints.",
                            "Run web detection.",
                            "Run Product Search.",
                            "Run localizer for object detection."
                          ]
                        },
                        "model": {
                          "type": "string",
                          "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\"."
                        },
                        "maxResults": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`."
                        }
                      },
                      "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list."
                    },
                    "description": "Required. Requested features."
                  },
                  "inputConfig": {
                    "id": "InputConfig",
                    "type": "object",
                    "properties": {
                      "content": {
                        "type": "string",
                        "format": "byte",
                        "description": "File content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateFiles requests. It does not work for AsyncBatchAnnotateFiles requests."
                      },
                      "mimeType": {
                        "type": "string",
                        "description": "The type of the file. Currently only \"application/pdf\", \"image/tiff\" and \"image/gif\" are supported. Wildcards are not supported."
                      },
                      "gcsSource": {
                        "id": "GcsSource",
                        "type": "object",
                        "properties": {
                          "uri": {
                            "type": "string",
                            "description": "Google Cloud Storage URI for the input file. This must only be a Google Cloud Storage object. Wildcards are not currently supported."
                          }
                        },
                        "description": "The Google Cloud Storage location to read the input from."
                      }
                    },
                    "description": "Required. Information about the input file."
                  },
                  "imageContext": {
                    "id": "ImageContext",
                    "type": "object",
                    "properties": {
                      "latLongRect": {
                        "id": "LatLongRect",
                        "type": "object",
                        "properties": {
                          "maxLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Max lat/long pair."
                          },
                          "minLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Min lat/long pair."
                          }
                        },
                        "description": "Not used."
                      },
                      "languageHints": {
                        "type": "array",
                        "items": {
                          "type": "string"
                        },
                        "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages)."
                      },
                      "cropHintsParams": {
                        "id": "CropHintsParams",
                        "type": "object",
                        "properties": {
                          "aspectRatios": {
                            "type": "array",
                            "items": {
                              "type": "number",
                              "format": "float"
                            },
                            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored."
                          }
                        },
                        "description": "Parameters for crop hints annotation request."
                      },
                      "webDetectionParams": {
                        "id": "WebDetectionParams",
                        "type": "object",
                        "properties": {
                          "includeGeoResults": {
                            "type": "boolean",
                            "description": "Whether to include results derived from the geo information in the image."
                          }
                        },
                        "description": "Parameters for web detection."
                      },
                      "productSearchParams": {
                        "id": "ProductSearchParams",
                        "type": "object",
                        "properties": {
                          "filter": {
                            "type": "string",
                            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='."
                          },
                          "productSet": {
                            "type": "string",
                            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`."
                          },
                          "boundingPoly": {
                            "id": "BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              },
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "The bounding polygon around the area of interest in the image. If it is not specified, system discretion will be applied."
                          },
                          "productCategories": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well."
                          }
                        },
                        "description": "Parameters for product search."
                      },
                      "textDetectionParams": {
                        "id": "TextDetectionParams",
                        "type": "object",
                        "properties": {
                          "enableTextDetectionConfidenceScore": {
                            "type": "boolean",
                            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well."
                          }
                        },
                        "description": "Parameters for text detection and document text detection."
                      }
                    },
                    "description": "Additional context that may accompany the image(s) in the file."
                  },
                  "outputConfig": {
                    "id": "OutputConfig",
                    "type": "object",
                    "properties": {
                      "batchSize": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations."
                      },
                      "gcsDestination": {
                        "id": "GcsDestination",
                        "type": "object",
                        "properties": {
                          "uri": {
                            "type": "string",
                            "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files."
                          }
                        },
                        "description": "The Google Cloud Storage location to write the output(s) to."
                      }
                    },
                    "description": "Required. The desired output location and metadata (e.g. format)."
                  }
                },
                "description": "An offline file annotation request."
              },
              "description": "Required. Individual async file annotation requests for this batch."
            }
          },
          "description": "Multiple async file annotation requests are batched into a single service call."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.locations.images.annotate:
    description: |-
      Run image detection and annotation for a batch of images.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.images/annotate
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.locations.images.asyncBatchAnnotate:
    description: |-
      Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.images/asyncBatchAnnotate
    example:
      inputs: [
        {
          "id": "AsyncBatchAnnotateImagesRequest",
          "type": "object",
          "properties": {
            "parent": {
              "type": "string",
              "description": "Optional. Target project and location to make a call. Format: `projects/{project-id}/locations/{location-id}`. If no parent is specified, a region will be chosen automatically. Supported location-ids: `us`: USA country only, `asia`: East asia areas, like Japan, Taiwan, `eu`: The European Union. Example: `projects/project-A/locations/eu`."
            },
            "requests": {
              "type": "array",
              "items": {
                "id": "AnnotateImageRequest",
                "type": "object",
                "properties": {
                  "image": {
                    "id": "Image",
                    "type": "object",
                    "properties": {
                      "source": {
                        "id": "ImageSource",
                        "type": "object",
                        "properties": {
                          "imageUri": {
                            "type": "string",
                            "description": "The URI of the source image. Can be either: 1. A Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info. 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from HTTP/HTTPS URLs, Google cannot guarantee that the request will be completed. Your request may fail if the specified host denies the request (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse prevention. You should not depend on externally-hosted images for production applications. When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes precedence."
                          },
                          "gcsImageUri": {
                            "type": "string",
                            "description": "**Use `image_uri` instead.** The Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for more info."
                          }
                        },
                        "description": "Google Cloud Storage image location, or publicly-accessible image URL. If both `content` and `source` are provided for an image, `content` takes precedence and is used to perform the image annotation request."
                      },
                      "content": {
                        "type": "string",
                        "format": "byte",
                        "description": "Image content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations use base64. Currently, this field only works for BatchAnnotateImages requests. It does not work for AsyncBatchAnnotateImages requests."
                      }
                    },
                    "description": "The image to be processed."
                  },
                  "features": {
                    "type": "array",
                    "items": {
                      "id": "Feature",
                      "type": "object",
                      "properties": {
                        "type": {
                          "enum": [
                            "TYPE_UNSPECIFIED",
                            "FACE_DETECTION",
                            "LANDMARK_DETECTION",
                            "LOGO_DETECTION",
                            "LABEL_DETECTION",
                            "TEXT_DETECTION",
                            "DOCUMENT_TEXT_DETECTION",
                            "SAFE_SEARCH_DETECTION",
                            "IMAGE_PROPERTIES",
                            "CROP_HINTS",
                            "WEB_DETECTION",
                            "PRODUCT_SEARCH",
                            "OBJECT_LOCALIZATION"
                          ],
                          "type": "string",
                          "description": "The feature type.",
                          "enumDescriptions": [
                            "Unspecified feature type.",
                            "Run face detection.",
                            "Run landmark detection.",
                            "Run logo detection.",
                            "Run label detection.",
                            "Run text detection / optical character recognition (OCR). Text detection is optimized for areas of text within a larger image; if the image is a document, use `DOCUMENT_TEXT_DETECTION` instead.",
                            "Run dense text document OCR. Takes precedence when both `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.",
                            "Run Safe Search to detect potentially unsafe or undesirable content.",
                            "Compute a set of image properties, such as the image's dominant colors.",
                            "Run crop hints.",
                            "Run web detection.",
                            "Run Product Search.",
                            "Run localizer for object detection."
                          ]
                        },
                        "model": {
                          "type": "string",
                          "description": "Model to use for the feature. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\"."
                        },
                        "maxResults": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Maximum number of results of this type. Does not apply to `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`."
                        }
                      },
                      "description": "The type of Google Cloud Vision API detection to perform, and the maximum number of results to return for that type. Multiple `Feature` objects can be specified in the `features` list."
                    },
                    "description": "Requested features."
                  },
                  "imageContext": {
                    "id": "ImageContext",
                    "type": "object",
                    "properties": {
                      "latLongRect": {
                        "id": "LatLongRect",
                        "type": "object",
                        "properties": {
                          "maxLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Max lat/long pair."
                          },
                          "minLatLng": {
                            "id": "LatLng",
                            "type": "object",
                            "properties": {
                              "latitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The latitude in degrees. It must be in the range [-90.0, +90.0]."
                              },
                              "longitude": {
                                "type": "number",
                                "format": "double",
                                "description": "The longitude in degrees. It must be in the range [-180.0, +180.0]."
                              }
                            },
                            "description": "Min lat/long pair."
                          }
                        },
                        "description": "Not used."
                      },
                      "languageHints": {
                        "type": "array",
                        "items": {
                          "type": "string"
                        },
                        "description": "List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results since it enables automatic language detection. For languages based on the Latin alphabet, setting `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text detection returns an error if one or more of the specified languages is not one of the [supported languages](https://cloud.google.com/vision/docs/languages)."
                      },
                      "cropHintsParams": {
                        "id": "CropHintsParams",
                        "type": "object",
                        "properties": {
                          "aspectRatios": {
                            "type": "array",
                            "items": {
                              "type": "number",
                              "format": "float"
                            },
                            "description": "Aspect ratios in floats, representing the ratio of the width to the height of the image. For example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333. If not specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum of 16; any aspect ratios provided after the 16th are ignored."
                          }
                        },
                        "description": "Parameters for crop hints annotation request."
                      },
                      "webDetectionParams": {
                        "id": "WebDetectionParams",
                        "type": "object",
                        "properties": {
                          "includeGeoResults": {
                            "type": "boolean",
                            "description": "Whether to include results derived from the geo information in the image."
                          }
                        },
                        "description": "Parameters for web detection."
                      },
                      "productSearchParams": {
                        "id": "ProductSearchParams",
                        "type": "object",
                        "properties": {
                          "filter": {
                            "type": "string",
                            "description": "The filtering expression. This can be used to restrict search results based on Product labels. We currently support an AND of OR of key-value expressions, where each expression within an OR must have the same key. An '=' should be used to connect the key and value. For example, \"(color = red OR color = blue) AND brand = Google\" is acceptable, but \"(color = red OR brand = Google)\" is not acceptable. \"color: red\" is not acceptable because it uses a ':' instead of an '='."
                          },
                          "productSet": {
                            "type": "string",
                            "description": "The resource name of a ProductSet to be searched for similar images. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`."
                          },
                          "boundingPoly": {
                            "id": "BoundingPoly",
                            "type": "object",
                            "properties": {
                              "vertices": {
                                "type": "array",
                                "items": {
                                  "id": "Vertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "integer",
                                      "format": "int32",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                                },
                                "description": "The bounding polygon vertices."
                              },
                              "normalizedVertices": {
                                "type": "array",
                                "items": {
                                  "id": "NormalizedVertex",
                                  "type": "object",
                                  "properties": {
                                    "x": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "X coordinate."
                                    },
                                    "y": {
                                      "type": "number",
                                      "format": "float",
                                      "description": "Y coordinate."
                                    }
                                  },
                                  "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                                },
                                "description": "The bounding polygon normalized vertices."
                              }
                            },
                            "description": "The bounding polygon around the area of interest in the image. If it is not specified, system discretion will be applied."
                          },
                          "productCategories": {
                            "type": "array",
                            "items": {
                              "type": "string"
                            },
                            "description": "The list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well."
                          }
                        },
                        "description": "Parameters for product search."
                      },
                      "textDetectionParams": {
                        "id": "TextDetectionParams",
                        "type": "object",
                        "properties": {
                          "enableTextDetectionConfidenceScore": {
                            "type": "boolean",
                            "description": "By default, Cloud Vision API only includes confidence score for DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence score for TEXT_DETECTION as well."
                          }
                        },
                        "description": "Parameters for text detection and document text detection."
                      }
                    },
                    "description": "Additional context that may accompany the image."
                  }
                },
                "description": "Request for performing Google Cloud Vision API tasks over a user-provided image, with user-requested features, and with context information."
              },
              "description": "Required. Individual image annotation requests for this batch."
            },
            "outputConfig": {
              "id": "OutputConfig",
              "type": "object",
              "properties": {
                "batchSize": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The max number of response protos to put into each output JSON file on Google Cloud Storage. The valid range is [1, 100]. If not specified, the default value is 20. For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20, then 5 json files each containing 20 response protos will be written under the prefix `gcs_destination`.`uri`. Currently, batch_size only applies to GcsDestination, with potential future support for other output configurations."
                },
                "gcsDestination": {
                  "id": "GcsDestination",
                  "type": "object",
                  "properties": {
                    "uri": {
                      "type": "string",
                      "description": "Google Cloud Storage URI prefix where the results will be stored. Results will be in JSON format and preceded by its corresponding input URI prefix. This field can either represent a gcs file prefix or gcs directory. In either case, the uri should be unique because in order to get all of the output files, you will need to do a wildcard gcs search on the uri prefix you provide. Examples: * File Prefix: gs://bucket-name/here/filenameprefix The output files will be created in gs://bucket-name/here/ and the names of the output files will begin with \"filenameprefix\". * Directory Prefix: gs://bucket-name/some/location/ The output files will be created in gs://bucket-name/some/location/ and the names of the output files could be anything because there was no filename prefix specified. If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too large and overflows into multiple sharded files."
                    }
                  },
                  "description": "The Google Cloud Storage location to write the output(s) to."
                }
              },
              "description": "Required. The desired output location and metadata (e.g. format)."
            }
          },
          "description": "Request for async image annotation for a list of images."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.locations.operations.get:
    description: |-
      Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.operations/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.locations.products.create:
    description: |-
      Creates and returns a new product resource. Possible errors: * Returns INVALID_ARGUMENT if display_name is missing or longer than 4096 characters. * Returns INVALID_ARGUMENT if description is longer than 4096 characters. * Returns INVALID_ARGUMENT if product_category is missing or invalid.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products/create
    example:
      inputs: [
        {
          "id": "Product",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product."
            },
            "description": {
              "type": "string",
              "description": "User-provided metadata to be stored with this product. Must be at most 4096 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long."
            },
            "productLabels": {
              "type": "array",
              "items": {
                "id": "KeyValue",
                "type": "object",
                "properties": {
                  "key": {
                    "type": "string",
                    "description": "The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                  },
                  "value": {
                    "type": "string",
                    "description": "The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                  }
                },
                "description": "A product label represented as a key-value pair."
              },
              "description": "Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. \"1199\". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet."
            },
            "productCategory": {
              "type": "string",
              "description": "Immutable. The category for the product identified by the reference image. This should be one of \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\" or \"general-v1\". The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported, but these should not be used for new products."
            }
          },
          "description": "A Product contains ReferenceImages."
        }
      ]
      outputs: [
        {}
      ]
  projects.locations.products.delete:
    description: |-
      Permanently deletes a product and its reference images. Metadata of the product and all its images will be deleted right away, but search queries against ProductSets containing the product may still work until all related caches are refreshed.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.locations.productSets.addProduct:
    description: |-
      Adds a Product to the specified ProductSet. If the Product is already present, no change is made. One Product can be added to at most 100 ProductSets. Possible errors: * Returns NOT_FOUND if the Product or the ProductSet doesn't exist.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/addProduct
    example:
      inputs: [
        {
          "id": "AddProductToProductSetRequest",
          "type": "object",
          "properties": {
            "product": {
              "type": "string",
              "description": "Required. The resource name for the Product to be added to this ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`"
            }
          },
          "description": "Request message for the `AddProductToProductSet` method."
        }
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.locations.productSets.create:
    description: |-
      Creates and returns a new ProductSet resource. Possible errors: * Returns INVALID_ARGUMENT if display_name is missing, or is longer than 4096 characters.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/create
    example:
      inputs: [
        {
          "id": "ProductSet",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "The resource name of the ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`. This field is ignored when creating a ProductSet."
            },
            "indexTime": {
              "type": "string",
              "format": "google-datetime",
              "readOnly": true,
              "description": "Output only. The time at which this ProductSet was last indexed. Query results will reflect all updates before this time. If this ProductSet has never been indexed, this timestamp is the default value \"1970-01-01T00:00:00Z\". This field is ignored when creating a ProductSet."
            },
            "indexError": {
              "id": "Status",
              "type": "object",
              "readOnly": true,
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "Output only. If there was an error with indexing the product set, the field is populated. This field is ignored when creating a ProductSet."
            },
            "displayName": {
              "type": "string",
              "description": "The user-provided name for this ProductSet. Must not be empty. Must be at most 4096 characters long."
            }
          },
          "description": "A ProductSet contains Products. A ProductSet can contain a maximum of 1 million reference images. If the limit is exceeded, periodic indexing will fail."
        }
      ]
      outputs: [
        {}
      ]
  projects.locations.productSets.delete:
    description: |-
      Permanently deletes a ProductSet. Products and ReferenceImages in the ProductSet are not deleted. The actual image files are not deleted from Google Cloud Storage.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.locations.productSets.get:
    description: |-
      Gets information associated with a ProductSet. Possible errors: * Returns NOT_FOUND if the ProductSet does not exist.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.locations.productSets.import:
    description: |-
      Asynchronous API that imports a list of reference images to specified product sets based on a list of image information. The google.longrunning.Operation API can be used to keep track of the progress and results of the request. `Operation.metadata` contains `BatchOperationMetadata`. (progress) `Operation.response` contains `ImportProductSetsResponse`. (results) The input source of this method is a csv file on Google Cloud Storage. For the format of the csv file please see ImportProductSetsGcsSource.csv_file_uri.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/import
    example:
      inputs: [
        {
          "id": "ImportProductSetsRequest",
          "type": "object",
          "properties": {
            "inputConfig": {
              "id": "ImportProductSetsInputConfig",
              "type": "object",
              "properties": {
                "gcsSource": {
                  "id": "ImportProductSetsGcsSource",
                  "type": "object",
                  "properties": {
                    "csvFileUri": {
                      "type": "string",
                      "description": "The Google Cloud Storage URI of the input csv file. The URI must start with `gs://`. The format of the input csv file should be one image per line. In each line, there are 8 columns. 1. image-uri 2. image-id 3. product-set-id 4. product-id 5. product-category 6. product-display-name 7. labels 8. bounding-poly The `image-uri`, `product-set-id`, `product-id`, and `product-category` columns are required. All other columns are optional. If the `ProductSet` or `Product` specified by the `product-set-id` and `product-id` values does not exist, then the system will create a new `ProductSet` or `Product` for the image. In this case, the `product-display-name` column refers to display_name, the `product-category` column refers to product_category, and the `labels` column refers to product_labels. The `image-id` column is optional but must be unique if provided. If it is empty, the system will automatically assign a unique id to the image. The `product-display-name` column is optional. If it is empty, the system sets the display_name field for the product to a space (\" \"). You can update the `display_name` later by using the API. If a `Product` with the specified `product-id` already exists, then the system ignores the `product-display-name`, `product-category`, and `labels` columns. The `labels` column (optional) is a line containing a list of comma-separated key-value pairs, in the following format: \"key_1=value_1,key_2=value_2,...,key_n=value_n\" The `bounding-poly` column (optional) identifies one region of interest from the image in the same manner as `CreateReferenceImage`. If you do not specify the `bounding-poly` column, then the system will try to detect regions of interest automatically. At most one `bounding-poly` column is allowed per line. If the image contains multiple regions of interest, add a line to the CSV file that includes the same product information, and the `bounding-poly` values for each region of interest. The `bounding-poly` column must contain an even number of comma-separated numbers, in the format \"p1_x,p1_y,p2_x,p2_y,...,pn_x,pn_y\". Use non-negative integers for absolute bounding polygons, and float values in [0, 1] for normalized bounding polygons. The system will resize the image if the image resolution is too large to process (larger than 20MP)."
                    }
                  },
                  "description": "The Google Cloud Storage location for a csv file which preserves a list of ImportProductSetRequests in each line."
                }
              },
              "description": "Required. The input content for the list of requests."
            }
          },
          "description": "Request message for the `ImportProductSets` method."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.locations.productSets.list:
    description: |-
      Lists ProductSets in an unspecified order. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100, or less than 1.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "ListProductSetsResponse",
          "type": "object",
          "properties": {
            "productSets": {
              "type": "array",
              "items": {
                "id": "ProductSet",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "The resource name of the ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`. This field is ignored when creating a ProductSet."
                  },
                  "indexTime": {
                    "type": "string",
                    "format": "google-datetime",
                    "readOnly": true,
                    "description": "Output only. The time at which this ProductSet was last indexed. Query results will reflect all updates before this time. If this ProductSet has never been indexed, this timestamp is the default value \"1970-01-01T00:00:00Z\". This field is ignored when creating a ProductSet."
                  },
                  "indexError": {
                    "id": "Status",
                    "type": "object",
                    "readOnly": true,
                    "properties": {
                      "code": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The status code, which should be an enum value of google.rpc.Code."
                      },
                      "details": {
                        "type": "array",
                        "items": {
                          "type": "object",
                          "additionalProperties": {
                            "type": "any",
                            "description": "Properties of the object. Contains field @type with type URL."
                          }
                        },
                        "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                      },
                      "message": {
                        "type": "string",
                        "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                      }
                    },
                    "description": "Output only. If there was an error with indexing the product set, the field is populated. This field is ignored when creating a ProductSet."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "The user-provided name for this ProductSet. Must not be empty. Must be at most 4096 characters long."
                  }
                },
                "description": "A ProductSet contains Products. A ProductSet can contain a maximum of 1 million reference images. If the limit is exceeded, periodic indexing will fail."
              },
              "description": "List of ProductSets."
            },
            "nextPageToken": {
              "type": "string",
              "description": "Token to retrieve the next page of results, or empty if there are no more results in the list."
            }
          },
          "description": "Response message for the `ListProductSets` method."
        }
      ]
  projects.locations.productSets.patch:
    description: |-
      Makes changes to a ProductSet resource. Only display_name can be updated currently. Possible errors: * Returns NOT_FOUND if the ProductSet does not exist. * Returns INVALID_ARGUMENT if display_name is present in update_mask but missing from the request or longer than 4096 characters.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/patch
    example:
      inputs: [
        {
          "id": "ProductSet",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "The resource name of the ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID`. This field is ignored when creating a ProductSet."
            },
            "indexTime": {
              "type": "string",
              "format": "google-datetime",
              "readOnly": true,
              "description": "Output only. The time at which this ProductSet was last indexed. Query results will reflect all updates before this time. If this ProductSet has never been indexed, this timestamp is the default value \"1970-01-01T00:00:00Z\". This field is ignored when creating a ProductSet."
            },
            "indexError": {
              "id": "Status",
              "type": "object",
              "readOnly": true,
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "Output only. If there was an error with indexing the product set, the field is populated. This field is ignored when creating a ProductSet."
            },
            "displayName": {
              "type": "string",
              "description": "The user-provided name for this ProductSet. Must not be empty. Must be at most 4096 characters long."
            }
          },
          "description": "A ProductSet contains Products. A ProductSet can contain a maximum of 1 million reference images. If the limit is exceeded, periodic indexing will fail."
        }
      ]
      outputs: [
        {}
      ]
  projects.locations.productSets.products.list:
    description: |-
      Lists the Products in a ProductSet, in an unspecified order. If the ProductSet does not exist, the products field of the response will be empty. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100 or less than 1.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets.products/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "ListProductsInProductSetResponse",
          "type": "object",
          "properties": {
            "products": {
              "type": "array",
              "items": {
                "id": "Product",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product."
                  },
                  "description": {
                    "type": "string",
                    "description": "User-provided metadata to be stored with this product. Must be at most 4096 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long."
                  },
                  "productLabels": {
                    "type": "array",
                    "items": {
                      "id": "KeyValue",
                      "type": "object",
                      "properties": {
                        "key": {
                          "type": "string",
                          "description": "The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                        },
                        "value": {
                          "type": "string",
                          "description": "The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                        }
                      },
                      "description": "A product label represented as a key-value pair."
                    },
                    "description": "Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. \"1199\". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet."
                  },
                  "productCategory": {
                    "type": "string",
                    "description": "Immutable. The category for the product identified by the reference image. This should be one of \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\" or \"general-v1\". The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported, but these should not be used for new products."
                  }
                },
                "description": "A Product contains ReferenceImages."
              },
              "description": "The list of Products."
            },
            "nextPageToken": {
              "type": "string",
              "description": "Token to retrieve the next page of results, or empty if there are no more results in the list."
            }
          },
          "description": "Response message for the `ListProductsInProductSet` method."
        }
      ]
  projects.locations.productSets.removeProduct:
    description: |-
      Removes a Product from the specified ProductSet.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.productSets/removeProduct
    example:
      inputs: [
        {
          "id": "RemoveProductFromProductSetRequest",
          "type": "object",
          "properties": {
            "product": {
              "type": "string",
              "description": "Required. The resource name for the Product to be removed from this ProductSet. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`"
            }
          },
          "description": "Request message for the `RemoveProductFromProductSet` method."
        }
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.locations.products.get:
    description: |-
      Gets information associated with a Product. Possible errors: * Returns NOT_FOUND if the Product does not exist.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.locations.products.list:
    description: |-
      Lists products in an unspecified order. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100 or less than 1.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "ListProductsResponse",
          "type": "object",
          "properties": {
            "products": {
              "type": "array",
              "items": {
                "id": "Product",
                "type": "object",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product."
                  },
                  "description": {
                    "type": "string",
                    "description": "User-provided metadata to be stored with this product. Must be at most 4096 characters long."
                  },
                  "displayName": {
                    "type": "string",
                    "description": "The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long."
                  },
                  "productLabels": {
                    "type": "array",
                    "items": {
                      "id": "KeyValue",
                      "type": "object",
                      "properties": {
                        "key": {
                          "type": "string",
                          "description": "The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                        },
                        "value": {
                          "type": "string",
                          "description": "The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                        }
                      },
                      "description": "A product label represented as a key-value pair."
                    },
                    "description": "Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. \"1199\". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet."
                  },
                  "productCategory": {
                    "type": "string",
                    "description": "Immutable. The category for the product identified by the reference image. This should be one of \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\" or \"general-v1\". The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported, but these should not be used for new products."
                  }
                },
                "description": "A Product contains ReferenceImages."
              },
              "description": "List of products."
            },
            "nextPageToken": {
              "type": "string",
              "description": "Token to retrieve the next page of results, or empty if there are no more results in the list."
            }
          },
          "description": "Response message for the `ListProducts` method."
        }
      ]
  projects.locations.products.patch:
    description: |-
      Makes changes to a Product resource. Only the `display_name`, `description`, and `labels` fields can be updated right now. If labels are updated, the change will not be reflected in queries until the next index time. Possible errors: * Returns NOT_FOUND if the Product does not exist. * Returns INVALID_ARGUMENT if display_name is present in update_mask but is missing from the request or longer than 4096 characters. * Returns INVALID_ARGUMENT if description is present in update_mask but is longer than 4096 characters. * Returns INVALID_ARGUMENT if product_category is present in update_mask.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products/patch
    example:
      inputs: [
        {
          "id": "Product",
          "type": "object",
          "properties": {
            "name": {
              "type": "string",
              "description": "The resource name of the product. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID`. This field is ignored when creating a product."
            },
            "description": {
              "type": "string",
              "description": "User-provided metadata to be stored with this product. Must be at most 4096 characters long."
            },
            "displayName": {
              "type": "string",
              "description": "The user-provided name for this Product. Must not be empty. Must be at most 4096 characters long."
            },
            "productLabels": {
              "type": "array",
              "items": {
                "id": "KeyValue",
                "type": "object",
                "properties": {
                  "key": {
                    "type": "string",
                    "description": "The key of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                  },
                  "value": {
                    "type": "string",
                    "description": "The value of the label attached to the product. Cannot be empty and cannot exceed 128 bytes."
                  }
                },
                "description": "A product label represented as a key-value pair."
              },
              "description": "Key-value pairs that can be attached to a product. At query time, constraints can be specified based on the product_labels. Note that integer values can be provided as strings, e.g. \"1199\". Only strings with integer values can match a range-based restriction which is to be supported soon. Multiple values can be assigned to the same key. One product may have up to 500 product_labels. Notice that the total number of distinct product_labels over all products in one ProductSet cannot exceed 1M, otherwise the product search pipeline will refuse to work for that ProductSet."
            },
            "productCategory": {
              "type": "string",
              "description": "Immutable. The category for the product identified by the reference image. This should be one of \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\" or \"general-v1\". The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported, but these should not be used for new products."
            }
          },
          "description": "A Product contains ReferenceImages."
        }
      ]
      outputs: [
        {}
      ]
  projects.locations.products.purge:
    description: |-
      Asynchronous API to delete all Products in a ProductSet or all Products that are in no ProductSet. If a Product is a member of the specified ProductSet in addition to other ProductSets, the Product will still be deleted. It is recommended to not delete the specified ProductSet until after this operation has completed. It is also recommended to not add any of the Products involved in the batch delete to a new ProductSet while this operation is running because those Products may still end up deleted. It's not possible to undo the PurgeProducts operation. Therefore, it is recommended to keep the csv files used in ImportProductSets (if that was how you originally built the Product Set) before starting PurgeProducts, in case you need to re-import the data after deletion. If the plan is to purge all of the Products from a ProductSet and then re-use the empty ProductSet to re-import new Products into the empty ProductSet, you must wait until the PurgeProducts operation has finished for that ProductSet. The google.longrunning.Operation API can be used to keep track of the progress and results of the request. `Operation.metadata` contains `BatchOperationMetadata`. (progress)
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products/purge
    example:
      inputs: [
        {
          "id": "PurgeProductsRequest",
          "type": "object",
          "properties": {
            "force": {
              "type": "boolean",
              "description": "The default value is false. Override this value to true to actually perform the purge."
            },
            "deleteOrphanProducts": {
              "type": "boolean",
              "description": "If delete_orphan_products is true, all Products that are not in any ProductSet will be deleted."
            },
            "productSetPurgeConfig": {
              "id": "ProductSetPurgeConfig",
              "type": "object",
              "properties": {
                "productSetId": {
                  "type": "string",
                  "description": "The ProductSet that contains the Products to delete. If a Product is a member of product_set_id in addition to other ProductSets, the Product will still be deleted."
                }
              },
              "description": "Specify which ProductSet contains the Products to be deleted."
            }
          },
          "description": "Request message for the `PurgeProducts` method."
        }
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  projects.locations.products.referenceImages.create:
    description: |-
      Creates and returns a new ReferenceImage resource. The `bounding_poly` field is optional. If `bounding_poly` is not specified, the system will try to detect regions of interest in the image that are compatible with the product_category on the parent product. If it is specified, detection is ALWAYS skipped. The system converts polygons into non-rotated rectangles. Note that the pipeline will resize the image if the image resolution is too large to process (above 50MP). Possible errors: * Returns INVALID_ARGUMENT if the image_uri is missing or longer than 4096 characters. * Returns INVALID_ARGUMENT if the product does not exist. * Returns INVALID_ARGUMENT if bounding_poly is not provided, and nothing compatible with the parent product's product_category is detected. * Returns INVALID_ARGUMENT if bounding_poly contains more than 10 polygons.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products.referenceImages/create
    example:
      inputs: [
        {
          "id": "ReferenceImage",
          "type": "object",
          "properties": {
            "uri": {
              "type": "string",
              "description": "Required. The Google Cloud Storage URI of the reference image. The URI must start with `gs://`."
            },
            "name": {
              "type": "string",
              "description": "The resource name of the reference image. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID/referenceImages/IMAGE_ID`. This field is ignored when creating a reference image."
            },
            "boundingPolys": {
              "type": "array",
              "items": {
                "id": "BoundingPoly",
                "type": "object",
                "properties": {
                  "vertices": {
                    "type": "array",
                    "items": {
                      "id": "Vertex",
                      "type": "object",
                      "properties": {
                        "x": {
                          "type": "integer",
                          "format": "int32",
                          "description": "X coordinate."
                        },
                        "y": {
                          "type": "integer",
                          "format": "int32",
                          "description": "Y coordinate."
                        }
                      },
                      "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                    },
                    "description": "The bounding polygon vertices."
                  },
                  "normalizedVertices": {
                    "type": "array",
                    "items": {
                      "id": "NormalizedVertex",
                      "type": "object",
                      "properties": {
                        "x": {
                          "type": "number",
                          "format": "float",
                          "description": "X coordinate."
                        },
                        "y": {
                          "type": "number",
                          "format": "float",
                          "description": "Y coordinate."
                        }
                      },
                      "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                    },
                    "description": "The bounding polygon normalized vertices."
                  }
                },
                "description": "A bounding polygon for the detected image annotation."
              },
              "description": "Optional. Bounding polygons around the areas of interest in the reference image. If this field is empty, the system will try to detect regions of interest. At most 10 bounding polygons will be used. The provided shape is converted into a non-rotated rectangle. Once converted, the small edge of the rectangle must be greater than or equal to 300 pixels. The aspect ratio must be 1:4 or less (i.e. 1:3 is ok; 1:5 is not)."
            }
          },
          "description": "A `ReferenceImage` represents a product image and its associated metadata, such as bounding boxes."
        }
      ]
      outputs: [
        {}
      ]
  projects.locations.products.referenceImages.delete:
    description: |-
      Permanently deletes a reference image. The image metadata will be deleted right away, but search queries against ProductSets containing the image may still work until all related caches are refreshed. The actual image files are not deleted from Google Cloud Storage.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products.referenceImages/delete
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Empty",
          "type": "object",
          "properties": {},
          "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
        }
      ]
  projects.locations.products.referenceImages.get:
    description: |-
      Gets information associated with a ReferenceImage. Possible errors: * Returns NOT_FOUND if the specified image does not exist.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products.referenceImages/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  projects.locations.products.referenceImages.list:
    description: |-
      Lists reference images. Possible errors: * Returns NOT_FOUND if the parent product does not exist. * Returns INVALID_ARGUMENT if the page_size is greater than 100, or less than 1.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.locations.products.referenceImages/list
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "ListReferenceImagesResponse",
          "type": "object",
          "properties": {
            "pageSize": {
              "type": "integer",
              "format": "int32",
              "description": "The maximum number of items to return. Default 10, maximum 100."
            },
            "nextPageToken": {
              "type": "string",
              "description": "The next_page_token returned from a previous List request, if any."
            },
            "referenceImages": {
              "type": "array",
              "items": {
                "id": "ReferenceImage",
                "type": "object",
                "properties": {
                  "uri": {
                    "type": "string",
                    "description": "Required. The Google Cloud Storage URI of the reference image. The URI must start with `gs://`."
                  },
                  "name": {
                    "type": "string",
                    "description": "The resource name of the reference image. Format is: `projects/PROJECT_ID/locations/LOC_ID/products/PRODUCT_ID/referenceImages/IMAGE_ID`. This field is ignored when creating a reference image."
                  },
                  "boundingPolys": {
                    "type": "array",
                    "items": {
                      "id": "BoundingPoly",
                      "type": "object",
                      "properties": {
                        "vertices": {
                          "type": "array",
                          "items": {
                            "id": "Vertex",
                            "type": "object",
                            "properties": {
                              "x": {
                                "type": "integer",
                                "format": "int32",
                                "description": "X coordinate."
                              },
                              "y": {
                                "type": "integer",
                                "format": "int32",
                                "description": "Y coordinate."
                              }
                            },
                            "description": "A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the original image."
                          },
                          "description": "The bounding polygon vertices."
                        },
                        "normalizedVertices": {
                          "type": "array",
                          "items": {
                            "id": "NormalizedVertex",
                            "type": "object",
                            "properties": {
                              "x": {
                                "type": "number",
                                "format": "float",
                                "description": "X coordinate."
                              },
                              "y": {
                                "type": "number",
                                "format": "float",
                                "description": "Y coordinate."
                              }
                            },
                            "description": "A vertex represents a 2D point in the image. NOTE: the normalized vertex coordinates are relative to the original image and range from 0 to 1."
                          },
                          "description": "The bounding polygon normalized vertices."
                        }
                      },
                      "description": "A bounding polygon for the detected image annotation."
                    },
                    "description": "Optional. Bounding polygons around the areas of interest in the reference image. If this field is empty, the system will try to detect regions of interest. At most 10 bounding polygons will be used. The provided shape is converted into a non-rotated rectangle. Once converted, the small edge of the rectangle must be greater than or equal to 300 pixels. The aspect ratio must be 1:4 or less (i.e. 1:3 is ok; 1:5 is not)."
                  }
                },
                "description": "A `ReferenceImage` represents a product image and its associated metadata, such as bounding boxes."
              },
              "description": "The list of reference images."
            }
          },
          "description": "Response message for the `ListReferenceImages` method."
        }
      ]
  projects.operations.get:
    description: |-
      Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
    versions:
      from: 1.0.0
    link: https://cloud.google.com/vision/docs/reference/rest/v1/projects.operations/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "Operation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "Status",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]