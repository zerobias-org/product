Product:
  name: GCP Remote Build Execution
  versions: [2.0.0]
  package: google.gcp.remotebuildexecution
  description: |-
    Remote Build Execution
  link: https://cloud.google.com/build/docs/api/reference/rest
  contentType: json
Operations:
  actionResults.get:
    description: |-
      Retrieve a cached execution result. Implementations SHOULD ensure that any blobs referenced from the ContentAddressableStorage are available at the time of returning the ActionResult and will be for some period of time afterwards. The lifetimes of the referenced blobs SHOULD be increased if necessary and applicable. Errors: * `NOT_FOUND`: The requested `ActionResult` is not in the cache.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/actionResults/get
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "BuildBazelRemoteExecutionV2ActionResult",
          "type": "object",
          "properties": {
            "exitCode": {
              "type": "integer",
              "format": "int32",
              "description": "The exit code of the command."
            },
            "stderrRaw": {
              "type": "string",
              "format": "byte",
              "description": "The standard error buffer of the action. The server SHOULD NOT inline stderr unless requested by the client in the GetActionResultRequest message. The server MAY omit inlining, even if requested, and MUST do so if inlining would cause the response to exceed message size limits."
            },
            "stdoutRaw": {
              "type": "string",
              "format": "byte",
              "description": "The standard output buffer of the action. The server SHOULD NOT inline stdout unless requested by the client in the GetActionResultRequest message. The server MAY omit inlining, even if requested, and MUST do so if inlining would cause the response to exceed message size limits."
            },
            "outputFiles": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2OutputFile",
                "type": "object",
                "properties": {
                  "path": {
                    "type": "string",
                    "description": "The full path of the file relative to the working directory, including the filename. The path separator is a forward slash `/`. Since this is a relative path, it MUST NOT begin with a leading forward slash."
                  },
                  "digest": {
                    "id": "BuildBazelRemoteExecutionV2Digest",
                    "type": "object",
                    "properties": {
                      "hash": {
                        "type": "string",
                        "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                      },
                      "sizeBytes": {
                        "type": "string",
                        "format": "int64",
                        "description": "The size of the blob, in bytes."
                      }
                    },
                    "description": "The digest of the file's content."
                  },
                  "contents": {
                    "type": "string",
                    "format": "byte",
                    "description": "The contents of the file if inlining was requested. The server SHOULD NOT inline file contents unless requested by the client in the GetActionResultRequest message. The server MAY omit inlining, even if requested, and MUST do so if inlining would cause the response to exceed message size limits."
                  },
                  "isExecutable": {
                    "type": "boolean",
                    "description": "True if file is executable, false otherwise."
                  },
                  "nodeProperties": {
                    "id": "BuildBazelRemoteExecutionV2NodeProperties",
                    "type": "object",
                    "properties": {
                      "mtime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "The file's last modification timestamp."
                      },
                      "unixMode": {
                        "type": "integer",
                        "format": "uint32",
                        "description": "The UNIX file mode, e.g., 0755."
                      },
                      "properties": {
                        "type": "array",
                        "items": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperty",
                          "type": "object",
                          "properties": {
                            "name": {
                              "type": "string",
                              "description": "The property name."
                            },
                            "value": {
                              "type": "string",
                              "description": "The property value."
                            }
                          },
                          "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                        },
                        "description": "A list of string-based NodeProperties."
                      }
                    },
                    "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                  }
                },
                "description": "An `OutputFile` is similar to a FileNode, but it is used as an output in an `ActionResult`. It allows a full file path rather than only a name."
              },
              "description": "The output files of the action. For each output file requested in the `output_files` or `output_paths` field of the Action, if the corresponding file existed after the action completed, a single entry will be present either in this field, or the `output_file_symlinks` field if the file was a symbolic link to another file (`output_symlinks` field after v2.1). If an output listed in `output_files` was found, but was a directory rather than a regular file, the server will return a FAILED_PRECONDITION. If the action does not produce the requested output, then that output will be omitted from the list. The server is free to arrange the output list as desired; clients MUST NOT assume that the output list is sorted."
            },
            "stderrDigest": {
              "id": "BuildBazelRemoteExecutionV2Digest",
              "type": "object",
              "properties": {
                "hash": {
                  "type": "string",
                  "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                },
                "sizeBytes": {
                  "type": "string",
                  "format": "int64",
                  "description": "The size of the blob, in bytes."
                }
              },
              "description": "The digest for a blob containing the standard error of the action, which can be retrieved from the ContentAddressableStorage."
            },
            "stdoutDigest": {
              "id": "BuildBazelRemoteExecutionV2Digest",
              "type": "object",
              "properties": {
                "hash": {
                  "type": "string",
                  "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                },
                "sizeBytes": {
                  "type": "string",
                  "format": "int64",
                  "description": "The size of the blob, in bytes."
                }
              },
              "description": "The digest for a blob containing the standard output of the action, which can be retrieved from the ContentAddressableStorage."
            },
            "outputSymlinks": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2OutputSymlink",
                "type": "object",
                "properties": {
                  "path": {
                    "type": "string",
                    "description": "The full path of the symlink relative to the working directory, including the filename. The path separator is a forward slash `/`. Since this is a relative path, it MUST NOT begin with a leading forward slash."
                  },
                  "target": {
                    "type": "string",
                    "description": "The target path of the symlink. The path separator is a forward slash `/`. The target path can be relative to the parent directory of the symlink or it can be an absolute path starting with `/`. Support for absolute paths can be checked using the Capabilities API. `..` components are allowed anywhere in the target path."
                  },
                  "nodeProperties": {
                    "id": "BuildBazelRemoteExecutionV2NodeProperties",
                    "type": "object",
                    "properties": {
                      "mtime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "The file's last modification timestamp."
                      },
                      "unixMode": {
                        "type": "integer",
                        "format": "uint32",
                        "description": "The UNIX file mode, e.g., 0755."
                      },
                      "properties": {
                        "type": "array",
                        "items": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperty",
                          "type": "object",
                          "properties": {
                            "name": {
                              "type": "string",
                              "description": "The property name."
                            },
                            "value": {
                              "type": "string",
                              "description": "The property value."
                            }
                          },
                          "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                        },
                        "description": "A list of string-based NodeProperties."
                      }
                    },
                    "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                  }
                },
                "description": "An `OutputSymlink` is similar to a Symlink, but it is used as an output in an `ActionResult`. `OutputSymlink` is binary-compatible with `SymlinkNode`."
              },
              "description": "New in v2.1: this field will only be populated if the command `output_paths` field was used, and not the pre v2.1 `output_files` or `output_directories` fields. The output paths of the action that are symbolic links to other paths. Those may be links to other outputs, or inputs, or even absolute paths outside of the working directory, if the server supports SymlinkAbsolutePathStrategy.ALLOWED. A single entry for each output requested in `output_paths` field of the Action, if the corresponding path existed after the action completed and was a symbolic link. If the action does not produce a requested output, then that output will be omitted from the list. The server is free to arrange the output list as desired; clients MUST NOT assume that the output list is sorted."
            },
            "executionMetadata": {
              "id": "BuildBazelRemoteExecutionV2ExecutedActionMetadata",
              "type": "object",
              "properties": {
                "worker": {
                  "type": "string",
                  "description": "The name of the worker which ran the execution."
                },
                "queuedTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When was the action added to the queue."
                },
                "auxiliaryMetadata": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "Details that are specific to the kind of worker used. For example, on POSIX-like systems this could contain a message with getrusage(2) statistics."
                },
                "workerStartTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker received the action."
                },
                "executionStartTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker started executing the action command."
                },
                "inputFetchStartTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker started fetching action inputs."
                },
                "workerCompletedTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker completed the action, including all stages."
                },
                "outputUploadStartTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker started uploading action outputs."
                },
                "executionCompletedTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker completed executing the action command."
                },
                "inputFetchCompletedTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker finished fetching action inputs."
                },
                "outputUploadCompletedTimestamp": {
                  "type": "string",
                  "format": "google-datetime",
                  "description": "When the worker finished uploading action outputs."
                }
              },
              "description": "The details of the execution that originally produced this result."
            },
            "outputDirectories": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2OutputDirectory",
                "type": "object",
                "properties": {
                  "path": {
                    "type": "string",
                    "description": "The full path of the directory relative to the working directory. The path separator is a forward slash `/`. Since this is a relative path, it MUST NOT begin with a leading forward slash. The empty string value is allowed, and it denotes the entire working directory."
                  },
                  "treeDigest": {
                    "id": "BuildBazelRemoteExecutionV2Digest",
                    "type": "object",
                    "properties": {
                      "hash": {
                        "type": "string",
                        "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                      },
                      "sizeBytes": {
                        "type": "string",
                        "format": "int64",
                        "description": "The size of the blob, in bytes."
                      }
                    },
                    "description": "The digest of the encoded Tree proto containing the directory's contents."
                  }
                },
                "description": "An `OutputDirectory` is the output in an `ActionResult` corresponding to a directory's full contents rather than a single file."
              },
              "description": "The output directories of the action. For each output directory requested in the `output_directories` or `output_paths` field of the Action, if the corresponding directory existed after the action completed, a single entry will be present in the output list, which will contain the digest of a Tree message containing the directory tree, and the path equal exactly to the corresponding Action output_directories member. As an example, suppose the Action had an output directory `a/b/dir` and the execution produced the following contents in `a/b/dir`: a file named `bar` and a directory named `foo` with an executable file named `baz`. Then, output_directory will contain (hashes shortened for readability): ```json // OutputDirectory proto: { path: \"a/b/dir\" tree_digest: { hash: \"4a73bc9d03...\", size: 55 } } // Tree proto with hash \"4a73bc9d03...\" and size 55: { root: { files: [ { name: \"bar\", digest: { hash: \"4a73bc9d03...\", size: 65534 } } ], directories: [ { name: \"foo\", digest: { hash: \"4cf2eda940...\", size: 43 } } ] } children : { // (Directory proto with hash \"4cf2eda940...\" and size 43) files: [ { name: \"baz\", digest: { hash: \"b2c941073e...\", size: 1294, }, is_executable: true } ] } } ``` If an output of the same name as listed in `output_files` of the Command was found in `output_directories`, but was not a directory, the server will return a FAILED_PRECONDITION."
            },
            "outputFileSymlinks": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2OutputSymlink",
                "type": "object",
                "properties": {
                  "path": {
                    "type": "string",
                    "description": "The full path of the symlink relative to the working directory, including the filename. The path separator is a forward slash `/`. Since this is a relative path, it MUST NOT begin with a leading forward slash."
                  },
                  "target": {
                    "type": "string",
                    "description": "The target path of the symlink. The path separator is a forward slash `/`. The target path can be relative to the parent directory of the symlink or it can be an absolute path starting with `/`. Support for absolute paths can be checked using the Capabilities API. `..` components are allowed anywhere in the target path."
                  },
                  "nodeProperties": {
                    "id": "BuildBazelRemoteExecutionV2NodeProperties",
                    "type": "object",
                    "properties": {
                      "mtime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "The file's last modification timestamp."
                      },
                      "unixMode": {
                        "type": "integer",
                        "format": "uint32",
                        "description": "The UNIX file mode, e.g., 0755."
                      },
                      "properties": {
                        "type": "array",
                        "items": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperty",
                          "type": "object",
                          "properties": {
                            "name": {
                              "type": "string",
                              "description": "The property name."
                            },
                            "value": {
                              "type": "string",
                              "description": "The property value."
                            }
                          },
                          "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                        },
                        "description": "A list of string-based NodeProperties."
                      }
                    },
                    "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                  }
                },
                "description": "An `OutputSymlink` is similar to a Symlink, but it is used as an output in an `ActionResult`. `OutputSymlink` is binary-compatible with `SymlinkNode`."
              },
              "description": "The output files of the action that are symbolic links to other files. Those may be links to other output files, or input files, or even absolute paths outside of the working directory, if the server supports SymlinkAbsolutePathStrategy.ALLOWED. For each output file requested in the `output_files` or `output_paths` field of the Action, if the corresponding file existed after the action completed, a single entry will be present either in this field, or in the `output_files` field, if the file was not a symbolic link. If an output symbolic link of the same name as listed in `output_files` of the Command was found, but its target type was not a regular file, the server will return a FAILED_PRECONDITION. If the action does not produce the requested output, then that output will be omitted from the list. The server is free to arrange the output list as desired; clients MUST NOT assume that the output list is sorted. DEPRECATED as of v2.1. Servers that wish to be compatible with v2.0 API should still populate this field in addition to `output_symlinks`."
            },
            "outputDirectorySymlinks": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2OutputSymlink",
                "type": "object",
                "properties": {
                  "path": {
                    "type": "string",
                    "description": "The full path of the symlink relative to the working directory, including the filename. The path separator is a forward slash `/`. Since this is a relative path, it MUST NOT begin with a leading forward slash."
                  },
                  "target": {
                    "type": "string",
                    "description": "The target path of the symlink. The path separator is a forward slash `/`. The target path can be relative to the parent directory of the symlink or it can be an absolute path starting with `/`. Support for absolute paths can be checked using the Capabilities API. `..` components are allowed anywhere in the target path."
                  },
                  "nodeProperties": {
                    "id": "BuildBazelRemoteExecutionV2NodeProperties",
                    "type": "object",
                    "properties": {
                      "mtime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "The file's last modification timestamp."
                      },
                      "unixMode": {
                        "type": "integer",
                        "format": "uint32",
                        "description": "The UNIX file mode, e.g., 0755."
                      },
                      "properties": {
                        "type": "array",
                        "items": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperty",
                          "type": "object",
                          "properties": {
                            "name": {
                              "type": "string",
                              "description": "The property name."
                            },
                            "value": {
                              "type": "string",
                              "description": "The property value."
                            }
                          },
                          "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                        },
                        "description": "A list of string-based NodeProperties."
                      }
                    },
                    "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                  }
                },
                "description": "An `OutputSymlink` is similar to a Symlink, but it is used as an output in an `ActionResult`. `OutputSymlink` is binary-compatible with `SymlinkNode`."
              },
              "description": "The output directories of the action that are symbolic links to other directories. Those may be links to other output directories, or input directories, or even absolute paths outside of the working directory, if the server supports SymlinkAbsolutePathStrategy.ALLOWED. For each output directory requested in the `output_directories` field of the Action, if the directory existed after the action completed, a single entry will be present either in this field, or in the `output_directories` field, if the directory was not a symbolic link. If an output of the same name was found, but was a symbolic link to a file instead of a directory, the server will return a FAILED_PRECONDITION. If the action does not produce the requested output, then that output will be omitted from the list. The server is free to arrange the output list as desired; clients MUST NOT assume that the output list is sorted. DEPRECATED as of v2.1. Servers that wish to be compatible with v2.0 API should still populate this field in addition to `output_symlinks`."
            }
          },
          "description": "An ActionResult represents the result of an Action being run. It is advised that at least one field (for example `ActionResult.execution_metadata.Worker`) have a non-default value, to ensure that the serialized value is non-empty, which can then be used as a basic data sanity check."
        }
      ]
  actionResults.update:
    description: |-
      Upload a new execution result. In order to allow the server to perform access control based on the type of action, and to assist with client debugging, the client MUST first upload the Action that produced the result, along with its Command, into the `ContentAddressableStorage`. Server implementations MAY modify the `UpdateActionResultRequest.action_result` and return an equivalent value. Errors: * `INVALID_ARGUMENT`: One or more arguments are invalid. * `FAILED_PRECONDITION`: One or more errors occurred in updating the action result, such as a missing command or action. * `RESOURCE_EXHAUSTED`: There is insufficient storage space to add the entry to the cache.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/actionResults/update
    example:
      inputs: [
        {}
      ]
      outputs: [
        {}
      ]
  actions.execute:
    description: |-
      Execute an action remotely. In order to execute an action, the client must first upload all of the inputs, the Command to run, and the Action into the ContentAddressableStorage. It then calls `Execute` with an `action_digest` referring to them. The server will run the action and eventually return the result. The input `Action`'s fields MUST meet the various canonicalization requirements specified in the documentation for their types so that it has the same digest as other logically equivalent `Action`s. The server MAY enforce the requirements and return errors if a non-canonical input is received. It MAY also proceed without verifying some or all of the requirements, such as for performance reasons. If the server does not verify the requirement, then it will treat the `Action` as distinct from another logically equivalent action if they hash differently. Returns a stream of google.longrunning.Operation messages describing the resulting execution, with eventual `response` ExecuteResponse. The `metadata` on the operation is of type ExecuteOperationMetadata. If the client remains connected after the first response is returned after the server, then updates are streamed as if the client had called WaitExecution until the execution completes or the request reaches an error. The operation can also be queried using Operations API. The server NEED NOT implement other methods or functionality of the Operations API. Errors discovered during creation of the `Operation` will be reported as gRPC Status errors, while errors that occurred while running the action will be reported in the `status` field of the `ExecuteResponse`. The server MUST NOT set the `error` field of the `Operation` proto. The possible errors include: * `INVALID_ARGUMENT`: One or more arguments are invalid. * `FAILED_PRECONDITION`: One or more errors occurred in setting up the action requested, such as a missing input or command or no worker being available. The client may be able to fix the errors and retry. * `RESOURCE_EXHAUSTED`: There is insufficient quota of some resource to run the action. * `UNAVAILABLE`: Due to a transient condition, such as all workers being occupied (and the server does not support a queue), the action could not be started. The client should retry. * `INTERNAL`: An internal error occurred in the execution engine or the worker. * `DEADLINE_EXCEEDED`: The execution timed out. * `CANCELLED`: The operation was cancelled by the client. This status is only possible if the server implements the Operations API CancelOperation method, and it was called for the current execution. In the case of a missing input or command, the server SHOULD additionally send a PreconditionFailure error detail where, for each requested blob not present in the CAS, there is a `Violation` with a `type` of `MISSING` and a `subject` of `"blobs/{hash}/{size}"` indicating the digest of the missing blob. The server does not need to guarantee that a call to this method leads to at most one execution of the action. The server MAY execute the action multiple times, potentially in parallel. These redundant executions MAY continue to run, even if the operation is completed.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/actions/execute
    example:
      inputs: [
        {
          "id": "BuildBazelRemoteExecutionV2ExecuteRequest",
          "type": "object",
          "properties": {
            "actionDigest": {
              "id": "BuildBazelRemoteExecutionV2Digest",
              "type": "object",
              "properties": {
                "hash": {
                  "type": "string",
                  "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                },
                "sizeBytes": {
                  "type": "string",
                  "format": "int64",
                  "description": "The size of the blob, in bytes."
                }
              },
              "description": "The digest of the Action to execute."
            },
            "executionPolicy": {
              "id": "BuildBazelRemoteExecutionV2ExecutionPolicy",
              "type": "object",
              "properties": {
                "priority": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The priority (relative importance) of this action. Generally, a lower value means that the action should be run sooner than actions having a greater priority value, but the interpretation of a given value is server- dependent. A priority of 0 means the *default* priority. Priorities may be positive or negative, and such actions should run later or sooner than actions having the default priority, respectively. The particular semantics of this field is up to the server. In particular, every server will have their own supported range of priorities, and will decide how these map into scheduling policy."
                }
              },
              "description": "An optional policy for execution of the action. The server will have a default policy if this is not provided."
            },
            "skipCacheLookup": {
              "type": "boolean",
              "description": "If true, the action will be executed even if its result is already present in the ActionCache. The execution is still allowed to be merged with other in-flight executions of the same action, however - semantically, the service MUST only guarantee that the results of an execution with this field set were not visible before the corresponding execution request was sent. Note that actions from execution requests setting this field set are still eligible to be entered into the action cache upon completion, and services SHOULD overwrite any existing entries that may exist. This allows skip_cache_lookup requests to be used as a mechanism for replacing action cache entries that reference outputs no longer available or that are poisoned in any way. If false, the result may be served from the action cache."
            },
            "resultsCachePolicy": {
              "id": "BuildBazelRemoteExecutionV2ResultsCachePolicy",
              "type": "object",
              "properties": {
                "priority": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The priority (relative importance) of this content in the overall cache. Generally, a lower value means a longer retention time or other advantage, but the interpretation of a given value is server-dependent. A priority of 0 means a *default* value, decided by the server. The particular semantics of this field is up to the server. In particular, every server will have their own supported range of priorities, and will decide how these map into retention/eviction policy."
                }
              },
              "description": "An optional policy for the results of this execution in the remote cache. The server will have a default policy if this is not provided. This may be applied to both the ActionResult and the associated blobs."
            }
          },
          "description": "A request message for Execution.Execute."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]
  blobs.batchRead:
    description: |-
      Download many blobs at once. The server may enforce a limit of the combined total size of blobs to be downloaded using this API. This limit may be obtained using the Capabilities API. Requests exceeding the limit should either be split into smaller chunks or downloaded using the ByteStream API, as appropriate. This request is equivalent to calling a Bytestream `Read` request on each individual blob, in parallel. The requests may succeed or fail independently. Errors: * `INVALID_ARGUMENT`: The client attempted to read more than the server supported limit. Every error on individual read will be returned in the corresponding digest status.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/blobs/batchRead
    example:
      inputs: [
        {
          "id": "BuildBazelRemoteExecutionV2BatchReadBlobsRequest",
          "type": "object",
          "properties": {
            "digests": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2Digest",
                "type": "object",
                "properties": {
                  "hash": {
                    "type": "string",
                    "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                  },
                  "sizeBytes": {
                    "type": "string",
                    "format": "int64",
                    "description": "The size of the blob, in bytes."
                  }
                },
                "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
              },
              "description": "The individual blob digests."
            }
          },
          "description": "A request message for ContentAddressableStorage.BatchReadBlobs."
        }
      ]
      outputs: [
        {
          "id": "BuildBazelRemoteExecutionV2BatchReadBlobsResponse",
          "type": "object",
          "properties": {
            "responses": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2BatchReadBlobsResponseResponse",
                "type": "object",
                "properties": {
                  "data": {
                    "type": "string",
                    "format": "byte",
                    "description": "The raw binary data."
                  },
                  "digest": {
                    "id": "BuildBazelRemoteExecutionV2Digest",
                    "type": "object",
                    "properties": {
                      "hash": {
                        "type": "string",
                        "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                      },
                      "sizeBytes": {
                        "type": "string",
                        "format": "int64",
                        "description": "The size of the blob, in bytes."
                      }
                    },
                    "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
                  },
                  "status": {
                    "id": "GoogleRpcStatus",
                    "type": "object",
                    "properties": {
                      "code": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The status code, which should be an enum value of google.rpc.Code."
                      },
                      "details": {
                        "type": "array",
                        "items": {
                          "type": "object",
                          "additionalProperties": {
                            "type": "any",
                            "description": "Properties of the object. Contains field @type with type URL."
                          }
                        },
                        "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                      },
                      "message": {
                        "type": "string",
                        "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                      }
                    },
                    "description": "The result of attempting to download that blob."
                  }
                },
                "description": "A response corresponding to a single blob that the client tried to download."
              },
              "description": "The responses to the requests."
            }
          },
          "description": "A response message for ContentAddressableStorage.BatchReadBlobs."
        }
      ]
  blobs.batchUpdate:
    description: |-
      Upload many blobs at once. The server may enforce a limit of the combined total size of blobs to be uploaded using this API. This limit may be obtained using the Capabilities API. Requests exceeding the limit should either be split into smaller chunks or uploaded using the ByteStream API, as appropriate. This request is equivalent to calling a Bytestream `Write` request on each individual blob, in parallel. The requests may succeed or fail independently. Errors: * `INVALID_ARGUMENT`: The client attempted to upload more than the server supported limit. Individual requests may return the following errors, additionally: * `RESOURCE_EXHAUSTED`: There is insufficient disk quota to store the blob. * `INVALID_ARGUMENT`: The Digest does not match the provided data.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/blobs/batchUpdate
    example:
      inputs: [
        {
          "id": "BuildBazelRemoteExecutionV2BatchUpdateBlobsRequest",
          "type": "object",
          "properties": {
            "requests": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2BatchUpdateBlobsRequestRequest",
                "type": "object",
                "properties": {
                  "data": {
                    "type": "string",
                    "format": "byte",
                    "description": "The raw binary data."
                  },
                  "digest": {
                    "id": "BuildBazelRemoteExecutionV2Digest",
                    "type": "object",
                    "properties": {
                      "hash": {
                        "type": "string",
                        "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                      },
                      "sizeBytes": {
                        "type": "string",
                        "format": "int64",
                        "description": "The size of the blob, in bytes."
                      }
                    },
                    "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
                  }
                },
                "description": "A request corresponding to a single blob that the client wants to upload."
              },
              "description": "The individual upload requests."
            }
          },
          "description": "A request message for ContentAddressableStorage.BatchUpdateBlobs."
        }
      ]
      outputs: [
        {
          "id": "BuildBazelRemoteExecutionV2BatchUpdateBlobsResponse",
          "type": "object",
          "properties": {
            "responses": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2BatchUpdateBlobsResponseResponse",
                "type": "object",
                "properties": {
                  "digest": {
                    "id": "BuildBazelRemoteExecutionV2Digest",
                    "type": "object",
                    "properties": {
                      "hash": {
                        "type": "string",
                        "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                      },
                      "sizeBytes": {
                        "type": "string",
                        "format": "int64",
                        "description": "The size of the blob, in bytes."
                      }
                    },
                    "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
                  },
                  "status": {
                    "id": "GoogleRpcStatus",
                    "type": "object",
                    "properties": {
                      "code": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The status code, which should be an enum value of google.rpc.Code."
                      },
                      "details": {
                        "type": "array",
                        "items": {
                          "type": "object",
                          "additionalProperties": {
                            "type": "any",
                            "description": "Properties of the object. Contains field @type with type URL."
                          }
                        },
                        "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                      },
                      "message": {
                        "type": "string",
                        "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                      }
                    },
                    "description": "The result of attempting to upload that blob."
                  }
                },
                "description": "A response corresponding to a single blob that the client tried to upload."
              },
              "description": "The responses to the requests."
            }
          },
          "description": "A response message for ContentAddressableStorage.BatchUpdateBlobs."
        }
      ]
  blobs.findMissing:
    description: |-
      Determine if blobs are present in the CAS. Clients can use this API before uploading blobs to determine which ones are already present in the CAS and do not need to be uploaded again. Servers SHOULD increase the lifetimes of the referenced blobs if necessary and applicable. There are no method-specific errors.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/blobs/findMissing
    example:
      inputs: [
        {
          "id": "BuildBazelRemoteExecutionV2FindMissingBlobsRequest",
          "type": "object",
          "properties": {
            "blobDigests": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2Digest",
                "type": "object",
                "properties": {
                  "hash": {
                    "type": "string",
                    "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                  },
                  "sizeBytes": {
                    "type": "string",
                    "format": "int64",
                    "description": "The size of the blob, in bytes."
                  }
                },
                "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
              },
              "description": "A list of the blobs to check."
            }
          },
          "description": "A request message for ContentAddressableStorage.FindMissingBlobs."
        }
      ]
      outputs: [
        {
          "id": "BuildBazelRemoteExecutionV2FindMissingBlobsResponse",
          "type": "object",
          "properties": {
            "missingBlobDigests": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2Digest",
                "type": "object",
                "properties": {
                  "hash": {
                    "type": "string",
                    "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                  },
                  "sizeBytes": {
                    "type": "string",
                    "format": "int64",
                    "description": "The size of the blob, in bytes."
                  }
                },
                "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
              },
              "description": "A list of the blobs requested *not* present in the storage."
            }
          },
          "description": "A response message for ContentAddressableStorage.FindMissingBlobs."
        }
      ]
  blobs.getTree:
    description: |-
      Fetch the entire directory tree rooted at a node. This request must be targeted at a Directory stored in the ContentAddressableStorage (CAS). The server will enumerate the `Directory` tree recursively and return every node descended from the root. The GetTreeRequest.page_token parameter can be used to skip ahead in the stream (e.g. when retrying a partially completed and aborted request), by setting it to a value taken from GetTreeResponse.next_page_token of the last successfully processed GetTreeResponse). The exact traversal order is unspecified and, unless retrieving subsequent pages from an earlier request, is not guaranteed to be stable across multiple invocations of `GetTree`. If part of the tree is missing from the CAS, the server will return the portion present and omit the rest. Errors: * `NOT_FOUND`: The requested tree root is not present in the CAS.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/blobs/getTree
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "BuildBazelRemoteExecutionV2GetTreeResponse",
          "type": "object",
          "properties": {
            "directories": {
              "type": "array",
              "items": {
                "id": "BuildBazelRemoteExecutionV2Directory",
                "type": "object",
                "properties": {
                  "files": {
                    "type": "array",
                    "items": {
                      "id": "BuildBazelRemoteExecutionV2FileNode",
                      "type": "object",
                      "properties": {
                        "name": {
                          "type": "string",
                          "description": "The name of the file."
                        },
                        "digest": {
                          "id": "BuildBazelRemoteExecutionV2Digest",
                          "type": "object",
                          "properties": {
                            "hash": {
                              "type": "string",
                              "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                            },
                            "sizeBytes": {
                              "type": "string",
                              "format": "int64",
                              "description": "The size of the blob, in bytes."
                            }
                          },
                          "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
                        },
                        "isExecutable": {
                          "type": "boolean",
                          "description": "True if file is executable, false otherwise."
                        },
                        "nodeProperties": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperties",
                          "type": "object",
                          "properties": {
                            "mtime": {
                              "type": "string",
                              "format": "google-datetime",
                              "description": "The file's last modification timestamp."
                            },
                            "unixMode": {
                              "type": "integer",
                              "format": "uint32",
                              "description": "The UNIX file mode, e.g., 0755."
                            },
                            "properties": {
                              "type": "array",
                              "items": {
                                "id": "BuildBazelRemoteExecutionV2NodeProperty",
                                "type": "object",
                                "properties": {
                                  "name": {
                                    "type": "string",
                                    "description": "The property name."
                                  },
                                  "value": {
                                    "type": "string",
                                    "description": "The property value."
                                  }
                                },
                                "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                              },
                              "description": "A list of string-based NodeProperties."
                            }
                          },
                          "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                        }
                      },
                      "description": "A `FileNode` represents a single file and associated metadata."
                    },
                    "description": "The files in the directory."
                  },
                  "symlinks": {
                    "type": "array",
                    "items": {
                      "id": "BuildBazelRemoteExecutionV2SymlinkNode",
                      "type": "object",
                      "properties": {
                        "name": {
                          "type": "string",
                          "description": "The name of the symlink."
                        },
                        "target": {
                          "type": "string",
                          "description": "The target path of the symlink. The path separator is a forward slash `/`. The target path can be relative to the parent directory of the symlink or it can be an absolute path starting with `/`. Support for absolute paths can be checked using the Capabilities API. `..` components are allowed anywhere in the target path as logical canonicalization may lead to different behavior in the presence of directory symlinks (e.g. `foo/../bar` may not be the same as `bar`). To reduce potential cache misses, canonicalization is still recommended where this is possible without impacting correctness."
                        },
                        "nodeProperties": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperties",
                          "type": "object",
                          "properties": {
                            "mtime": {
                              "type": "string",
                              "format": "google-datetime",
                              "description": "The file's last modification timestamp."
                            },
                            "unixMode": {
                              "type": "integer",
                              "format": "uint32",
                              "description": "The UNIX file mode, e.g., 0755."
                            },
                            "properties": {
                              "type": "array",
                              "items": {
                                "id": "BuildBazelRemoteExecutionV2NodeProperty",
                                "type": "object",
                                "properties": {
                                  "name": {
                                    "type": "string",
                                    "description": "The property name."
                                  },
                                  "value": {
                                    "type": "string",
                                    "description": "The property value."
                                  }
                                },
                                "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                              },
                              "description": "A list of string-based NodeProperties."
                            }
                          },
                          "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                        }
                      },
                      "description": "A `SymlinkNode` represents a symbolic link."
                    },
                    "description": "The symlinks in the directory."
                  },
                  "directories": {
                    "type": "array",
                    "items": {
                      "id": "BuildBazelRemoteExecutionV2DirectoryNode",
                      "type": "object",
                      "properties": {
                        "name": {
                          "type": "string",
                          "description": "The name of the directory."
                        },
                        "digest": {
                          "id": "BuildBazelRemoteExecutionV2Digest",
                          "type": "object",
                          "properties": {
                            "hash": {
                              "type": "string",
                              "description": "The hash. In the case of SHA-256, it will always be a lowercase hex string exactly 64 characters long."
                            },
                            "sizeBytes": {
                              "type": "string",
                              "format": "int64",
                              "description": "The size of the blob, in bytes."
                            }
                          },
                          "description": "A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the `hash` field is correctly specified but `size_bytes` is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a `Digest` is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields."
                        }
                      },
                      "description": "A `DirectoryNode` represents a child of a Directory which is itself a `Directory` and its associated metadata."
                    },
                    "description": "The subdirectories in the directory."
                  },
                  "nodeProperties": {
                    "id": "BuildBazelRemoteExecutionV2NodeProperties",
                    "type": "object",
                    "properties": {
                      "mtime": {
                        "type": "string",
                        "format": "google-datetime",
                        "description": "The file's last modification timestamp."
                      },
                      "unixMode": {
                        "type": "integer",
                        "format": "uint32",
                        "description": "The UNIX file mode, e.g., 0755."
                      },
                      "properties": {
                        "type": "array",
                        "items": {
                          "id": "BuildBazelRemoteExecutionV2NodeProperty",
                          "type": "object",
                          "properties": {
                            "name": {
                              "type": "string",
                              "description": "The property name."
                            },
                            "value": {
                              "type": "string",
                              "description": "The property value."
                            }
                          },
                          "description": "A single property for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the property `name`s that it accepts. If permitted by the server, the same `name` may occur multiple times."
                        },
                        "description": "A list of string-based NodeProperties."
                      }
                    },
                    "description": "Node properties for FileNodes, DirectoryNodes, and SymlinkNodes. The server is responsible for specifying the properties that it accepts."
                  }
                },
                "description": "A `Directory` represents a directory node in a file tree, containing zero or more children FileNodes, DirectoryNodes and SymlinkNodes. Each `Node` contains its name in the directory, either the digest of its content (either a file blob or a `Directory` proto) or a symlink target, as well as possibly some metadata about the file or directory. In order to ensure that two equivalent directory trees hash to the same value, the following restrictions MUST be obeyed when constructing a a `Directory`: * Every child in the directory must have a path of exactly one segment. Multiple levels of directory hierarchy may not be collapsed. * Each child in the directory must have a unique path segment (file name). Note that while the API itself is case-sensitive, the environment where the Action is executed may or may not be case-sensitive. That is, it is legal to call the API with a Directory that has both \"Foo\" and \"foo\" as children, but the Action may be rejected by the remote system upon execution. * The files, directories and symlinks in the directory must each be sorted in lexicographical order by path. The path strings must be sorted by code point, equivalently, by UTF-8 bytes. * The NodeProperties of files, directories, and symlinks must be sorted in lexicographical order by property name. A `Directory` that obeys the restrictions is said to be in canonical form. As an example, the following could be used for a file named `bar` and a directory named `foo` with an executable file named `baz` (hashes shortened for readability): ```json // (Directory proto) { files: [ { name: \"bar\", digest: { hash: \"4a73bc9d03...\", size: 65534 }, node_properties: [ { \"name\": \"MTime\", \"value\": \"2017-01-15T01:30:15.01Z\" } ] } ], directories: [ { name: \"foo\", digest: { hash: \"4cf2eda940...\", size: 43 } } ] } // (Directory proto with hash \"4cf2eda940...\" and size 43) { files: [ { name: \"baz\", digest: { hash: \"b2c941073e...\", size: 1294, }, is_executable: true } ] } ```"
              },
              "description": "The directories descended from the requested root."
            },
            "nextPageToken": {
              "type": "string",
              "description": "If present, signifies that there are more results which the client can retrieve by passing this as the page_token in a subsequent request. If empty, signifies that this is the last page of results."
            }
          },
          "description": "A response message for ContentAddressableStorage.GetTree."
        }
      ]
  getCapabilities:
    description: |-
      GetCapabilities returns the server capabilities configuration of the remote endpoint. Only the capabilities of the services supported by the endpoint will be returned: * Execution + CAS + Action Cache endpoints should return both CacheCapabilities and ExecutionCapabilities. * Execution only endpoints should return ExecutionCapabilities. * CAS + Action Cache only endpoints should return CacheCapabilities.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2//etCapabilities
    example:
      inputs: [
        {}
      ]
      outputs: [
        {
          "id": "BuildBazelRemoteExecutionV2ServerCapabilities",
          "type": "object",
          "properties": {
            "lowApiVersion": {
              "id": "BuildBazelSemverSemVer",
              "type": "object",
              "properties": {
                "major": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The major version, e.g 10 for 10.2.3."
                },
                "minor": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The minor version, e.g. 2 for 10.2.3."
                },
                "patch": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The patch version, e.g 3 for 10.2.3."
                },
                "prerelease": {
                  "type": "string",
                  "description": "The pre-release version. Either this field or major/minor/patch fields must be filled. They are mutually exclusive. Pre-release versions are assumed to be earlier than any released versions."
                }
              },
              "description": "Earliest non-deprecated RE API version supported."
            },
            "highApiVersion": {
              "id": "BuildBazelSemverSemVer",
              "type": "object",
              "properties": {
                "major": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The major version, e.g 10 for 10.2.3."
                },
                "minor": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The minor version, e.g. 2 for 10.2.3."
                },
                "patch": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The patch version, e.g 3 for 10.2.3."
                },
                "prerelease": {
                  "type": "string",
                  "description": "The pre-release version. Either this field or major/minor/patch fields must be filled. They are mutually exclusive. Pre-release versions are assumed to be earlier than any released versions."
                }
              },
              "description": "Latest RE API version supported."
            },
            "cacheCapabilities": {
              "id": "BuildBazelRemoteExecutionV2CacheCapabilities",
              "type": "object",
              "properties": {
                "digestFunction": {
                  "type": "array",
                  "items": {
                    "enum": [
                      "UNKNOWN",
                      "SHA256",
                      "SHA1",
                      "MD5",
                      "VSO",
                      "SHA384",
                      "SHA512",
                      "MURMUR3"
                    ],
                    "type": "string",
                    "enumDescriptions": [
                      "It is an error for the server to return this value.",
                      "The SHA-256 digest function.",
                      "The SHA-1 digest function.",
                      "The MD5 digest function.",
                      "The Microsoft \"VSO-Hash\" paged SHA256 digest function. See https://github.com/microsoft/BuildXL/blob/master/Documentation/Specs/PagedHash.md .",
                      "The SHA-384 digest function.",
                      "The SHA-512 digest function.",
                      "Murmur3 128-bit digest function, x64 variant. Note that this is not a cryptographic hash function and its collision properties are not strongly guaranteed. See https://github.com/aappleby/smhasher/wiki/MurmurHash3 ."
                    ]
                  },
                  "description": "All the digest functions supported by the remote cache. Remote cache may support multiple digest functions simultaneously."
                },
                "supportedCompressor": {
                  "type": "array",
                  "items": {
                    "enum": [
                      "IDENTITY",
                      "ZSTD"
                    ],
                    "type": "string",
                    "enumDescriptions": [
                      "No compression. Servers and clients MUST always support this, and do not need to advertise it.",
                      "Zstandard compression."
                    ]
                  },
                  "description": "Compressors supported by the \"compressed-blobs\" bytestream resources. Servers MUST support identity/no-compression, even if it is not listed here. Note that this does not imply which if any compressors are supported by the server at the gRPC level."
                },
                "maxBatchTotalSizeBytes": {
                  "type": "string",
                  "format": "int64",
                  "description": "Maximum total size of blobs to be uploaded/downloaded using batch methods. A value of 0 means no limit is set, although in practice there will always be a message size limitation of the protocol in use, e.g. GRPC."
                },
                "cachePriorityCapabilities": {
                  "id": "BuildBazelRemoteExecutionV2PriorityCapabilities",
                  "type": "object",
                  "properties": {
                    "priorities": {
                      "type": "array",
                      "items": {
                        "id": "BuildBazelRemoteExecutionV2PriorityCapabilitiesPriorityRange",
                        "type": "object",
                        "properties": {
                          "maxPriority": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The maximum numeric value for this priority range, which represents the least urgent task or shortest retained item."
                          },
                          "minPriority": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The minimum numeric value for this priority range, which represents the most urgent task or longest retained item."
                          }
                        },
                        "description": "Supported range of priorities, including boundaries."
                      }
                    }
                  },
                  "description": "Supported cache priority range for both CAS and ActionCache."
                },
                "symlinkAbsolutePathStrategy": {
                  "enum": [
                    "UNKNOWN",
                    "DISALLOWED",
                    "ALLOWED"
                  ],
                  "type": "string",
                  "description": "Whether absolute symlink targets are supported.",
                  "enumDescriptions": [
                    "Invalid value.",
                    "Server will return an `INVALID_ARGUMENT` on input symlinks with absolute targets. If an action tries to create an output symlink with an absolute target, a `FAILED_PRECONDITION` will be returned.",
                    "Server will allow symlink targets to escape the input root tree, possibly resulting in non-hermetic builds."
                  ]
                },
                "actionCacheUpdateCapabilities": {
                  "id": "BuildBazelRemoteExecutionV2ActionCacheUpdateCapabilities",
                  "type": "object",
                  "properties": {
                    "updateEnabled": {
                      "type": "boolean"
                    }
                  },
                  "description": "Capabilities for updating the action cache."
                }
              },
              "description": "Capabilities of the remote cache system."
            },
            "deprecatedApiVersion": {
              "id": "BuildBazelSemverSemVer",
              "type": "object",
              "properties": {
                "major": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The major version, e.g 10 for 10.2.3."
                },
                "minor": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The minor version, e.g. 2 for 10.2.3."
                },
                "patch": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The patch version, e.g 3 for 10.2.3."
                },
                "prerelease": {
                  "type": "string",
                  "description": "The pre-release version. Either this field or major/minor/patch fields must be filled. They are mutually exclusive. Pre-release versions are assumed to be earlier than any released versions."
                }
              },
              "description": "Earliest RE API version supported, including deprecated versions."
            },
            "executionCapabilities": {
              "id": "BuildBazelRemoteExecutionV2ExecutionCapabilities",
              "type": "object",
              "properties": {
                "execEnabled": {
                  "type": "boolean",
                  "description": "Whether remote execution is enabled for the particular server/instance."
                },
                "digestFunction": {
                  "enum": [
                    "UNKNOWN",
                    "SHA256",
                    "SHA1",
                    "MD5",
                    "VSO",
                    "SHA384",
                    "SHA512",
                    "MURMUR3"
                  ],
                  "type": "string",
                  "description": "Remote execution may only support a single digest function.",
                  "enumDescriptions": [
                    "It is an error for the server to return this value.",
                    "The SHA-256 digest function.",
                    "The SHA-1 digest function.",
                    "The MD5 digest function.",
                    "The Microsoft \"VSO-Hash\" paged SHA256 digest function. See https://github.com/microsoft/BuildXL/blob/master/Documentation/Specs/PagedHash.md .",
                    "The SHA-384 digest function.",
                    "The SHA-512 digest function.",
                    "Murmur3 128-bit digest function, x64 variant. Note that this is not a cryptographic hash function and its collision properties are not strongly guaranteed. See https://github.com/aappleby/smhasher/wiki/MurmurHash3 ."
                  ]
                },
                "supportedNodeProperties": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Supported node properties."
                },
                "executionPriorityCapabilities": {
                  "id": "BuildBazelRemoteExecutionV2PriorityCapabilities",
                  "type": "object",
                  "properties": {
                    "priorities": {
                      "type": "array",
                      "items": {
                        "id": "BuildBazelRemoteExecutionV2PriorityCapabilitiesPriorityRange",
                        "type": "object",
                        "properties": {
                          "maxPriority": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The maximum numeric value for this priority range, which represents the least urgent task or shortest retained item."
                          },
                          "minPriority": {
                            "type": "integer",
                            "format": "int32",
                            "description": "The minimum numeric value for this priority range, which represents the most urgent task or longest retained item."
                          }
                        },
                        "description": "Supported range of priorities, including boundaries."
                      }
                    }
                  },
                  "description": "Supported execution priority range."
                }
              },
              "description": "Capabilities of the remote execution system."
            }
          },
          "description": "A response message for Capabilities.GetCapabilities."
        }
      ]
  operations.waitExecution:
    description: |-
      Wait for an execution operation to complete. When the client initially makes the request, the server immediately responds with the current status of the execution. The server will leave the request stream open until the operation completes, and then respond with the completed operation. The server MAY choose to stream additional updates as execution progresses, such as to provide an update as to the state of the execution.
    versions:
      from: 2.0.0
    link: https://cloud.google.com/remote-build-execution/docs//v2/operations/waitExecution
    example:
      inputs: [
        {
          "id": "BuildBazelRemoteExecutionV2WaitExecutionRequest",
          "type": "object",
          "properties": {},
          "description": "A request message for WaitExecution."
        }
      ]
      outputs: [
        {
          "id": "GoogleLongrunningOperation",
          "type": "object",
          "properties": {
            "done": {
              "type": "boolean",
              "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available."
            },
            "name": {
              "type": "string",
              "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`."
            },
            "error": {
              "id": "GoogleRpcStatus",
              "type": "object",
              "properties": {
                "code": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The status code, which should be an enum value of google.rpc.Code."
                },
                "details": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "additionalProperties": {
                      "type": "any",
                      "description": "Properties of the object. Contains field @type with type URL."
                    }
                  },
                  "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use."
                },
                "message": {
                  "type": "string",
                  "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
                }
              },
              "description": "The error result of the operation in case of failure or cancellation."
            },
            "metadata": {
              "type": "object",
              "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            },
            "response": {
              "type": "object",
              "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.",
              "additionalProperties": {
                "type": "any",
                "description": "Properties of the object. Contains field @type with type URL."
              }
            }
          },
          "description": "This resource represents a long-running operation that is the result of a network API call."
        }
      ]